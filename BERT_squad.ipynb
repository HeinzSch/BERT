{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAUq7duyG5J0"
   },
   "source": [
    "# Fase 1: Importar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XYlThAmGZg1",
    "outputId": "921dd8cc-b788-4a3c-94b8-295f7edaf6cf"
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "#!pip install sentencepiece\n",
    "#!pip install tf-models-official\n",
    "#!pip install tf-models-nightly # mejor instalar la versión en desarrollo\n",
    "#!pip install tf-nightly\n",
    "#!pip install tensorflow_hub\n",
    "#!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eDdYqvxPHnI8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "id": "zFS9XSASHvQi",
    "outputId": "f9859e9f-5200-4999-ed0d-026c3f45c3cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Fv38eJzSH00S"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "from official.nlp.bert.tokenization import FullTokenizer\n",
    "from official.nlp.bert.input_pipeline import create_squad_dataset\n",
    "from official.nlp.data.squad_lib import generate_tf_record_from_json_file\n",
    "\n",
    "from official.nlp import optimization\n",
    "\n",
    "from official.nlp.data.squad_lib import read_squad_examples\n",
    "from official.nlp.data.squad_lib import FeatureWriter\n",
    "from official.nlp.data.squad_lib import convert_examples_to_features\n",
    "from official.nlp.data.squad_lib import write_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WjzrCZJMJN1N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSGw1I_zHAb5"
   },
   "source": [
    "# Fase 2: Preprocesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfdTEReCKFky",
    "outputId": "82d941bc-9989-4350-d331-ad08e0f2eaec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/icarlos/BERT/Q&A'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E_PcOeemKcYq"
   },
   "outputs": [],
   "source": [
    "input_meta_data = generate_tf_record_from_json_file(\n",
    "    \"/home/icarlos/BERT/Q&A/train-v1.1.json\",\n",
    "    \"/home/icarlos/BERT/Q&A/vocab.txt\",\n",
    "    \"/home/icarlos/BERT/Q&A/train-v1.1.tf_record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7XQGdnANLziM"
   },
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(\"/home/icarlos/BERT/Q&A/train_meta_data\", \"w\") as writer:\n",
    "    writer.write(json.dumps(input_meta_data, indent=4) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "295nG2zQMYSU",
    "outputId": "c4465981-dde3-46d3-c2f1-ee873caa2f32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 22:05:14.076876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.081641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.082098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.083238: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-24 22:05:14.083818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.084227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.084608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.462592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.463006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.463366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-24 22:05:14.463718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5935 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = create_squad_dataset(\n",
    "    \"/home/icarlos/BERT/Q&A/train-v1.1.tf_record\",\n",
    "    input_meta_data['max_seq_length'], # 384\n",
    "    BATCH_SIZE,\n",
    "    is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4939RJqHRUs"
   },
   "source": [
    "# Fase 3: Construcción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcQcFi8kOc6K"
   },
   "source": [
    "## Capa Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gjmLeQjiaOo5"
   },
   "outputs": [],
   "source": [
    "class BertSquadLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BertSquadLayer, self).__init__()\n",
    "        self.final_dense = tf.keras.layers.Dense(\n",
    "            units=2,\n",
    "            kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        logits = self.final_dense(inputs) # (batch_size, seq_len, 2)\n",
    "        logits = tf.transpose(logits, [2, 0, 1]) # (2, batch_size, seq_len)\n",
    "        unstacked_logits = tf.unstack(logits, axis=0) # [(batch_size, seq_len), (batch_size, seq_len)] \n",
    "        return unstacked_logits[0], unstacked_logits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQbQFKjUOeyf"
   },
   "source": [
    "## Modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KgkIFb1GMT81"
   },
   "outputs": [],
   "source": [
    "class BERTSquad(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 name=\"bert_squad\"):\n",
    "        super(BERTSquad, self).__init__(name=name)\n",
    "        \n",
    "        self.bert_layer = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "            trainable=True)\n",
    "        \n",
    "        self.squad_layer = BertSquadLayer()\n",
    "    \n",
    "    def apply_bert(self, inputs):\n",
    "        _ , sequence_output = self.bert_layer([inputs[\"input_word_ids\"],\n",
    "                                               inputs[\"input_mask\"],\n",
    "                                               inputs[\"input_type_ids\"]])\n",
    "        return sequence_output\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_output = self.apply_bert(inputs)\n",
    "\n",
    "        start_logits, end_logits = self.squad_layer(seq_output)\n",
    "        \n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBmSU2RnHV_a"
   },
   "source": [
    "# Fase 4: Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnA3WHwRIHAZ"
   },
   "source": [
    "## Creación de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JEUxomxENRoJ"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_SIZE = 88641\n",
    "NB_BATCHES_TRAIN = 44000\n",
    "BATCH_SIZE = 3\n",
    "NB_EPOCHS = 3\n",
    "INIT_LR = 5e-5\n",
    "WARMUP_STEPS = int(NB_BATCHES_TRAIN * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5Pg6EKe2daFy"
   },
   "outputs": [],
   "source": [
    "train_dataset_light = train_dataset.take(NB_BATCHES_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eHd5MzTdNIZq"
   },
   "outputs": [],
   "source": [
    "bert_squad = BERTSquad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "G0cvDjBm_KXT"
   },
   "outputs": [],
   "source": [
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=INIT_LR,\n",
    "    num_train_steps=NB_BATCHES_TRAIN,\n",
    "    num_warmup_steps=WARMUP_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "I6kG-HpzVK7v"
   },
   "outputs": [],
   "source": [
    "def squad_loss_fn(labels, model_outputs):\n",
    "    start_positions = labels['start_positions']\n",
    "    end_positions = labels['end_positions']\n",
    "    start_logits, end_logits = model_outputs\n",
    "\n",
    "    start_loss = tf.keras.backend.sparse_categorical_crossentropy(\n",
    "        start_positions, start_logits, from_logits=True)\n",
    "    end_loss = tf.keras.backend.sparse_categorical_crossentropy(\n",
    "        end_positions, end_logits, from_logits=True)\n",
    "    \n",
    "    total_loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HN_C_WA5R_Cb",
    "outputId": "783e1376-0065-4189-f959-8d3f62855e25",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
       "  array([[  101,  2000,  3183,  2001,  2198,  1038,  1012,  1047,  3217,\n",
       "           2278,  2496,  1029,   102,  1996,  7437,  1038,  1012,  1047,\n",
       "           3217,  2278,  2820,  2005,  2248,  3521,  2913,  2012,  1996,\n",
       "           2118,  1997, 10289,  8214,  2003,  4056,  2000,  2470,  1010,\n",
       "           2495,  1998, 15641,  2006,  1996,  5320,  1997,  6355,  4736,\n",
       "           1998,  1996,  3785,  2005,  9084,  3521,  1012,  2009,  4107,\n",
       "           8065,  1010,  3040,  1005,  1055,  1010,  1998,  8324,  5445,\n",
       "           1999,  3521,  2913,  1012,  2009,  2001,  2631,  1999,  3069,\n",
       "           2083,  1996, 11440,  1997,  7437,  1038,  1012,  1047,  3217,\n",
       "           2278,  1010,  1996,  7794,  1997,  9383,  1005,  1055,  3954,\n",
       "           4097,  1047,  3217,  2278,  1012,  1996,  2820,  2001,  4427,\n",
       "           2011,  1996,  4432,  1997,  1996,  7065,  1012, 10117,  1049,\n",
       "           1012,  2002,  9695,  2232, 20116,  2278,  1010,  2343, 12372,\n",
       "           1997,  1996,  2118,  1997, 10289,  8214,  1012,  1996,  2820,\n",
       "           2038,  5201,  2000,  2248,  3343, 10287,  2055,  3521,  2311,\n",
       "           6078,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0]], dtype=int32)>,\n",
       "  'input_mask': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n",
       "  'input_type_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
       "  array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>},\n",
       " {'end_positions': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([93], dtype=int32)>,\n",
       "  'start_positions': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([90], dtype=int32)>})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset_light))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "V-iE2QFC_KRI"
   },
   "outputs": [],
   "source": [
    "bert_squad.compile(optimizer,\n",
    "                   squad_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "Hjp-_4OyTbuK",
    "outputId": "f85640d4-9adf-44f9-b612-5c414e085077"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/icarlos/BERT/Q&A/ckpt_bert_squad/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(bert_squad=bert_squad)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Último checkpoint restaurado!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDgEq09xIOOl"
   },
   "source": [
    "## Entrenamiento personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5ywelW3uaSbT",
    "outputId": "1c27881e-7ebe-438e-b6dd-6830bd4bcc79",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio del Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 22:08:34.447445: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Lote 0 Pérdida 6.0601\n",
      "Epoch 1 Lote 50 Pérdida 5.9680\n",
      "Epoch 1 Lote 100 Pérdida 5.9271\n",
      "Epoch 1 Lote 150 Pérdida 5.9106\n",
      "Epoch 1 Lote 200 Pérdida 5.8838\n",
      "Epoch 1 Lote 250 Pérdida 5.8429\n",
      "Epoch 1 Lote 300 Pérdida 5.7826\n",
      "Epoch 1 Lote 350 Pérdida 5.7139\n",
      "Epoch 1 Lote 400 Pérdida 5.6307\n",
      "Epoch 1 Lote 450 Pérdida 5.5336\n",
      "Epoch 1 Lote 500 Pérdida 5.4196\n",
      "Epoch 1 Lote 550 Pérdida 5.3051\n",
      "Epoch 1 Lote 600 Pérdida 5.1861\n",
      "Epoch 1 Lote 650 Pérdida 5.0797\n",
      "Epoch 1 Lote 700 Pérdida 4.9616\n",
      "Epoch 1 Lote 750 Pérdida 4.8364\n",
      "Epoch 1 Lote 800 Pérdida 4.7354\n",
      "Epoch 1 Lote 850 Pérdida 4.5974\n",
      "Epoch 1 Lote 900 Pérdida 4.4960\n",
      "Epoch 1 Lote 950 Pérdida 4.4166\n",
      "Epoch 1 Lote 1000 Pérdida 4.3473\n",
      "Epoch 1 Lote 1050 Pérdida 4.2614\n",
      "Epoch 1 Lote 1100 Pérdida 4.1880\n",
      "Epoch 1 Lote 1150 Pérdida 4.1160\n",
      "Epoch 1 Lote 1200 Pérdida 4.0581\n",
      "Epoch 1 Lote 1250 Pérdida 3.9965\n",
      "Epoch 1 Lote 1300 Pérdida 3.9571\n",
      "Epoch 1 Lote 1350 Pérdida 3.9233\n",
      "Epoch 1 Lote 1400 Pérdida 3.8766\n",
      "Epoch 1 Lote 1450 Pérdida 3.8449\n",
      "Epoch 1 Lote 1500 Pérdida 3.8059\n",
      "Epoch 1 Lote 1550 Pérdida 3.7633\n",
      "Epoch 1 Lote 1600 Pérdida 3.7050\n",
      "Epoch 1 Lote 1650 Pérdida 3.6574\n",
      "Epoch 1 Lote 1700 Pérdida 3.6102\n",
      "Epoch 1 Lote 1750 Pérdida 3.5762\n",
      "Epoch 1 Lote 1800 Pérdida 3.5440\n",
      "Epoch 1 Lote 1850 Pérdida 3.5138\n",
      "Epoch 1 Lote 1900 Pérdida 3.4788\n",
      "Epoch 1 Lote 1950 Pérdida 3.4384\n",
      "Epoch 1 Lote 2000 Pérdida 3.3961\n",
      "Epoch 1 Lote 2050 Pérdida 3.3578\n",
      "Epoch 1 Lote 2100 Pérdida 3.3336\n",
      "Epoch 1 Lote 2150 Pérdida 3.2905\n",
      "Epoch 1 Lote 2200 Pérdida 3.2628\n",
      "Epoch 1 Lote 2250 Pérdida 3.2373\n",
      "Epoch 1 Lote 2300 Pérdida 3.2075\n",
      "Epoch 1 Lote 2350 Pérdida 3.1992\n",
      "Epoch 1 Lote 2400 Pérdida 3.1797\n",
      "Epoch 1 Lote 2450 Pérdida 3.1619\n",
      "Epoch 1 Lote 2500 Pérdida 3.1418\n",
      "Epoch 1 Lote 2550 Pérdida 3.1065\n",
      "Epoch 1 Lote 2600 Pérdida 3.0996\n",
      "Epoch 1 Lote 2650 Pérdida 3.0882\n",
      "Epoch 1 Lote 2700 Pérdida 3.0624\n",
      "Epoch 1 Lote 2750 Pérdida 3.0426\n",
      "Epoch 1 Lote 2800 Pérdida 3.0255\n",
      "Epoch 1 Lote 2850 Pérdida 3.0094\n",
      "Epoch 1 Lote 2900 Pérdida 2.9972\n",
      "Epoch 1 Lote 2950 Pérdida 2.9770\n",
      "Epoch 1 Lote 3000 Pérdida 2.9572\n",
      "Epoch 1 Lote 3050 Pérdida 2.9449\n",
      "Epoch 1 Lote 3100 Pérdida 2.9332\n",
      "Epoch 1 Lote 3150 Pérdida 2.9147\n",
      "Epoch 1 Lote 3200 Pérdida 2.8983\n",
      "Epoch 1 Lote 3250 Pérdida 2.8902\n",
      "Epoch 1 Lote 3300 Pérdida 2.8851\n",
      "Epoch 1 Lote 3350 Pérdida 2.8772\n",
      "Epoch 1 Lote 3400 Pérdida 2.8687\n",
      "Epoch 1 Lote 3450 Pérdida 2.8602\n",
      "Epoch 1 Lote 3500 Pérdida 2.8436\n",
      "Epoch 1 Lote 3550 Pérdida 2.8376\n",
      "Epoch 1 Lote 3600 Pérdida 2.8236\n",
      "Epoch 1 Lote 3650 Pérdida 2.8104\n",
      "Epoch 1 Lote 3700 Pérdida 2.7925\n",
      "Epoch 1 Lote 3750 Pérdida 2.7848\n",
      "Epoch 1 Lote 3800 Pérdida 2.7814\n",
      "Epoch 1 Lote 3850 Pérdida 2.7698\n",
      "Epoch 1 Lote 3900 Pérdida 2.7600\n",
      "Epoch 1 Lote 3950 Pérdida 2.7476\n",
      "Epoch 1 Lote 4000 Pérdida 2.7324\n",
      "Epoch 1 Lote 4050 Pérdida 2.7169\n",
      "Epoch 1 Lote 4100 Pérdida 2.7053\n",
      "Epoch 1 Lote 4150 Pérdida 2.6898\n",
      "Epoch 1 Lote 4200 Pérdida 2.6838\n",
      "Epoch 1 Lote 4250 Pérdida 2.6809\n",
      "Epoch 1 Lote 4300 Pérdida 2.6719\n",
      "Epoch 1 Lote 4350 Pérdida 2.6582\n",
      "Epoch 1 Lote 4400 Pérdida 2.6491\n",
      "Epoch 1 Lote 4450 Pérdida 2.6408\n",
      "Epoch 1 Lote 4500 Pérdida 2.6278\n",
      "Epoch 1 Lote 4550 Pérdida 2.6227\n",
      "Epoch 1 Lote 4600 Pérdida 2.6121\n",
      "Epoch 1 Lote 4650 Pérdida 2.5986\n",
      "Epoch 1 Lote 4700 Pérdida 2.5970\n",
      "Epoch 1 Lote 4750 Pérdida 2.5862\n",
      "Epoch 1 Lote 4800 Pérdida 2.5823\n",
      "Epoch 1 Lote 4850 Pérdida 2.5835\n",
      "Epoch 1 Lote 4900 Pérdida 2.5782\n",
      "Epoch 1 Lote 4950 Pérdida 2.5786\n",
      "Epoch 1 Lote 5000 Pérdida 2.5803\n",
      "Epoch 1 Lote 5050 Pérdida 2.5785\n",
      "Epoch 1 Lote 5100 Pérdida 2.5715\n",
      "Epoch 1 Lote 5150 Pérdida 2.5724\n",
      "Epoch 1 Lote 5200 Pérdida 2.5695\n",
      "Epoch 1 Lote 5250 Pérdida 2.5701\n",
      "Epoch 1 Lote 5300 Pérdida 2.5657\n",
      "Epoch 1 Lote 5350 Pérdida 2.5624\n",
      "Epoch 1 Lote 5400 Pérdida 2.5578\n",
      "Epoch 1 Lote 5450 Pérdida 2.5553\n",
      "Epoch 1 Lote 5500 Pérdida 2.5520\n",
      "Epoch 1 Lote 5550 Pérdida 2.5461\n",
      "Epoch 1 Lote 5600 Pérdida 2.5407\n",
      "Epoch 1 Lote 5650 Pérdida 2.5354\n",
      "Epoch 1 Lote 5700 Pérdida 2.5286\n",
      "Epoch 1 Lote 5750 Pérdida 2.5278\n",
      "Epoch 1 Lote 5800 Pérdida 2.5189\n",
      "Epoch 1 Lote 5850 Pérdida 2.5121\n",
      "Epoch 1 Lote 5900 Pérdida 2.5064\n",
      "Epoch 1 Lote 5950 Pérdida 2.5001\n",
      "Epoch 1 Lote 6000 Pérdida 2.4973\n",
      "Epoch 1 Lote 6050 Pérdida 2.4974\n",
      "Epoch 1 Lote 6100 Pérdida 2.4928\n",
      "Epoch 1 Lote 6150 Pérdida 2.4877\n",
      "Epoch 1 Lote 6200 Pérdida 2.4842\n",
      "Epoch 1 Lote 6250 Pérdida 2.4827\n",
      "Epoch 1 Lote 6300 Pérdida 2.4816\n",
      "Epoch 1 Lote 6350 Pérdida 2.4821\n",
      "Epoch 1 Lote 6400 Pérdida 2.4786\n",
      "Epoch 1 Lote 6450 Pérdida 2.4791\n",
      "Epoch 1 Lote 6500 Pérdida 2.4780\n",
      "Epoch 1 Lote 6550 Pérdida 2.4746\n",
      "Epoch 1 Lote 6600 Pérdida 2.4726\n",
      "Epoch 1 Lote 6650 Pérdida 2.4703\n",
      "Epoch 1 Lote 6700 Pérdida 2.4673\n",
      "Epoch 1 Lote 6750 Pérdida 2.4648\n",
      "Epoch 1 Lote 6800 Pérdida 2.4632\n",
      "Epoch 1 Lote 6850 Pérdida 2.4581\n",
      "Epoch 1 Lote 6900 Pérdida 2.4557\n",
      "Epoch 1 Lote 6950 Pérdida 2.4547\n",
      "Epoch 1 Lote 7000 Pérdida 2.4517\n",
      "Epoch 1 Lote 7050 Pérdida 2.4449\n",
      "Epoch 1 Lote 7100 Pérdida 2.4437\n",
      "Epoch 1 Lote 7150 Pérdida 2.4421\n",
      "Epoch 1 Lote 7200 Pérdida 2.4386\n",
      "Epoch 1 Lote 7250 Pérdida 2.4423\n",
      "Epoch 1 Lote 7300 Pérdida 2.4389\n",
      "Epoch 1 Lote 7350 Pérdida 2.4367\n",
      "Epoch 1 Lote 7400 Pérdida 2.4258\n",
      "Epoch 1 Lote 7450 Pérdida 2.4186\n",
      "Epoch 1 Lote 7500 Pérdida 2.4120\n",
      "Epoch 1 Lote 7550 Pérdida 2.4027\n",
      "Epoch 1 Lote 7600 Pérdida 2.3981\n",
      "Epoch 1 Lote 7650 Pérdida 2.3921\n",
      "Epoch 1 Lote 7700 Pérdida 2.3878\n",
      "Epoch 1 Lote 7750 Pérdida 2.3851\n",
      "Epoch 1 Lote 7800 Pérdida 2.3810\n",
      "Epoch 1 Lote 7850 Pérdida 2.3812\n",
      "Epoch 1 Lote 7900 Pérdida 2.3807\n",
      "Epoch 1 Lote 7950 Pérdida 2.3808\n",
      "Epoch 1 Lote 8000 Pérdida 2.3809\n",
      "Epoch 1 Lote 8050 Pérdida 2.3767\n",
      "Epoch 1 Lote 8100 Pérdida 2.3749\n",
      "Epoch 1 Lote 8150 Pérdida 2.3723\n",
      "Epoch 1 Lote 8200 Pérdida 2.3665\n",
      "Epoch 1 Lote 8250 Pérdida 2.3684\n",
      "Epoch 1 Lote 8300 Pérdida 2.3688\n",
      "Epoch 1 Lote 8350 Pérdida 2.3679\n",
      "Epoch 1 Lote 8400 Pérdida 2.3642\n",
      "Epoch 1 Lote 8450 Pérdida 2.3592\n",
      "Epoch 1 Lote 8500 Pérdida 2.3542\n",
      "Epoch 1 Lote 8550 Pérdida 2.3522\n",
      "Epoch 1 Lote 8600 Pérdida 2.3494\n",
      "Epoch 1 Lote 8650 Pérdida 2.3465\n",
      "Epoch 1 Lote 8700 Pérdida 2.3428\n",
      "Epoch 1 Lote 8750 Pérdida 2.3439\n",
      "Epoch 1 Lote 8800 Pérdida 2.3470\n",
      "Epoch 1 Lote 8850 Pérdida 2.3477\n",
      "Epoch 1 Lote 8900 Pérdida 2.3475\n",
      "Epoch 1 Lote 8950 Pérdida 2.3479\n",
      "Epoch 1 Lote 9000 Pérdida 2.3482\n",
      "Epoch 1 Lote 9050 Pérdida 2.3478\n",
      "Epoch 1 Lote 9100 Pérdida 2.3458\n",
      "Epoch 1 Lote 9150 Pérdida 2.3446\n",
      "Epoch 1 Lote 9200 Pérdida 2.3394\n",
      "Epoch 1 Lote 9250 Pérdida 2.3355\n",
      "Epoch 1 Lote 9300 Pérdida 2.3323\n",
      "Epoch 1 Lote 9350 Pérdida 2.3300\n",
      "Epoch 1 Lote 9400 Pérdida 2.3259\n",
      "Epoch 1 Lote 9450 Pérdida 2.3252\n",
      "Epoch 1 Lote 9500 Pérdida 2.3221\n",
      "Epoch 1 Lote 9550 Pérdida 2.3211\n",
      "Epoch 1 Lote 9600 Pérdida 2.3187\n",
      "Epoch 1 Lote 9650 Pérdida 2.3183\n",
      "Epoch 1 Lote 9700 Pérdida 2.3161\n",
      "Epoch 1 Lote 9750 Pérdida 2.3133\n",
      "Epoch 1 Lote 9800 Pérdida 2.3090\n",
      "Epoch 1 Lote 9850 Pérdida 2.3083\n",
      "Epoch 1 Lote 9900 Pérdida 2.3049\n",
      "Epoch 1 Lote 9950 Pérdida 2.3024\n",
      "Epoch 1 Lote 10000 Pérdida 2.2990\n",
      "Epoch 1 Lote 10050 Pérdida 2.2966\n",
      "Epoch 1 Lote 10100 Pérdida 2.2928\n",
      "Epoch 1 Lote 10150 Pérdida 2.2918\n",
      "Epoch 1 Lote 10200 Pérdida 2.2905\n",
      "Epoch 1 Lote 10250 Pérdida 2.2884\n",
      "Epoch 1 Lote 10300 Pérdida 2.2876\n",
      "Epoch 1 Lote 10350 Pérdida 2.2873\n",
      "Epoch 1 Lote 10400 Pérdida 2.2875\n",
      "Epoch 1 Lote 10450 Pérdida 2.2861\n",
      "Epoch 1 Lote 10500 Pérdida 2.2852\n",
      "Epoch 1 Lote 10550 Pérdida 2.2850\n",
      "Epoch 1 Lote 10600 Pérdida 2.2832\n",
      "Epoch 1 Lote 10650 Pérdida 2.2811\n",
      "Epoch 1 Lote 10700 Pérdida 2.2794\n",
      "Epoch 1 Lote 10750 Pérdida 2.2802\n",
      "Epoch 1 Lote 10800 Pérdida 2.2801\n",
      "Epoch 1 Lote 10850 Pérdida 2.2799\n",
      "Epoch 1 Lote 10900 Pérdida 2.2807\n",
      "Epoch 1 Lote 10950 Pérdida 2.2799\n",
      "Epoch 1 Lote 11000 Pérdida 2.2787\n",
      "Epoch 1 Lote 11050 Pérdida 2.2757\n",
      "Epoch 1 Lote 11100 Pérdida 2.2762\n",
      "Epoch 1 Lote 11150 Pérdida 2.2763\n",
      "Epoch 1 Lote 11200 Pérdida 2.2752\n",
      "Epoch 1 Lote 11250 Pérdida 2.2732\n",
      "Epoch 1 Lote 11300 Pérdida 2.2732\n",
      "Epoch 1 Lote 11350 Pérdida 2.2704\n",
      "Epoch 1 Lote 11400 Pérdida 2.2710\n",
      "Epoch 1 Lote 11450 Pérdida 2.2699\n",
      "Epoch 1 Lote 11500 Pérdida 2.2682\n",
      "Epoch 1 Lote 11550 Pérdida 2.2651\n",
      "Epoch 1 Lote 11600 Pérdida 2.2599\n",
      "Epoch 1 Lote 11650 Pérdida 2.2561\n",
      "Epoch 1 Lote 11700 Pérdida 2.2534\n",
      "Epoch 1 Lote 11750 Pérdida 2.2487\n",
      "Epoch 1 Lote 11800 Pérdida 2.2469\n",
      "Epoch 1 Lote 11850 Pérdida 2.2441\n",
      "Epoch 1 Lote 11900 Pérdida 2.2440\n",
      "Epoch 1 Lote 11950 Pérdida 2.2410\n",
      "Epoch 1 Lote 12000 Pérdida 2.2390\n",
      "Epoch 1 Lote 12050 Pérdida 2.2363\n",
      "Epoch 1 Lote 12100 Pérdida 2.2341\n",
      "Epoch 1 Lote 12150 Pérdida 2.2354\n",
      "Epoch 1 Lote 12200 Pérdida 2.2337\n",
      "Epoch 1 Lote 12250 Pérdida 2.2316\n",
      "Epoch 1 Lote 12300 Pérdida 2.2284\n",
      "Epoch 1 Lote 12350 Pérdida 2.2252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Lote 12400 Pérdida 2.2235\n",
      "Epoch 1 Lote 12450 Pérdida 2.2204\n",
      "Epoch 1 Lote 12500 Pérdida 2.2191\n",
      "Epoch 1 Lote 12550 Pérdida 2.2198\n",
      "Epoch 1 Lote 12600 Pérdida 2.2178\n",
      "Epoch 1 Lote 12650 Pérdida 2.2171\n",
      "Epoch 1 Lote 12700 Pérdida 2.2152\n",
      "Epoch 1 Lote 12750 Pérdida 2.2117\n",
      "Epoch 1 Lote 12800 Pérdida 2.2107\n",
      "Epoch 1 Lote 12850 Pérdida 2.2116\n",
      "Epoch 1 Lote 12900 Pérdida 2.2084\n",
      "Epoch 1 Lote 12950 Pérdida 2.2045\n",
      "Epoch 1 Lote 13000 Pérdida 2.2030\n",
      "Epoch 1 Lote 13050 Pérdida 2.1996\n",
      "Epoch 1 Lote 13100 Pérdida 2.1979\n",
      "Epoch 1 Lote 13150 Pérdida 2.1981\n",
      "Epoch 1 Lote 13200 Pérdida 2.1968\n",
      "Epoch 1 Lote 13250 Pérdida 2.1949\n",
      "Epoch 1 Lote 13300 Pérdida 2.1934\n",
      "Epoch 1 Lote 13350 Pérdida 2.1920\n",
      "Epoch 1 Lote 13400 Pérdida 2.1888\n",
      "Epoch 1 Lote 13450 Pérdida 2.1853\n",
      "Epoch 1 Lote 13500 Pérdida 2.1834\n",
      "Epoch 1 Lote 13550 Pérdida 2.1828\n",
      "Epoch 1 Lote 13600 Pérdida 2.1809\n",
      "Epoch 1 Lote 13650 Pérdida 2.1803\n",
      "Epoch 1 Lote 13700 Pérdida 2.1797\n",
      "Epoch 1 Lote 13750 Pérdida 2.1757\n",
      "Epoch 1 Lote 13800 Pérdida 2.1750\n",
      "Epoch 1 Lote 13850 Pérdida 2.1731\n",
      "Epoch 1 Lote 13900 Pérdida 2.1730\n",
      "Epoch 1 Lote 13950 Pérdida 2.1733\n",
      "Epoch 1 Lote 14000 Pérdida 2.1717\n",
      "Epoch 1 Lote 14050 Pérdida 2.1707\n",
      "Epoch 1 Lote 14100 Pérdida 2.1682\n",
      "Epoch 1 Lote 14150 Pérdida 2.1672\n",
      "Epoch 1 Lote 14200 Pérdida 2.1676\n",
      "Epoch 1 Lote 14250 Pérdida 2.1675\n",
      "Epoch 1 Lote 14300 Pérdida 2.1636\n",
      "Epoch 1 Lote 14350 Pérdida 2.1608\n",
      "Epoch 1 Lote 14400 Pérdida 2.1588\n",
      "Epoch 1 Lote 14450 Pérdida 2.1552\n",
      "Epoch 1 Lote 14500 Pérdida 2.1523\n",
      "Epoch 1 Lote 14550 Pérdida 2.1502\n",
      "Epoch 1 Lote 14600 Pérdida 2.1474\n",
      "Epoch 1 Lote 14650 Pérdida 2.1472\n",
      "Epoch 1 Lote 14700 Pérdida 2.1454\n",
      "Epoch 1 Lote 14750 Pérdida 2.1435\n",
      "Epoch 1 Lote 14800 Pérdida 2.1420\n",
      "Epoch 1 Lote 14850 Pérdida 2.1408\n",
      "Epoch 1 Lote 14900 Pérdida 2.1396\n",
      "Epoch 1 Lote 14950 Pérdida 2.1388\n",
      "Epoch 1 Lote 15000 Pérdida 2.1373\n",
      "Epoch 1 Lote 15050 Pérdida 2.1356\n",
      "Epoch 1 Lote 15100 Pérdida 2.1348\n",
      "Epoch 1 Lote 15150 Pérdida 2.1358\n",
      "Epoch 1 Lote 15200 Pérdida 2.1329\n",
      "Epoch 1 Lote 15250 Pérdida 2.1306\n",
      "Epoch 1 Lote 15300 Pérdida 2.1300\n",
      "Epoch 1 Lote 15350 Pérdida 2.1306\n",
      "Epoch 1 Lote 15400 Pérdida 2.1272\n",
      "Epoch 1 Lote 15450 Pérdida 2.1271\n",
      "Epoch 1 Lote 15500 Pérdida 2.1263\n",
      "Epoch 1 Lote 15550 Pérdida 2.1254\n",
      "Epoch 1 Lote 15600 Pérdida 2.1223\n",
      "Epoch 1 Lote 15650 Pérdida 2.1235\n",
      "Epoch 1 Lote 15700 Pérdida 2.1217\n",
      "Epoch 1 Lote 15750 Pérdida 2.1206\n",
      "Epoch 1 Lote 15800 Pérdida 2.1202\n",
      "Epoch 1 Lote 15850 Pérdida 2.1200\n",
      "Epoch 1 Lote 15900 Pérdida 2.1185\n",
      "Epoch 1 Lote 15950 Pérdida 2.1157\n",
      "Epoch 1 Lote 16000 Pérdida 2.1152\n",
      "Epoch 1 Lote 16050 Pérdida 2.1148\n",
      "Epoch 1 Lote 16100 Pérdida 2.1141\n",
      "Epoch 1 Lote 16150 Pérdida 2.1149\n",
      "Epoch 1 Lote 16200 Pérdida 2.1149\n",
      "Epoch 1 Lote 16250 Pérdida 2.1138\n",
      "Epoch 1 Lote 16300 Pérdida 2.1140\n",
      "Epoch 1 Lote 16350 Pérdida 2.1117\n",
      "Epoch 1 Lote 16400 Pérdida 2.1097\n",
      "Epoch 1 Lote 16450 Pérdida 2.1095\n",
      "Epoch 1 Lote 16500 Pérdida 2.1073\n",
      "Epoch 1 Lote 16550 Pérdida 2.1067\n",
      "Epoch 1 Lote 16600 Pérdida 2.1056\n",
      "Epoch 1 Lote 16650 Pérdida 2.1038\n",
      "Epoch 1 Lote 16700 Pérdida 2.1019\n",
      "Epoch 1 Lote 16750 Pérdida 2.1009\n",
      "Epoch 1 Lote 16800 Pérdida 2.1003\n",
      "Epoch 1 Lote 16850 Pérdida 2.0979\n",
      "Epoch 1 Lote 16900 Pérdida 2.0950\n",
      "Epoch 1 Lote 16950 Pérdida 2.0937\n",
      "Epoch 1 Lote 17000 Pérdida 2.0927\n",
      "Epoch 1 Lote 17050 Pérdida 2.0914\n",
      "Epoch 1 Lote 17100 Pérdida 2.0909\n",
      "Epoch 1 Lote 17150 Pérdida 2.0904\n",
      "Epoch 1 Lote 17200 Pérdida 2.0895\n",
      "Epoch 1 Lote 17250 Pérdida 2.0871\n",
      "Epoch 1 Lote 17300 Pérdida 2.0869\n",
      "Epoch 1 Lote 17350 Pérdida 2.0851\n",
      "Epoch 1 Lote 17400 Pérdida 2.0834\n",
      "Epoch 1 Lote 17450 Pérdida 2.0843\n",
      "Epoch 1 Lote 17500 Pérdida 2.0826\n",
      "Epoch 1 Lote 17550 Pérdida 2.0809\n",
      "Epoch 1 Lote 17600 Pérdida 2.0796\n",
      "Epoch 1 Lote 17650 Pérdida 2.0779\n",
      "Epoch 1 Lote 17700 Pérdida 2.0783\n",
      "Epoch 1 Lote 17750 Pérdida 2.0771\n",
      "Epoch 1 Lote 17800 Pérdida 2.0756\n",
      "Epoch 1 Lote 17850 Pérdida 2.0751\n",
      "Epoch 1 Lote 17900 Pérdida 2.0734\n",
      "Epoch 1 Lote 17950 Pérdida 2.0739\n",
      "Epoch 1 Lote 18000 Pérdida 2.0716\n",
      "Epoch 1 Lote 18050 Pérdida 2.0704\n",
      "Epoch 1 Lote 18100 Pérdida 2.0685\n",
      "Epoch 1 Lote 18150 Pérdida 2.0684\n",
      "Epoch 1 Lote 18200 Pérdida 2.0669\n",
      "Epoch 1 Lote 18250 Pérdida 2.0657\n",
      "Epoch 1 Lote 18300 Pérdida 2.0650\n",
      "Epoch 1 Lote 18350 Pérdida 2.0640\n",
      "Epoch 1 Lote 18400 Pérdida 2.0637\n",
      "Epoch 1 Lote 18450 Pérdida 2.0626\n",
      "Epoch 1 Lote 18500 Pérdida 2.0617\n",
      "Epoch 1 Lote 18550 Pérdida 2.0613\n",
      "Epoch 1 Lote 18600 Pérdida 2.0611\n",
      "Epoch 1 Lote 18650 Pérdida 2.0593\n",
      "Epoch 1 Lote 18700 Pérdida 2.0579\n",
      "Epoch 1 Lote 18750 Pérdida 2.0570\n",
      "Epoch 1 Lote 18800 Pérdida 2.0545\n",
      "Epoch 1 Lote 18850 Pérdida 2.0528\n",
      "Epoch 1 Lote 18900 Pérdida 2.0514\n",
      "Epoch 1 Lote 18950 Pérdida 2.0496\n",
      "Epoch 1 Lote 19000 Pérdida 2.0478\n",
      "Epoch 1 Lote 19050 Pérdida 2.0456\n",
      "Epoch 1 Lote 19100 Pérdida 2.0426\n",
      "Epoch 1 Lote 19150 Pérdida 2.0402\n",
      "Epoch 1 Lote 19200 Pérdida 2.0386\n",
      "Epoch 1 Lote 19250 Pérdida 2.0354\n",
      "Epoch 1 Lote 19300 Pérdida 2.0326\n",
      "Epoch 1 Lote 19350 Pérdida 2.0306\n",
      "Epoch 1 Lote 19400 Pérdida 2.0274\n",
      "Epoch 1 Lote 19450 Pérdida 2.0254\n",
      "Epoch 1 Lote 19500 Pérdida 2.0246\n",
      "Epoch 1 Lote 19550 Pérdida 2.0233\n",
      "Epoch 1 Lote 19600 Pérdida 2.0244\n",
      "Epoch 1 Lote 19650 Pérdida 2.0219\n",
      "Epoch 1 Lote 19700 Pérdida 2.0206\n",
      "Epoch 1 Lote 19750 Pérdida 2.0202\n",
      "Epoch 1 Lote 19800 Pérdida 2.0189\n",
      "Epoch 1 Lote 19850 Pérdida 2.0182\n",
      "Epoch 1 Lote 19900 Pérdida 2.0182\n",
      "Epoch 1 Lote 19950 Pérdida 2.0173\n",
      "Epoch 1 Lote 20000 Pérdida 2.0158\n",
      "Epoch 1 Lote 20050 Pérdida 2.0156\n",
      "Epoch 1 Lote 20100 Pérdida 2.0135\n",
      "Epoch 1 Lote 20150 Pérdida 2.0117\n",
      "Epoch 1 Lote 20200 Pérdida 2.0094\n",
      "Epoch 1 Lote 20250 Pérdida 2.0077\n",
      "Epoch 1 Lote 20300 Pérdida 2.0068\n",
      "Epoch 1 Lote 20350 Pérdida 2.0064\n",
      "Epoch 1 Lote 20400 Pérdida 2.0071\n",
      "Epoch 1 Lote 20450 Pérdida 2.0067\n",
      "Epoch 1 Lote 20500 Pérdida 2.0071\n",
      "Epoch 1 Lote 20550 Pérdida 2.0075\n",
      "Epoch 1 Lote 20600 Pérdida 2.0073\n",
      "Epoch 1 Lote 20650 Pérdida 2.0065\n",
      "Epoch 1 Lote 20700 Pérdida 2.0054\n",
      "Epoch 1 Lote 20750 Pérdida 2.0041\n",
      "Epoch 1 Lote 20800 Pérdida 2.0041\n",
      "Epoch 1 Lote 20850 Pérdida 2.0025\n",
      "Epoch 1 Lote 20900 Pérdida 2.0007\n",
      "Epoch 1 Lote 20950 Pérdida 1.9979\n",
      "Epoch 1 Lote 21000 Pérdida 1.9955\n",
      "Epoch 1 Lote 21050 Pérdida 1.9945\n",
      "Epoch 1 Lote 21100 Pérdida 1.9916\n",
      "Epoch 1 Lote 21150 Pérdida 1.9906\n",
      "Epoch 1 Lote 21200 Pérdida 1.9893\n",
      "Epoch 1 Lote 21250 Pérdida 1.9878\n",
      "Epoch 1 Lote 21300 Pérdida 1.9875\n",
      "Epoch 1 Lote 21350 Pérdida 1.9857\n",
      "Epoch 1 Lote 21400 Pérdida 1.9840\n",
      "Epoch 1 Lote 21450 Pérdida 1.9819\n",
      "Epoch 1 Lote 21500 Pérdida 1.9807\n",
      "Epoch 1 Lote 21550 Pérdida 1.9789\n",
      "Epoch 1 Lote 21600 Pérdida 1.9772\n",
      "Epoch 1 Lote 21650 Pérdida 1.9753\n",
      "Epoch 1 Lote 21700 Pérdida 1.9731\n",
      "Epoch 1 Lote 21750 Pérdida 1.9717\n",
      "Epoch 1 Lote 21800 Pérdida 1.9705\n",
      "Epoch 1 Lote 21850 Pérdida 1.9697\n",
      "Epoch 1 Lote 21900 Pérdida 1.9683\n",
      "Epoch 1 Lote 21950 Pérdida 1.9688\n",
      "Epoch 1 Lote 22000 Pérdida 1.9680\n",
      "Epoch 1 Lote 22050 Pérdida 1.9669\n",
      "Epoch 1 Lote 22100 Pérdida 1.9653\n",
      "Epoch 1 Lote 22150 Pérdida 1.9632\n",
      "Epoch 1 Lote 22200 Pérdida 1.9621\n",
      "Epoch 1 Lote 22250 Pérdida 1.9606\n",
      "Epoch 1 Lote 22300 Pérdida 1.9598\n",
      "Epoch 1 Lote 22350 Pérdida 1.9581\n",
      "Epoch 1 Lote 22400 Pérdida 1.9566\n",
      "Epoch 1 Lote 22450 Pérdida 1.9546\n",
      "Epoch 1 Lote 22500 Pérdida 1.9533\n",
      "Epoch 1 Lote 22550 Pérdida 1.9523\n",
      "Epoch 1 Lote 22600 Pérdida 1.9501\n",
      "Epoch 1 Lote 22650 Pérdida 1.9488\n",
      "Epoch 1 Lote 22700 Pérdida 1.9465\n",
      "Epoch 1 Lote 22750 Pérdida 1.9457\n",
      "Epoch 1 Lote 22800 Pérdida 1.9448\n",
      "Epoch 1 Lote 22850 Pérdida 1.9451\n",
      "Epoch 1 Lote 22900 Pérdida 1.9444\n",
      "Epoch 1 Lote 22950 Pérdida 1.9434\n",
      "Epoch 1 Lote 23000 Pérdida 1.9421\n",
      "Epoch 1 Lote 23050 Pérdida 1.9409\n",
      "Epoch 1 Lote 23100 Pérdida 1.9393\n",
      "Epoch 1 Lote 23150 Pérdida 1.9387\n",
      "Epoch 1 Lote 23200 Pérdida 1.9386\n",
      "Epoch 1 Lote 23250 Pérdida 1.9371\n",
      "Epoch 1 Lote 23300 Pérdida 1.9372\n",
      "Epoch 1 Lote 23350 Pérdida 1.9348\n",
      "Epoch 1 Lote 23400 Pérdida 1.9336\n",
      "Epoch 1 Lote 23450 Pérdida 1.9326\n",
      "Epoch 1 Lote 23500 Pérdida 1.9315\n",
      "Epoch 1 Lote 23550 Pérdida 1.9308\n",
      "Epoch 1 Lote 23600 Pérdida 1.9300\n",
      "Epoch 1 Lote 23650 Pérdida 1.9278\n",
      "Epoch 1 Lote 23700 Pérdida 1.9272\n",
      "Epoch 1 Lote 23750 Pérdida 1.9260\n",
      "Epoch 1 Lote 23800 Pérdida 1.9251\n",
      "Epoch 1 Lote 23850 Pérdida 1.9233\n",
      "Epoch 1 Lote 23900 Pérdida 1.9225\n",
      "Epoch 1 Lote 23950 Pérdida 1.9220\n",
      "Epoch 1 Lote 24000 Pérdida 1.9202\n",
      "Epoch 1 Lote 24050 Pérdida 1.9188\n",
      "Epoch 1 Lote 24100 Pérdida 1.9191\n",
      "Epoch 1 Lote 24150 Pérdida 1.9195\n",
      "Epoch 1 Lote 24200 Pérdida 1.9196\n",
      "Epoch 1 Lote 24250 Pérdida 1.9198\n",
      "Epoch 1 Lote 24300 Pérdida 1.9194\n",
      "Epoch 1 Lote 24350 Pérdida 1.9193\n",
      "Epoch 1 Lote 24400 Pérdida 1.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Lote 24450 Pérdida 1.9198\n",
      "Epoch 1 Lote 24500 Pérdida 1.9189\n",
      "Epoch 1 Lote 24550 Pérdida 1.9187\n",
      "Epoch 1 Lote 24600 Pérdida 1.9181\n",
      "Epoch 1 Lote 24650 Pérdida 1.9170\n",
      "Epoch 1 Lote 24700 Pérdida 1.9163\n",
      "Epoch 1 Lote 24750 Pérdida 1.9148\n",
      "Epoch 1 Lote 24800 Pérdida 1.9141\n",
      "Epoch 1 Lote 24850 Pérdida 1.9128\n",
      "Epoch 1 Lote 24900 Pérdida 1.9110\n",
      "Epoch 1 Lote 24950 Pérdida 1.9098\n",
      "Epoch 1 Lote 25000 Pérdida 1.9078\n",
      "Epoch 1 Lote 25050 Pérdida 1.9065\n",
      "Epoch 1 Lote 25100 Pérdida 1.9057\n",
      "Epoch 1 Lote 25150 Pérdida 1.9049\n",
      "Epoch 1 Lote 25200 Pérdida 1.9059\n",
      "Epoch 1 Lote 25250 Pérdida 1.9049\n",
      "Epoch 1 Lote 25300 Pérdida 1.9037\n",
      "Epoch 1 Lote 25350 Pérdida 1.9026\n",
      "Epoch 1 Lote 25400 Pérdida 1.9011\n",
      "Epoch 1 Lote 25450 Pérdida 1.8996\n",
      "Epoch 1 Lote 25500 Pérdida 1.8987\n",
      "Epoch 1 Lote 25550 Pérdida 1.8984\n",
      "Epoch 1 Lote 25600 Pérdida 1.8977\n",
      "Epoch 1 Lote 25650 Pérdida 1.8969\n",
      "Epoch 1 Lote 25700 Pérdida 1.8948\n",
      "Epoch 1 Lote 25750 Pérdida 1.8952\n",
      "Epoch 1 Lote 25800 Pérdida 1.8946\n",
      "Epoch 1 Lote 25850 Pérdida 1.8944\n",
      "Epoch 1 Lote 25900 Pérdida 1.8934\n",
      "Epoch 1 Lote 25950 Pérdida 1.8921\n",
      "Epoch 1 Lote 26000 Pérdida 1.8906\n",
      "Epoch 1 Lote 26050 Pérdida 1.8900\n",
      "Epoch 1 Lote 26100 Pérdida 1.8892\n",
      "Epoch 1 Lote 26150 Pérdida 1.8883\n",
      "Epoch 1 Lote 26200 Pérdida 1.8866\n",
      "Epoch 1 Lote 26250 Pérdida 1.8853\n",
      "Epoch 1 Lote 26300 Pérdida 1.8839\n",
      "Epoch 1 Lote 26350 Pérdida 1.8815\n",
      "Epoch 1 Lote 26400 Pérdida 1.8799\n",
      "Epoch 1 Lote 26450 Pérdida 1.8783\n",
      "Epoch 1 Lote 26500 Pérdida 1.8772\n",
      "Epoch 1 Lote 26550 Pérdida 1.8763\n",
      "Epoch 1 Lote 26600 Pérdida 1.8750\n",
      "Epoch 1 Lote 26650 Pérdida 1.8741\n",
      "Epoch 1 Lote 26700 Pérdida 1.8734\n",
      "Epoch 1 Lote 26750 Pérdida 1.8717\n",
      "Epoch 1 Lote 26800 Pérdida 1.8706\n",
      "Epoch 1 Lote 26850 Pérdida 1.8691\n",
      "Epoch 1 Lote 26900 Pérdida 1.8691\n",
      "Epoch 1 Lote 26950 Pérdida 1.8689\n",
      "Epoch 1 Lote 27000 Pérdida 1.8684\n",
      "Epoch 1 Lote 27050 Pérdida 1.8667\n",
      "Epoch 1 Lote 27100 Pérdida 1.8657\n",
      "Epoch 1 Lote 27150 Pérdida 1.8649\n",
      "Epoch 1 Lote 27200 Pérdida 1.8647\n",
      "Epoch 1 Lote 27250 Pérdida 1.8638\n",
      "Epoch 1 Lote 27300 Pérdida 1.8624\n",
      "Epoch 1 Lote 27350 Pérdida 1.8617\n",
      "Epoch 1 Lote 27400 Pérdida 1.8614\n",
      "Epoch 1 Lote 27450 Pérdida 1.8614\n",
      "Epoch 1 Lote 27500 Pérdida 1.8610\n",
      "Epoch 1 Lote 27550 Pérdida 1.8600\n",
      "Epoch 1 Lote 27600 Pérdida 1.8599\n",
      "Epoch 1 Lote 27650 Pérdida 1.8583\n",
      "Epoch 1 Lote 27700 Pérdida 1.8569\n",
      "Epoch 1 Lote 27750 Pérdida 1.8564\n",
      "Epoch 1 Lote 27800 Pérdida 1.8566\n",
      "Epoch 1 Lote 27850 Pérdida 1.8567\n",
      "Epoch 1 Lote 27900 Pérdida 1.8553\n",
      "Epoch 1 Lote 27950 Pérdida 1.8551\n",
      "Epoch 1 Lote 28000 Pérdida 1.8543\n",
      "Epoch 1 Lote 28050 Pérdida 1.8534\n",
      "Epoch 1 Lote 28100 Pérdida 1.8526\n",
      "Epoch 1 Lote 28150 Pérdida 1.8516\n",
      "Epoch 1 Lote 28200 Pérdida 1.8518\n",
      "Epoch 1 Lote 28250 Pérdida 1.8512\n",
      "Epoch 1 Lote 28300 Pérdida 1.8501\n",
      "Epoch 1 Lote 28350 Pérdida 1.8488\n",
      "Epoch 1 Lote 28400 Pérdida 1.8480\n",
      "Epoch 1 Lote 28450 Pérdida 1.8476\n",
      "Epoch 1 Lote 28500 Pérdida 1.8469\n",
      "Epoch 1 Lote 28550 Pérdida 1.8455\n",
      "Epoch 1 Lote 28600 Pérdida 1.8443\n",
      "Epoch 1 Lote 28650 Pérdida 1.8433\n",
      "Epoch 1 Lote 28700 Pérdida 1.8423\n",
      "Epoch 1 Lote 28750 Pérdida 1.8415\n",
      "Epoch 1 Lote 28800 Pérdida 1.8410\n",
      "Epoch 1 Lote 28850 Pérdida 1.8405\n",
      "Epoch 1 Lote 28900 Pérdida 1.8394\n",
      "Epoch 1 Lote 28950 Pérdida 1.8385\n",
      "Epoch 1 Lote 29000 Pérdida 1.8388\n",
      "Epoch 1 Lote 29050 Pérdida 1.8374\n",
      "Epoch 1 Lote 29100 Pérdida 1.8364\n",
      "Epoch 1 Lote 29150 Pérdida 1.8356\n",
      "Epoch 1 Lote 29200 Pérdida 1.8346\n",
      "Epoch 1 Lote 29250 Pérdida 1.8339\n",
      "Epoch 1 Lote 29300 Pérdida 1.8321\n",
      "Epoch 1 Lote 29350 Pérdida 1.8313\n",
      "Epoch 1 Lote 29400 Pérdida 1.8312\n",
      "Epoch 1 Lote 29450 Pérdida 1.8310\n",
      "Epoch 1 Lote 29500 Pérdida 1.8307\n",
      "Epoch 1 Lote 29550 Pérdida 1.8304\n",
      "Epoch 1 Lote 29600 Pérdida 1.8301\n",
      "Epoch 1 Lote 29650 Pérdida 1.8300\n",
      "Epoch 1 Lote 29700 Pérdida 1.8298\n",
      "Epoch 1 Lote 29750 Pérdida 1.8302\n",
      "Epoch 1 Lote 29800 Pérdida 1.8299\n",
      "Epoch 1 Lote 29850 Pérdida 1.8302\n",
      "Epoch 1 Lote 29900 Pérdida 1.8292\n",
      "Epoch 1 Lote 29950 Pérdida 1.8288\n",
      "Epoch 1 Lote 30000 Pérdida 1.8279\n",
      "Epoch 1 Lote 30050 Pérdida 1.8273\n",
      "Epoch 1 Lote 30100 Pérdida 1.8265\n",
      "Epoch 1 Lote 30150 Pérdida 1.8252\n",
      "Epoch 1 Lote 30200 Pérdida 1.8245\n",
      "Epoch 1 Lote 30250 Pérdida 1.8241\n",
      "Epoch 1 Lote 30300 Pérdida 1.8228\n",
      "Epoch 1 Lote 30350 Pérdida 1.8227\n",
      "Epoch 1 Lote 30400 Pérdida 1.8215\n",
      "Epoch 1 Lote 30450 Pérdida 1.8213\n",
      "Epoch 1 Lote 30500 Pérdida 1.8216\n",
      "Epoch 1 Lote 30550 Pérdida 1.8212\n",
      "Epoch 1 Lote 30600 Pérdida 1.8202\n",
      "Epoch 1 Lote 30650 Pérdida 1.8196\n",
      "Epoch 1 Lote 30700 Pérdida 1.8202\n",
      "Epoch 1 Lote 30750 Pérdida 1.8204\n",
      "Epoch 1 Lote 30800 Pérdida 1.8201\n",
      "Epoch 1 Lote 30850 Pérdida 1.8191\n",
      "Epoch 1 Lote 30900 Pérdida 1.8184\n",
      "Epoch 1 Lote 30950 Pérdida 1.8183\n",
      "Epoch 1 Lote 31000 Pérdida 1.8171\n",
      "Epoch 1 Lote 31050 Pérdida 1.8165\n",
      "Epoch 1 Lote 31100 Pérdida 1.8174\n",
      "Epoch 1 Lote 31150 Pérdida 1.8170\n",
      "Epoch 1 Lote 31200 Pérdida 1.8160\n",
      "Epoch 1 Lote 31250 Pérdida 1.8154\n",
      "Epoch 1 Lote 31300 Pérdida 1.8155\n",
      "Epoch 1 Lote 31350 Pérdida 1.8146\n",
      "Epoch 1 Lote 31400 Pérdida 1.8147\n",
      "Epoch 1 Lote 31450 Pérdida 1.8145\n",
      "Epoch 1 Lote 31500 Pérdida 1.8128\n",
      "Epoch 1 Lote 31550 Pérdida 1.8120\n",
      "Epoch 1 Lote 31600 Pérdida 1.8111\n",
      "Epoch 1 Lote 31650 Pérdida 1.8107\n",
      "Epoch 1 Lote 31700 Pérdida 1.8101\n",
      "Epoch 1 Lote 31750 Pérdida 1.8086\n",
      "Epoch 1 Lote 31800 Pérdida 1.8070\n",
      "Epoch 1 Lote 31850 Pérdida 1.8061\n",
      "Epoch 1 Lote 31900 Pérdida 1.8040\n",
      "Epoch 1 Lote 31950 Pérdida 1.8027\n",
      "Epoch 1 Lote 32000 Pérdida 1.8014\n",
      "Epoch 1 Lote 32050 Pérdida 1.8004\n",
      "Epoch 1 Lote 32100 Pérdida 1.7982\n",
      "Epoch 1 Lote 32150 Pérdida 1.7972\n",
      "Epoch 1 Lote 32200 Pérdida 1.7961\n",
      "Epoch 1 Lote 32250 Pérdida 1.7951\n",
      "Epoch 1 Lote 32300 Pérdida 1.7943\n",
      "Epoch 1 Lote 32350 Pérdida 1.7934\n",
      "Epoch 1 Lote 32400 Pérdida 1.7930\n",
      "Epoch 1 Lote 32450 Pérdida 1.7924\n",
      "Epoch 1 Lote 32500 Pérdida 1.7916\n",
      "Epoch 1 Lote 32550 Pérdida 1.7912\n",
      "Epoch 1 Lote 32600 Pérdida 1.7908\n",
      "Epoch 1 Lote 32650 Pérdida 1.7898\n",
      "Epoch 1 Lote 32700 Pérdida 1.7893\n",
      "Epoch 1 Lote 32750 Pérdida 1.7881\n",
      "Epoch 1 Lote 32800 Pérdida 1.7872\n",
      "Epoch 1 Lote 32850 Pérdida 1.7870\n",
      "Epoch 1 Lote 32900 Pérdida 1.7868\n",
      "Epoch 1 Lote 32950 Pérdida 1.7864\n",
      "Epoch 1 Lote 33000 Pérdida 1.7856\n",
      "Epoch 1 Lote 33050 Pérdida 1.7848\n",
      "Epoch 1 Lote 33100 Pérdida 1.7839\n",
      "Epoch 1 Lote 33150 Pérdida 1.7833\n",
      "Epoch 1 Lote 33200 Pérdida 1.7823\n",
      "Epoch 1 Lote 33250 Pérdida 1.7811\n",
      "Epoch 1 Lote 33300 Pérdida 1.7793\n",
      "Epoch 1 Lote 33350 Pérdida 1.7775\n",
      "Epoch 1 Lote 33400 Pérdida 1.7766\n",
      "Epoch 1 Lote 33450 Pérdida 1.7756\n",
      "Epoch 1 Lote 33500 Pérdida 1.7754\n",
      "Epoch 1 Lote 33550 Pérdida 1.7741\n",
      "Epoch 1 Lote 33600 Pérdida 1.7727\n",
      "Epoch 1 Lote 33650 Pérdida 1.7722\n",
      "Epoch 1 Lote 33700 Pérdida 1.7711\n",
      "Epoch 1 Lote 33750 Pérdida 1.7699\n",
      "Epoch 1 Lote 33800 Pérdida 1.7696\n",
      "Epoch 1 Lote 33850 Pérdida 1.7697\n",
      "Epoch 1 Lote 33900 Pérdida 1.7700\n",
      "Epoch 1 Lote 33950 Pérdida 1.7685\n",
      "Epoch 1 Lote 34000 Pérdida 1.7679\n",
      "Epoch 1 Lote 34050 Pérdida 1.7669\n",
      "Epoch 1 Lote 34100 Pérdida 1.7654\n",
      "Epoch 1 Lote 34150 Pérdida 1.7650\n",
      "Epoch 1 Lote 34200 Pérdida 1.7640\n",
      "Epoch 1 Lote 34250 Pérdida 1.7637\n",
      "Epoch 1 Lote 34300 Pérdida 1.7635\n",
      "Epoch 1 Lote 34350 Pérdida 1.7627\n",
      "Epoch 1 Lote 34400 Pérdida 1.7621\n",
      "Epoch 1 Lote 34450 Pérdida 1.7616\n",
      "Epoch 1 Lote 34500 Pérdida 1.7619\n",
      "Epoch 1 Lote 34550 Pérdida 1.7616\n",
      "Epoch 1 Lote 34600 Pérdida 1.7604\n",
      "Epoch 1 Lote 34650 Pérdida 1.7602\n",
      "Epoch 1 Lote 34700 Pérdida 1.7602\n",
      "Epoch 1 Lote 34750 Pérdida 1.7601\n",
      "Epoch 1 Lote 34800 Pérdida 1.7601\n",
      "Epoch 1 Lote 34850 Pérdida 1.7601\n",
      "Epoch 1 Lote 34900 Pérdida 1.7609\n",
      "Epoch 1 Lote 34950 Pérdida 1.7616\n",
      "Epoch 1 Lote 35000 Pérdida 1.7623\n",
      "Epoch 1 Lote 35050 Pérdida 1.7624\n",
      "Epoch 1 Lote 35100 Pérdida 1.7634\n",
      "Epoch 1 Lote 35150 Pérdida 1.7633\n",
      "Epoch 1 Lote 35200 Pérdida 1.7623\n",
      "Epoch 1 Lote 35250 Pérdida 1.7612\n",
      "Epoch 1 Lote 35300 Pérdida 1.7598\n",
      "Epoch 1 Lote 35350 Pérdida 1.7593\n",
      "Epoch 1 Lote 35400 Pérdida 1.7579\n",
      "Epoch 1 Lote 35450 Pérdida 1.7567\n",
      "Epoch 1 Lote 35500 Pérdida 1.7556\n",
      "Epoch 1 Lote 35550 Pérdida 1.7549\n",
      "Epoch 1 Lote 35600 Pérdida 1.7538\n",
      "Epoch 1 Lote 35650 Pérdida 1.7529\n",
      "Epoch 1 Lote 35700 Pérdida 1.7525\n",
      "Epoch 1 Lote 35750 Pérdida 1.7519\n",
      "Epoch 1 Lote 35800 Pérdida 1.7516\n",
      "Epoch 1 Lote 35850 Pérdida 1.7516\n",
      "Epoch 1 Lote 35900 Pérdida 1.7507\n",
      "Epoch 1 Lote 35950 Pérdida 1.7502\n",
      "Epoch 1 Lote 36000 Pérdida 1.7511\n",
      "Epoch 1 Lote 36050 Pérdida 1.7519\n",
      "Epoch 1 Lote 36100 Pérdida 1.7532\n",
      "Epoch 1 Lote 36150 Pérdida 1.7541\n",
      "Epoch 1 Lote 36200 Pérdida 1.7537\n",
      "Epoch 1 Lote 36250 Pérdida 1.7535\n",
      "Epoch 1 Lote 36300 Pérdida 1.7537\n",
      "Epoch 1 Lote 36350 Pérdida 1.7537\n",
      "Epoch 1 Lote 36400 Pérdida 1.7539\n",
      "Epoch 1 Lote 36450 Pérdida 1.7551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Lote 36500 Pérdida 1.7564\n",
      "Epoch 1 Lote 36550 Pérdida 1.7575\n",
      "Epoch 1 Lote 36600 Pérdida 1.7580\n",
      "Epoch 1 Lote 36650 Pérdida 1.7589\n",
      "Epoch 1 Lote 36700 Pérdida 1.7603\n",
      "Epoch 1 Lote 36750 Pérdida 1.7601\n",
      "Epoch 1 Lote 36800 Pérdida 1.7597\n",
      "Epoch 1 Lote 36850 Pérdida 1.7589\n",
      "Epoch 1 Lote 36900 Pérdida 1.7582\n",
      "Epoch 1 Lote 36950 Pérdida 1.7583\n",
      "Epoch 1 Lote 37000 Pérdida 1.7574\n",
      "Epoch 1 Lote 37050 Pérdida 1.7568\n",
      "Epoch 1 Lote 37100 Pérdida 1.7560\n",
      "Epoch 1 Lote 37150 Pérdida 1.7554\n",
      "Epoch 1 Lote 37200 Pérdida 1.7543\n",
      "Epoch 1 Lote 37250 Pérdida 1.7538\n",
      "Epoch 1 Lote 37300 Pérdida 1.7530\n",
      "Epoch 1 Lote 37350 Pérdida 1.7528\n",
      "Epoch 1 Lote 37400 Pérdida 1.7532\n",
      "Epoch 1 Lote 37450 Pérdida 1.7535\n",
      "Epoch 1 Lote 37500 Pérdida 1.7531\n",
      "Epoch 1 Lote 37550 Pérdida 1.7519\n",
      "Epoch 1 Lote 37600 Pérdida 1.7521\n",
      "Epoch 1 Lote 37650 Pérdida 1.7510\n",
      "Epoch 1 Lote 37700 Pérdida 1.7498\n",
      "Epoch 1 Lote 37750 Pérdida 1.7494\n",
      "Epoch 1 Lote 37800 Pérdida 1.7491\n",
      "Epoch 1 Lote 37850 Pérdida 1.7489\n",
      "Epoch 1 Lote 37900 Pérdida 1.7485\n",
      "Epoch 1 Lote 37950 Pérdida 1.7484\n",
      "Epoch 1 Lote 38000 Pérdida 1.7481\n",
      "Epoch 1 Lote 38050 Pérdida 1.7480\n",
      "Epoch 1 Lote 38100 Pérdida 1.7473\n",
      "Epoch 1 Lote 38150 Pérdida 1.7467\n",
      "Epoch 1 Lote 38200 Pérdida 1.7473\n",
      "Epoch 1 Lote 38250 Pérdida 1.7460\n",
      "Epoch 1 Lote 38300 Pérdida 1.7461\n",
      "Epoch 1 Lote 38350 Pérdida 1.7455\n",
      "Epoch 1 Lote 38400 Pérdida 1.7452\n",
      "Epoch 1 Lote 38450 Pérdida 1.7450\n",
      "Epoch 1 Lote 38500 Pérdida 1.7446\n",
      "Epoch 1 Lote 38550 Pérdida 1.7432\n",
      "Epoch 1 Lote 38600 Pérdida 1.7417\n",
      "Epoch 1 Lote 38650 Pérdida 1.7404\n",
      "Epoch 1 Lote 38700 Pérdida 1.7390\n",
      "Epoch 1 Lote 38750 Pérdida 1.7388\n",
      "Epoch 1 Lote 38800 Pérdida 1.7382\n",
      "Epoch 1 Lote 38850 Pérdida 1.7366\n",
      "Epoch 1 Lote 38900 Pérdida 1.7352\n",
      "Epoch 1 Lote 38950 Pérdida 1.7345\n",
      "Epoch 1 Lote 39000 Pérdida 1.7334\n",
      "Epoch 1 Lote 39050 Pérdida 1.7323\n",
      "Epoch 1 Lote 39100 Pérdida 1.7315\n",
      "Epoch 1 Lote 39150 Pérdida 1.7306\n",
      "Epoch 1 Lote 39200 Pérdida 1.7293\n",
      "Epoch 1 Lote 39250 Pérdida 1.7286\n",
      "Epoch 1 Lote 39300 Pérdida 1.7275\n",
      "Epoch 1 Lote 39350 Pérdida 1.7265\n",
      "Epoch 1 Lote 39400 Pérdida 1.7255\n",
      "Epoch 1 Lote 39450 Pérdida 1.7243\n",
      "Epoch 1 Lote 39500 Pérdida 1.7225\n",
      "Epoch 1 Lote 39550 Pérdida 1.7209\n",
      "Epoch 1 Lote 39600 Pérdida 1.7195\n",
      "Epoch 1 Lote 39650 Pérdida 1.7181\n",
      "Epoch 1 Lote 39700 Pérdida 1.7192\n",
      "Epoch 1 Lote 39750 Pérdida 1.7207\n",
      "Epoch 1 Lote 39800 Pérdida 1.7203\n",
      "Epoch 1 Lote 39850 Pérdida 1.7202\n",
      "Epoch 1 Lote 39900 Pérdida 1.7197\n",
      "Epoch 1 Lote 39950 Pérdida 1.7190\n",
      "Epoch 1 Lote 40000 Pérdida 1.7190\n",
      "Epoch 1 Lote 40050 Pérdida 1.7182\n",
      "Epoch 1 Lote 40100 Pérdida 1.7175\n",
      "Epoch 1 Lote 40150 Pérdida 1.7162\n",
      "Epoch 1 Lote 40200 Pérdida 1.7148\n",
      "Epoch 1 Lote 40250 Pérdida 1.7135\n",
      "Epoch 1 Lote 40300 Pérdida 1.7126\n",
      "Epoch 1 Lote 40350 Pérdida 1.7120\n",
      "Epoch 1 Lote 40400 Pérdida 1.7123\n",
      "Epoch 1 Lote 40450 Pérdida 1.7134\n",
      "Epoch 1 Lote 40500 Pérdida 1.7144\n",
      "Epoch 1 Lote 40550 Pérdida 1.7143\n",
      "Epoch 1 Lote 40600 Pérdida 1.7143\n",
      "Epoch 1 Lote 40650 Pérdida 1.7138\n",
      "Epoch 1 Lote 40700 Pérdida 1.7134\n",
      "Epoch 1 Lote 40750 Pérdida 1.7128\n",
      "Epoch 1 Lote 40800 Pérdida 1.7125\n",
      "Epoch 1 Lote 40850 Pérdida 1.7131\n",
      "Epoch 1 Lote 40900 Pérdida 1.7128\n",
      "Epoch 1 Lote 40950 Pérdida 1.7121\n",
      "Epoch 1 Lote 41000 Pérdida 1.7116\n",
      "Epoch 1 Lote 41050 Pérdida 1.7109\n",
      "Epoch 1 Lote 41100 Pérdida 1.7109\n",
      "Epoch 1 Lote 41150 Pérdida 1.7105\n",
      "Epoch 1 Lote 41200 Pérdida 1.7099\n",
      "Epoch 1 Lote 41250 Pérdida 1.7099\n",
      "Epoch 1 Lote 41300 Pérdida 1.7098\n",
      "Epoch 1 Lote 41350 Pérdida 1.7095\n",
      "Epoch 1 Lote 41400 Pérdida 1.7090\n",
      "Epoch 1 Lote 41450 Pérdida 1.7084\n",
      "Epoch 1 Lote 41500 Pérdida 1.7078\n",
      "Epoch 1 Lote 41550 Pérdida 1.7062\n",
      "Epoch 1 Lote 41600 Pérdida 1.7050\n",
      "Epoch 1 Lote 41650 Pérdida 1.7044\n",
      "Epoch 1 Lote 41700 Pérdida 1.7033\n",
      "Epoch 1 Lote 41750 Pérdida 1.7030\n",
      "Epoch 1 Lote 41800 Pérdida 1.7027\n",
      "Epoch 1 Lote 41850 Pérdida 1.7031\n",
      "Epoch 1 Lote 41900 Pérdida 1.7034\n",
      "Epoch 1 Lote 41950 Pérdida 1.7034\n",
      "Epoch 1 Lote 42000 Pérdida 1.7042\n",
      "Epoch 1 Lote 42050 Pérdida 1.7043\n",
      "Epoch 1 Lote 42100 Pérdida 1.7040\n",
      "Epoch 1 Lote 42150 Pérdida 1.7044\n",
      "Epoch 1 Lote 42200 Pérdida 1.7042\n",
      "Epoch 1 Lote 42250 Pérdida 1.7037\n",
      "Epoch 1 Lote 42300 Pérdida 1.7036\n",
      "Epoch 1 Lote 42350 Pérdida 1.7033\n",
      "Epoch 1 Lote 42400 Pérdida 1.7030\n",
      "Epoch 1 Lote 42450 Pérdida 1.7025\n",
      "Epoch 1 Lote 42500 Pérdida 1.7024\n",
      "Epoch 1 Lote 42550 Pérdida 1.7020\n",
      "Epoch 1 Lote 42600 Pérdida 1.7010\n",
      "Epoch 1 Lote 42650 Pérdida 1.7002\n",
      "Epoch 1 Lote 42700 Pérdida 1.6992\n",
      "Epoch 1 Lote 42750 Pérdida 1.6983\n",
      "Epoch 1 Lote 42800 Pérdida 1.6977\n",
      "Epoch 1 Lote 42850 Pérdida 1.6971\n",
      "Epoch 1 Lote 42900 Pérdida 1.6969\n",
      "Epoch 1 Lote 42950 Pérdida 1.6961\n",
      "Epoch 1 Lote 43000 Pérdida 1.6959\n",
      "Epoch 1 Lote 43050 Pérdida 1.6956\n",
      "Epoch 1 Lote 43100 Pérdida 1.6949\n",
      "Epoch 1 Lote 43150 Pérdida 1.6945\n",
      "Epoch 1 Lote 43200 Pérdida 1.6941\n",
      "Epoch 1 Lote 43250 Pérdida 1.6934\n",
      "Epoch 1 Lote 43300 Pérdida 1.6941\n",
      "Epoch 1 Lote 43350 Pérdida 1.6953\n",
      "Epoch 1 Lote 43400 Pérdida 1.6963\n",
      "Epoch 1 Lote 43450 Pérdida 1.6963\n",
      "Epoch 1 Lote 43500 Pérdida 1.6967\n",
      "Epoch 1 Lote 43550 Pérdida 1.6972\n",
      "Epoch 1 Lote 43600 Pérdida 1.6973\n",
      "Epoch 1 Lote 43650 Pérdida 1.6968\n",
      "Epoch 1 Lote 43700 Pérdida 1.6970\n",
      "Epoch 1 Lote 43750 Pérdida 1.6968\n",
      "Epoch 1 Lote 43800 Pérdida 1.6975\n",
      "Epoch 1 Lote 43850 Pérdida 1.6973\n",
      "Epoch 1 Lote 43900 Pérdida 1.6971\n",
      "Epoch 1 Lote 43950 Pérdida 1.6965\n",
      "Tiempo total para entrenar 1 epoch: 4224.962344884872 segs\n",
      "\n",
      "Inicio del Epoch 2\n",
      "Epoch 2 Lote 0 Pérdida 0.1368\n",
      "Epoch 2 Lote 50 Pérdida 1.4265\n",
      "Epoch 2 Lote 100 Pérdida 1.2467\n",
      "Epoch 2 Lote 150 Pérdida 1.0281\n",
      "Epoch 2 Lote 200 Pérdida 0.9833\n",
      "Epoch 2 Lote 250 Pérdida 1.1244\n",
      "Epoch 2 Lote 300 Pérdida 1.1220\n",
      "Epoch 2 Lote 350 Pérdida 1.1514\n",
      "Epoch 2 Lote 400 Pérdida 1.3111\n",
      "Epoch 2 Lote 450 Pérdida 1.3712\n",
      "Epoch 2 Lote 500 Pérdida 1.4230\n",
      "Epoch 2 Lote 550 Pérdida 1.4423\n",
      "Epoch 2 Lote 600 Pérdida 1.4740\n",
      "Epoch 2 Lote 650 Pérdida 1.4878\n",
      "Epoch 2 Lote 700 Pérdida 1.5218\n",
      "Epoch 2 Lote 750 Pérdida 1.5600\n",
      "Epoch 2 Lote 800 Pérdida 1.5682\n",
      "Epoch 2 Lote 850 Pérdida 1.5395\n",
      "Epoch 2 Lote 900 Pérdida 1.5505\n",
      "Epoch 2 Lote 950 Pérdida 1.5269\n",
      "Epoch 2 Lote 1000 Pérdida 1.5310\n",
      "Epoch 2 Lote 1050 Pérdida 1.5416\n",
      "Epoch 2 Lote 1100 Pérdida 1.5472\n",
      "Epoch 2 Lote 1150 Pérdida 1.5409\n",
      "Epoch 2 Lote 1200 Pérdida 1.5325\n",
      "Epoch 2 Lote 1250 Pérdida 1.5175\n",
      "Epoch 2 Lote 1300 Pérdida 1.5018\n",
      "Epoch 2 Lote 1350 Pérdida 1.5225\n",
      "Epoch 2 Lote 1400 Pérdida 1.5176\n",
      "Epoch 2 Lote 1450 Pérdida 1.5133\n",
      "Epoch 2 Lote 1500 Pérdida 1.5083\n",
      "Epoch 2 Lote 1550 Pérdida 1.5003\n",
      "Epoch 2 Lote 1600 Pérdida 1.4831\n",
      "Epoch 2 Lote 1650 Pérdida 1.4760\n",
      "Epoch 2 Lote 1700 Pérdida 1.4657\n",
      "Epoch 2 Lote 1750 Pérdida 1.4556\n",
      "Epoch 2 Lote 1800 Pérdida 1.4627\n",
      "Epoch 2 Lote 1850 Pérdida 1.4572\n",
      "Epoch 2 Lote 1900 Pérdida 1.4365\n",
      "Epoch 2 Lote 1950 Pérdida 1.4337\n",
      "Epoch 2 Lote 2000 Pérdida 1.4175\n",
      "Epoch 2 Lote 2050 Pérdida 1.4140\n",
      "Epoch 2 Lote 2100 Pérdida 1.4097\n",
      "Epoch 2 Lote 2150 Pérdida 1.3919\n",
      "Epoch 2 Lote 2200 Pérdida 1.3870\n",
      "Epoch 2 Lote 2250 Pérdida 1.3785\n",
      "Epoch 2 Lote 2300 Pérdida 1.3683\n",
      "Epoch 2 Lote 2350 Pérdida 1.3699\n",
      "Epoch 2 Lote 2400 Pérdida 1.3757\n",
      "Epoch 2 Lote 2450 Pérdida 1.3911\n",
      "Epoch 2 Lote 2500 Pérdida 1.3983\n",
      "Epoch 2 Lote 2550 Pérdida 1.3966\n",
      "Epoch 2 Lote 2600 Pérdida 1.4017\n",
      "Epoch 2 Lote 2650 Pérdida 1.4101\n",
      "Epoch 2 Lote 2700 Pérdida 1.4125\n",
      "Epoch 2 Lote 2750 Pérdida 1.4182\n",
      "Epoch 2 Lote 2800 Pérdida 1.4145\n",
      "Epoch 2 Lote 2850 Pérdida 1.4145\n",
      "Epoch 2 Lote 2900 Pérdida 1.4128\n",
      "Epoch 2 Lote 2950 Pérdida 1.4116\n",
      "Epoch 2 Lote 3000 Pérdida 1.4040\n",
      "Epoch 2 Lote 3050 Pérdida 1.4020\n",
      "Epoch 2 Lote 3100 Pérdida 1.3960\n",
      "Epoch 2 Lote 3150 Pérdida 1.3887\n",
      "Epoch 2 Lote 3200 Pérdida 1.3930\n",
      "Epoch 2 Lote 3250 Pérdida 1.3878\n",
      "Epoch 2 Lote 3300 Pérdida 1.3839\n",
      "Epoch 2 Lote 3350 Pérdida 1.3771\n",
      "Epoch 2 Lote 3400 Pérdida 1.3778\n",
      "Epoch 2 Lote 3450 Pérdida 1.3736\n",
      "Epoch 2 Lote 3500 Pérdida 1.3702\n",
      "Epoch 2 Lote 3550 Pérdida 1.3670\n",
      "Epoch 2 Lote 3600 Pérdida 1.3673\n",
      "Epoch 2 Lote 3650 Pérdida 1.3736\n",
      "Epoch 2 Lote 3700 Pérdida 1.3698\n",
      "Epoch 2 Lote 3750 Pérdida 1.3666\n",
      "Epoch 2 Lote 3800 Pérdida 1.3676\n",
      "Epoch 2 Lote 3850 Pérdida 1.3563\n",
      "Epoch 2 Lote 3900 Pérdida 1.3517\n",
      "Epoch 2 Lote 3950 Pérdida 1.3466\n",
      "Epoch 2 Lote 4000 Pérdida 1.3407\n",
      "Epoch 2 Lote 4050 Pérdida 1.3302\n",
      "Epoch 2 Lote 4100 Pérdida 1.3233\n",
      "Epoch 2 Lote 4150 Pérdida 1.3144\n",
      "Epoch 2 Lote 4200 Pérdida 1.3116\n",
      "Epoch 2 Lote 4250 Pérdida 1.3050\n",
      "Epoch 2 Lote 4300 Pérdida 1.3118\n",
      "Epoch 2 Lote 4350 Pérdida 1.3059\n",
      "Epoch 2 Lote 4400 Pérdida 1.3003\n",
      "Epoch 2 Lote 4450 Pérdida 1.2957\n",
      "Epoch 2 Lote 4500 Pérdida 1.2874\n",
      "Epoch 2 Lote 4550 Pérdida 1.2807\n",
      "Epoch 2 Lote 4600 Pérdida 1.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Lote 4650 Pérdida 1.2678\n",
      "Epoch 2 Lote 4700 Pérdida 1.2624\n",
      "Epoch 2 Lote 4750 Pérdida 1.2600\n",
      "Epoch 2 Lote 4800 Pérdida 1.2581\n",
      "Epoch 2 Lote 4850 Pérdida 1.2564\n",
      "Epoch 2 Lote 4900 Pérdida 1.2552\n",
      "Epoch 2 Lote 4950 Pérdida 1.2575\n",
      "Epoch 2 Lote 5000 Pérdida 1.2589\n",
      "Epoch 2 Lote 5050 Pérdida 1.2571\n",
      "Epoch 2 Lote 5100 Pérdida 1.2577\n",
      "Epoch 2 Lote 5150 Pérdida 1.2557\n",
      "Epoch 2 Lote 5200 Pérdida 1.2558\n",
      "Epoch 2 Lote 5250 Pérdida 1.2562\n",
      "Epoch 2 Lote 5300 Pérdida 1.2575\n",
      "Epoch 2 Lote 5350 Pérdida 1.2589\n",
      "Epoch 2 Lote 5400 Pérdida 1.2573\n",
      "Epoch 2 Lote 5450 Pérdida 1.2552\n",
      "Epoch 2 Lote 5500 Pérdida 1.2521\n",
      "Epoch 2 Lote 5550 Pérdida 1.2491\n",
      "Epoch 2 Lote 5600 Pérdida 1.2473\n",
      "Epoch 2 Lote 5650 Pérdida 1.2436\n",
      "Epoch 2 Lote 5700 Pérdida 1.2387\n",
      "Epoch 2 Lote 5750 Pérdida 1.2354\n",
      "Epoch 2 Lote 5800 Pérdida 1.2324\n",
      "Epoch 2 Lote 5850 Pérdida 1.2283\n",
      "Epoch 2 Lote 5900 Pérdida 1.2239\n",
      "Epoch 2 Lote 5950 Pérdida 1.2205\n",
      "Epoch 2 Lote 6000 Pérdida 1.2169\n",
      "Epoch 2 Lote 6050 Pérdida 1.2199\n",
      "Epoch 2 Lote 6100 Pérdida 1.2168\n",
      "Epoch 2 Lote 6150 Pérdida 1.2126\n",
      "Epoch 2 Lote 6200 Pérdida 1.2137\n",
      "Epoch 2 Lote 6250 Pérdida 1.2124\n",
      "Epoch 2 Lote 6300 Pérdida 1.2106\n",
      "Epoch 2 Lote 6350 Pérdida 1.2125\n",
      "Epoch 2 Lote 6400 Pérdida 1.2146\n",
      "Epoch 2 Lote 6450 Pérdida 1.2149\n",
      "Epoch 2 Lote 6500 Pérdida 1.2159\n",
      "Epoch 2 Lote 6550 Pérdida 1.2134\n",
      "Epoch 2 Lote 6600 Pérdida 1.2198\n",
      "Epoch 2 Lote 6650 Pérdida 1.2197\n",
      "Epoch 2 Lote 6700 Pérdida 1.2146\n",
      "Epoch 2 Lote 6750 Pérdida 1.2218\n",
      "Epoch 2 Lote 6800 Pérdida 1.2250\n",
      "Epoch 2 Lote 6850 Pérdida 1.2291\n",
      "Epoch 2 Lote 6900 Pérdida 1.2273\n",
      "Epoch 2 Lote 6950 Pérdida 1.2312\n",
      "Epoch 2 Lote 7000 Pérdida 1.2294\n",
      "Epoch 2 Lote 7050 Pérdida 1.2256\n",
      "Epoch 2 Lote 7100 Pérdida 1.2306\n",
      "Epoch 2 Lote 7150 Pérdida 1.2317\n",
      "Epoch 2 Lote 7200 Pérdida 1.2320\n",
      "Epoch 2 Lote 7250 Pérdida 1.2378\n",
      "Epoch 2 Lote 7300 Pérdida 1.2397\n",
      "Epoch 2 Lote 7350 Pérdida 1.2379\n",
      "Epoch 2 Lote 7400 Pérdida 1.2363\n",
      "Epoch 2 Lote 7450 Pérdida 1.2333\n",
      "Epoch 2 Lote 7500 Pérdida 1.2299\n",
      "Epoch 2 Lote 7550 Pérdida 1.2301\n",
      "Epoch 2 Lote 7600 Pérdida 1.2259\n",
      "Epoch 2 Lote 7650 Pérdida 1.2250\n",
      "Epoch 2 Lote 7700 Pérdida 1.2236\n",
      "Epoch 2 Lote 7750 Pérdida 1.2228\n",
      "Epoch 2 Lote 7800 Pérdida 1.2234\n",
      "Epoch 2 Lote 7850 Pérdida 1.2202\n",
      "Epoch 2 Lote 7900 Pérdida 1.2197\n",
      "Epoch 2 Lote 7950 Pérdida 1.2215\n",
      "Epoch 2 Lote 8000 Pérdida 1.2229\n",
      "Epoch 2 Lote 8050 Pérdida 1.2226\n",
      "Epoch 2 Lote 8100 Pérdida 1.2213\n",
      "Epoch 2 Lote 8150 Pérdida 1.2186\n",
      "Epoch 2 Lote 8200 Pérdida 1.2151\n",
      "Epoch 2 Lote 8250 Pérdida 1.2117\n",
      "Epoch 2 Lote 8300 Pérdida 1.2158\n",
      "Epoch 2 Lote 8350 Pérdida 1.2136\n",
      "Epoch 2 Lote 8400 Pérdida 1.2129\n",
      "Epoch 2 Lote 8450 Pérdida 1.2105\n",
      "Epoch 2 Lote 8500 Pérdida 1.2069\n",
      "Epoch 2 Lote 8550 Pérdida 1.2071\n",
      "Epoch 2 Lote 8600 Pérdida 1.2078\n",
      "Epoch 2 Lote 8650 Pérdida 1.2066\n",
      "Epoch 2 Lote 8700 Pérdida 1.2031\n",
      "Epoch 2 Lote 8750 Pérdida 1.2056\n",
      "Epoch 2 Lote 8800 Pérdida 1.2064\n",
      "Epoch 2 Lote 8850 Pérdida 1.2050\n",
      "Epoch 2 Lote 8900 Pérdida 1.2064\n",
      "Epoch 2 Lote 8950 Pérdida 1.2050\n",
      "Epoch 2 Lote 9000 Pérdida 1.2069\n",
      "Epoch 2 Lote 9050 Pérdida 1.2064\n",
      "Epoch 2 Lote 9100 Pérdida 1.2044\n",
      "Epoch 2 Lote 9150 Pérdida 1.2019\n",
      "Epoch 2 Lote 9200 Pérdida 1.2000\n",
      "Epoch 2 Lote 9250 Pérdida 1.1971\n",
      "Epoch 2 Lote 9300 Pérdida 1.1940\n",
      "Epoch 2 Lote 9350 Pérdida 1.1902\n",
      "Epoch 2 Lote 9400 Pérdida 1.1870\n",
      "Epoch 2 Lote 9450 Pérdida 1.1855\n",
      "Epoch 2 Lote 9500 Pérdida 1.1829\n",
      "Epoch 2 Lote 9550 Pérdida 1.1796\n",
      "Epoch 2 Lote 9600 Pérdida 1.1763\n",
      "Epoch 2 Lote 9650 Pérdida 1.1733\n",
      "Epoch 2 Lote 9700 Pérdida 1.1701\n",
      "Epoch 2 Lote 9750 Pérdida 1.1660\n",
      "Epoch 2 Lote 9800 Pérdida 1.1621\n",
      "Epoch 2 Lote 9850 Pérdida 1.1596\n",
      "Epoch 2 Lote 9900 Pérdida 1.1590\n",
      "Epoch 2 Lote 9950 Pérdida 1.1540\n",
      "Epoch 2 Lote 10000 Pérdida 1.1514\n",
      "Epoch 2 Lote 10050 Pérdida 1.1484\n",
      "Epoch 2 Lote 10100 Pérdida 1.1449\n",
      "Epoch 2 Lote 10150 Pérdida 1.1427\n",
      "Epoch 2 Lote 10200 Pérdida 1.1387\n",
      "Epoch 2 Lote 10250 Pérdida 1.1357\n",
      "Epoch 2 Lote 10300 Pérdida 1.1351\n",
      "Epoch 2 Lote 10350 Pérdida 1.1341\n",
      "Epoch 2 Lote 10400 Pérdida 1.1336\n",
      "Epoch 2 Lote 10450 Pérdida 1.1347\n",
      "Epoch 2 Lote 10500 Pérdida 1.1345\n",
      "Epoch 2 Lote 10550 Pérdida 1.1356\n",
      "Epoch 2 Lote 10600 Pérdida 1.1354\n",
      "Epoch 2 Lote 10650 Pérdida 1.1334\n",
      "Epoch 2 Lote 10700 Pérdida 1.1311\n",
      "Epoch 2 Lote 10750 Pérdida 1.1302\n",
      "Epoch 2 Lote 10800 Pérdida 1.1322\n",
      "Epoch 2 Lote 10850 Pérdida 1.1325\n",
      "Epoch 2 Lote 10900 Pérdida 1.1321\n",
      "Epoch 2 Lote 10950 Pérdida 1.1316\n",
      "Epoch 2 Lote 11000 Pérdida 1.1332\n",
      "Epoch 2 Lote 11050 Pérdida 1.1324\n",
      "Epoch 2 Lote 11100 Pérdida 1.1325\n",
      "Epoch 2 Lote 11150 Pérdida 1.1325\n",
      "Epoch 2 Lote 11200 Pérdida 1.1326\n",
      "Epoch 2 Lote 11250 Pérdida 1.1305\n",
      "Epoch 2 Lote 11300 Pérdida 1.1279\n",
      "Epoch 2 Lote 11350 Pérdida 1.1259\n",
      "Epoch 2 Lote 11400 Pérdida 1.1227\n",
      "Epoch 2 Lote 11450 Pérdida 1.1209\n",
      "Epoch 2 Lote 11500 Pérdida 1.1199\n",
      "Epoch 2 Lote 11550 Pérdida 1.1180\n",
      "Epoch 2 Lote 11600 Pérdida 1.1158\n",
      "Epoch 2 Lote 11650 Pérdida 1.1125\n",
      "Epoch 2 Lote 11700 Pérdida 1.1103\n",
      "Epoch 2 Lote 11750 Pérdida 1.1083\n",
      "Epoch 2 Lote 11800 Pérdida 1.1076\n",
      "Epoch 2 Lote 11850 Pérdida 1.1080\n",
      "Epoch 2 Lote 11900 Pérdida 1.1068\n",
      "Epoch 2 Lote 11950 Pérdida 1.1046\n",
      "Epoch 2 Lote 12000 Pérdida 1.1043\n",
      "Epoch 2 Lote 12050 Pérdida 1.1015\n",
      "Epoch 2 Lote 12100 Pérdida 1.0987\n",
      "Epoch 2 Lote 12150 Pérdida 1.0968\n",
      "Epoch 2 Lote 12200 Pérdida 1.0943\n",
      "Epoch 2 Lote 12250 Pérdida 1.0932\n",
      "Epoch 2 Lote 12300 Pérdida 1.0926\n",
      "Epoch 2 Lote 12350 Pérdida 1.0926\n",
      "Epoch 2 Lote 12400 Pérdida 1.0905\n",
      "Epoch 2 Lote 12450 Pérdida 1.0886\n",
      "Epoch 2 Lote 12500 Pérdida 1.0873\n",
      "Epoch 2 Lote 12550 Pérdida 1.0866\n",
      "Epoch 2 Lote 12600 Pérdida 1.0849\n",
      "Epoch 2 Lote 12650 Pérdida 1.0829\n",
      "Epoch 2 Lote 12700 Pérdida 1.0809\n",
      "Epoch 2 Lote 12750 Pérdida 1.0794\n",
      "Epoch 2 Lote 12800 Pérdida 1.0768\n",
      "Epoch 2 Lote 12850 Pérdida 1.0758\n",
      "Epoch 2 Lote 12900 Pérdida 1.0741\n",
      "Epoch 2 Lote 12950 Pérdida 1.0718\n",
      "Epoch 2 Lote 13000 Pérdida 1.0711\n",
      "Epoch 2 Lote 13050 Pérdida 1.0692\n",
      "Epoch 2 Lote 13100 Pérdida 1.0678\n",
      "Epoch 2 Lote 13150 Pérdida 1.0684\n",
      "Epoch 2 Lote 13200 Pérdida 1.0674\n",
      "Epoch 2 Lote 13250 Pérdida 1.0662\n",
      "Epoch 2 Lote 13300 Pérdida 1.0668\n",
      "Epoch 2 Lote 13350 Pérdida 1.0652\n",
      "Epoch 2 Lote 13400 Pérdida 1.0627\n",
      "Epoch 2 Lote 13450 Pérdida 1.0600\n",
      "Epoch 2 Lote 13500 Pérdida 1.0586\n",
      "Epoch 2 Lote 13550 Pérdida 1.0570\n",
      "Epoch 2 Lote 13600 Pérdida 1.0558\n",
      "Epoch 2 Lote 13650 Pérdida 1.0542\n",
      "Epoch 2 Lote 13700 Pérdida 1.0543\n",
      "Epoch 2 Lote 13750 Pérdida 1.0539\n",
      "Epoch 2 Lote 13800 Pérdida 1.0545\n",
      "Epoch 2 Lote 13850 Pérdida 1.0525\n",
      "Epoch 2 Lote 13900 Pérdida 1.0508\n",
      "Epoch 2 Lote 13950 Pérdida 1.0506\n",
      "Epoch 2 Lote 14000 Pérdida 1.0491\n",
      "Epoch 2 Lote 14050 Pérdida 1.0482\n",
      "Epoch 2 Lote 14100 Pérdida 1.0475\n",
      "Epoch 2 Lote 14150 Pérdida 1.0475\n",
      "Epoch 2 Lote 14200 Pérdida 1.0474\n",
      "Epoch 2 Lote 14250 Pérdida 1.0467\n",
      "Epoch 2 Lote 14300 Pérdida 1.0458\n",
      "Epoch 2 Lote 14350 Pérdida 1.0444\n",
      "Epoch 2 Lote 14400 Pérdida 1.0434\n",
      "Epoch 2 Lote 14450 Pérdida 1.0427\n",
      "Epoch 2 Lote 14500 Pérdida 1.0403\n",
      "Epoch 2 Lote 14550 Pérdida 1.0397\n",
      "Epoch 2 Lote 14600 Pérdida 1.0376\n",
      "Epoch 2 Lote 14650 Pérdida 1.0387\n",
      "Epoch 2 Lote 14700 Pérdida 1.0410\n",
      "Epoch 2 Lote 14750 Pérdida 1.0401\n",
      "Epoch 2 Lote 14800 Pérdida 1.0402\n",
      "Epoch 2 Lote 14850 Pérdida 1.0406\n",
      "Epoch 2 Lote 14900 Pérdida 1.0383\n",
      "Epoch 2 Lote 14950 Pérdida 1.0368\n",
      "Epoch 2 Lote 15000 Pérdida 1.0368\n",
      "Epoch 2 Lote 15050 Pérdida 1.0345\n",
      "Epoch 2 Lote 15100 Pérdida 1.0341\n",
      "Epoch 2 Lote 15150 Pérdida 1.0353\n",
      "Epoch 2 Lote 15200 Pérdida 1.0360\n",
      "Epoch 2 Lote 15250 Pérdida 1.0352\n",
      "Epoch 2 Lote 15300 Pérdida 1.0348\n",
      "Epoch 2 Lote 15350 Pérdida 1.0340\n",
      "Epoch 2 Lote 15400 Pérdida 1.0333\n",
      "Epoch 2 Lote 15450 Pérdida 1.0320\n",
      "Epoch 2 Lote 15500 Pérdida 1.0310\n",
      "Epoch 2 Lote 15550 Pérdida 1.0304\n",
      "Epoch 2 Lote 15600 Pérdida 1.0291\n",
      "Epoch 2 Lote 15650 Pérdida 1.0276\n",
      "Epoch 2 Lote 15700 Pérdida 1.0285\n",
      "Epoch 2 Lote 15750 Pérdida 1.0289\n",
      "Epoch 2 Lote 15800 Pérdida 1.0272\n",
      "Epoch 2 Lote 15850 Pérdida 1.0270\n",
      "Epoch 2 Lote 15900 Pérdida 1.0260\n",
      "Epoch 2 Lote 15950 Pérdida 1.0267\n",
      "Epoch 2 Lote 16000 Pérdida 1.0281\n",
      "Epoch 2 Lote 16050 Pérdida 1.0278\n",
      "Epoch 2 Lote 16100 Pérdida 1.0273\n",
      "Epoch 2 Lote 16150 Pérdida 1.0269\n",
      "Epoch 2 Lote 16200 Pérdida 1.0277\n",
      "Epoch 2 Lote 16250 Pérdida 1.0268\n",
      "Epoch 2 Lote 16300 Pérdida 1.0267\n",
      "Epoch 2 Lote 16350 Pérdida 1.0257\n",
      "Epoch 2 Lote 16400 Pérdida 1.0243\n",
      "Epoch 2 Lote 16450 Pérdida 1.0229\n",
      "Epoch 2 Lote 16500 Pérdida 1.0222\n",
      "Epoch 2 Lote 16550 Pérdida 1.0204\n",
      "Epoch 2 Lote 16600 Pérdida 1.0185\n",
      "Epoch 2 Lote 16650 Pérdida 1.0186\n",
      "Epoch 2 Lote 16700 Pérdida 1.0187\n",
      "Epoch 2 Lote 16750 Pérdida 1.0166\n",
      "Epoch 2 Lote 16800 Pérdida 1.0150\n",
      "Epoch 2 Lote 16850 Pérdida 1.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Lote 16900 Pérdida 1.0114\n",
      "Epoch 2 Lote 16950 Pérdida 1.0107\n",
      "Epoch 2 Lote 17000 Pérdida 1.0101\n",
      "Epoch 2 Lote 17050 Pérdida 1.0104\n",
      "Epoch 2 Lote 17100 Pérdida 1.0110\n",
      "Epoch 2 Lote 17150 Pérdida 1.0122\n",
      "Epoch 2 Lote 17200 Pérdida 1.0120\n",
      "Epoch 2 Lote 17250 Pérdida 1.0108\n",
      "Epoch 2 Lote 17300 Pérdida 1.0110\n",
      "Epoch 2 Lote 17350 Pérdida 1.0114\n",
      "Epoch 2 Lote 17400 Pérdida 1.0122\n",
      "Epoch 2 Lote 17450 Pérdida 1.0113\n",
      "Epoch 2 Lote 17500 Pérdida 1.0104\n",
      "Epoch 2 Lote 17550 Pérdida 1.0085\n",
      "Epoch 2 Lote 17600 Pérdida 1.0070\n",
      "Epoch 2 Lote 17650 Pérdida 1.0051\n",
      "Epoch 2 Lote 17700 Pérdida 1.0041\n",
      "Epoch 2 Lote 17750 Pérdida 1.0035\n",
      "Epoch 2 Lote 17800 Pérdida 1.0024\n",
      "Epoch 2 Lote 17850 Pérdida 1.0018\n",
      "Epoch 2 Lote 17900 Pérdida 1.0011\n",
      "Epoch 2 Lote 17950 Pérdida 1.0001\n",
      "Epoch 2 Lote 18000 Pérdida 0.9992\n",
      "Epoch 2 Lote 18050 Pérdida 0.9981\n",
      "Epoch 2 Lote 18100 Pérdida 0.9961\n",
      "Epoch 2 Lote 18150 Pérdida 0.9950\n",
      "Epoch 2 Lote 18200 Pérdida 0.9930\n",
      "Epoch 2 Lote 18250 Pérdida 0.9929\n",
      "Epoch 2 Lote 18300 Pérdida 0.9913\n",
      "Epoch 2 Lote 18350 Pérdida 0.9901\n",
      "Epoch 2 Lote 18400 Pérdida 0.9893\n",
      "Epoch 2 Lote 18450 Pérdida 0.9880\n",
      "Epoch 2 Lote 18500 Pérdida 0.9868\n",
      "Epoch 2 Lote 18550 Pérdida 0.9862\n",
      "Epoch 2 Lote 18600 Pérdida 0.9858\n",
      "Epoch 2 Lote 18650 Pérdida 0.9846\n",
      "Epoch 2 Lote 18700 Pérdida 0.9836\n",
      "Epoch 2 Lote 18750 Pérdida 0.9823\n",
      "Epoch 2 Lote 18800 Pérdida 0.9812\n",
      "Epoch 2 Lote 18850 Pérdida 0.9804\n",
      "Epoch 2 Lote 18900 Pérdida 0.9799\n",
      "Epoch 2 Lote 18950 Pérdida 0.9794\n",
      "Epoch 2 Lote 19000 Pérdida 0.9778\n",
      "Epoch 2 Lote 19050 Pérdida 0.9763\n",
      "Epoch 2 Lote 19100 Pérdida 0.9742\n",
      "Epoch 2 Lote 19150 Pérdida 0.9721\n",
      "Epoch 2 Lote 19200 Pérdida 0.9705\n",
      "Epoch 2 Lote 19250 Pérdida 0.9688\n",
      "Epoch 2 Lote 19300 Pérdida 0.9672\n",
      "Epoch 2 Lote 19350 Pérdida 0.9656\n",
      "Epoch 2 Lote 19400 Pérdida 0.9634\n",
      "Epoch 2 Lote 19450 Pérdida 0.9623\n",
      "Epoch 2 Lote 19500 Pérdida 0.9614\n",
      "Epoch 2 Lote 19550 Pérdida 0.9610\n",
      "Epoch 2 Lote 19600 Pérdida 0.9599\n",
      "Epoch 2 Lote 19650 Pérdida 0.9591\n",
      "Epoch 2 Lote 19700 Pérdida 0.9577\n",
      "Epoch 2 Lote 19750 Pérdida 0.9561\n",
      "Epoch 2 Lote 19800 Pérdida 0.9554\n",
      "Epoch 2 Lote 19850 Pérdida 0.9555\n",
      "Epoch 2 Lote 19900 Pérdida 0.9550\n",
      "Epoch 2 Lote 19950 Pérdida 0.9546\n",
      "Epoch 2 Lote 20000 Pérdida 0.9535\n",
      "Epoch 2 Lote 20050 Pérdida 0.9524\n",
      "Epoch 2 Lote 20100 Pérdida 0.9516\n",
      "Epoch 2 Lote 20150 Pérdida 0.9503\n",
      "Epoch 2 Lote 20200 Pérdida 0.9491\n",
      "Epoch 2 Lote 20250 Pérdida 0.9483\n",
      "Epoch 2 Lote 20300 Pérdida 0.9482\n",
      "Epoch 2 Lote 20350 Pérdida 0.9475\n",
      "Epoch 2 Lote 20400 Pérdida 0.9473\n",
      "Epoch 2 Lote 20450 Pérdida 0.9477\n",
      "Epoch 2 Lote 20500 Pérdida 0.9471\n",
      "Epoch 2 Lote 20550 Pérdida 0.9466\n",
      "Epoch 2 Lote 20600 Pérdida 0.9466\n",
      "Epoch 2 Lote 20650 Pérdida 0.9453\n",
      "Epoch 2 Lote 20700 Pérdida 0.9448\n",
      "Epoch 2 Lote 20750 Pérdida 0.9443\n",
      "Epoch 2 Lote 20800 Pérdida 0.9436\n",
      "Epoch 2 Lote 20850 Pérdida 0.9428\n",
      "Epoch 2 Lote 20900 Pérdida 0.9420\n",
      "Epoch 2 Lote 20950 Pérdida 0.9413\n",
      "Epoch 2 Lote 21000 Pérdida 0.9405\n",
      "Epoch 2 Lote 21050 Pérdida 0.9399\n",
      "Epoch 2 Lote 21100 Pérdida 0.9388\n",
      "Epoch 2 Lote 21150 Pérdida 0.9377\n",
      "Epoch 2 Lote 21200 Pérdida 0.9378\n",
      "Epoch 2 Lote 21250 Pérdida 0.9381\n",
      "Epoch 2 Lote 21300 Pérdida 0.9372\n",
      "Epoch 2 Lote 21350 Pérdida 0.9368\n",
      "Epoch 2 Lote 21400 Pérdida 0.9362\n",
      "Epoch 2 Lote 21450 Pérdida 0.9349\n",
      "Epoch 2 Lote 21500 Pérdida 0.9334\n",
      "Epoch 2 Lote 21550 Pérdida 0.9320\n",
      "Epoch 2 Lote 21600 Pérdida 0.9306\n",
      "Epoch 2 Lote 21650 Pérdida 0.9298\n",
      "Epoch 2 Lote 21700 Pérdida 0.9286\n",
      "Epoch 2 Lote 21750 Pérdida 0.9272\n",
      "Epoch 2 Lote 21800 Pérdida 0.9259\n",
      "Epoch 2 Lote 21850 Pérdida 0.9251\n",
      "Epoch 2 Lote 21900 Pérdida 0.9245\n",
      "Epoch 2 Lote 21950 Pérdida 0.9247\n",
      "Epoch 2 Lote 22000 Pérdida 0.9246\n",
      "Epoch 2 Lote 22050 Pérdida 0.9246\n",
      "Epoch 2 Lote 22100 Pérdida 0.9235\n",
      "Epoch 2 Lote 22150 Pérdida 0.9232\n",
      "Epoch 2 Lote 22200 Pérdida 0.9231\n",
      "Epoch 2 Lote 22250 Pérdida 0.9222\n",
      "Epoch 2 Lote 22300 Pérdida 0.9214\n",
      "Epoch 2 Lote 22350 Pérdida 0.9215\n",
      "Epoch 2 Lote 22400 Pérdida 0.9198\n",
      "Epoch 2 Lote 22450 Pérdida 0.9190\n",
      "Epoch 2 Lote 22500 Pérdida 0.9172\n",
      "Epoch 2 Lote 22550 Pérdida 0.9169\n",
      "Epoch 2 Lote 22600 Pérdida 0.9157\n",
      "Epoch 2 Lote 22650 Pérdida 0.9144\n",
      "Epoch 2 Lote 22700 Pérdida 0.9135\n",
      "Epoch 2 Lote 22750 Pérdida 0.9124\n",
      "Epoch 2 Lote 22800 Pérdida 0.9112\n",
      "Epoch 2 Lote 22850 Pérdida 0.9103\n",
      "Epoch 2 Lote 22900 Pérdida 0.9096\n",
      "Epoch 2 Lote 22950 Pérdida 0.9088\n",
      "Epoch 2 Lote 23000 Pérdida 0.9077\n",
      "Epoch 2 Lote 23050 Pérdida 0.9069\n",
      "Epoch 2 Lote 23100 Pérdida 0.9060\n",
      "Epoch 2 Lote 23150 Pérdida 0.9047\n",
      "Epoch 2 Lote 23200 Pérdida 0.9041\n",
      "Epoch 2 Lote 23250 Pérdida 0.9034\n",
      "Epoch 2 Lote 23300 Pérdida 0.9024\n",
      "Epoch 2 Lote 23350 Pérdida 0.9018\n",
      "Epoch 2 Lote 23400 Pérdida 0.9007\n",
      "Epoch 2 Lote 23450 Pérdida 0.8999\n",
      "Epoch 2 Lote 23500 Pérdida 0.8985\n",
      "Epoch 2 Lote 23550 Pérdida 0.8974\n",
      "Epoch 2 Lote 23600 Pérdida 0.8972\n",
      "Epoch 2 Lote 23650 Pérdida 0.8963\n",
      "Epoch 2 Lote 23700 Pérdida 0.8955\n",
      "Epoch 2 Lote 23750 Pérdida 0.8945\n",
      "Epoch 2 Lote 23800 Pérdida 0.8938\n",
      "Epoch 2 Lote 23850 Pérdida 0.8922\n",
      "Epoch 2 Lote 23900 Pérdida 0.8916\n",
      "Epoch 2 Lote 23950 Pérdida 0.8902\n",
      "Epoch 2 Lote 24000 Pérdida 0.8894\n",
      "Epoch 2 Lote 24050 Pérdida 0.8896\n",
      "Epoch 2 Lote 24100 Pérdida 0.8900\n",
      "Epoch 2 Lote 24150 Pérdida 0.8894\n",
      "Epoch 2 Lote 24200 Pérdida 0.8901\n",
      "Epoch 2 Lote 24250 Pérdida 0.8895\n",
      "Epoch 2 Lote 24300 Pérdida 0.8898\n",
      "Epoch 2 Lote 24350 Pérdida 0.8903\n",
      "Epoch 2 Lote 24400 Pérdida 0.8916\n",
      "Epoch 2 Lote 24450 Pérdida 0.8914\n",
      "Epoch 2 Lote 24500 Pérdida 0.8910\n",
      "Epoch 2 Lote 24550 Pérdida 0.8909\n",
      "Epoch 2 Lote 24600 Pérdida 0.8898\n",
      "Epoch 2 Lote 24650 Pérdida 0.8885\n",
      "Epoch 2 Lote 24700 Pérdida 0.8880\n",
      "Epoch 2 Lote 24750 Pérdida 0.8873\n",
      "Epoch 2 Lote 24800 Pérdida 0.8871\n",
      "Epoch 2 Lote 24850 Pérdida 0.8862\n",
      "Epoch 2 Lote 24900 Pérdida 0.8850\n",
      "Epoch 2 Lote 24950 Pérdida 0.8841\n",
      "Epoch 2 Lote 25000 Pérdida 0.8834\n",
      "Epoch 2 Lote 25050 Pérdida 0.8823\n",
      "Epoch 2 Lote 25100 Pérdida 0.8818\n",
      "Epoch 2 Lote 25150 Pérdida 0.8810\n",
      "Epoch 2 Lote 25200 Pérdida 0.8805\n",
      "Epoch 2 Lote 25250 Pérdida 0.8797\n",
      "Epoch 2 Lote 25300 Pérdida 0.8792\n",
      "Epoch 2 Lote 25350 Pérdida 0.8780\n",
      "Epoch 2 Lote 25400 Pérdida 0.8769\n",
      "Epoch 2 Lote 25450 Pérdida 0.8762\n",
      "Epoch 2 Lote 25500 Pérdida 0.8752\n",
      "Epoch 2 Lote 25550 Pérdida 0.8747\n",
      "Epoch 2 Lote 25600 Pérdida 0.8736\n",
      "Epoch 2 Lote 25650 Pérdida 0.8726\n",
      "Epoch 2 Lote 25700 Pérdida 0.8714\n",
      "Epoch 2 Lote 25750 Pérdida 0.8712\n",
      "Epoch 2 Lote 25800 Pérdida 0.8708\n",
      "Epoch 2 Lote 25850 Pérdida 0.8702\n",
      "Epoch 2 Lote 25900 Pérdida 0.8697\n",
      "Epoch 2 Lote 25950 Pérdida 0.8686\n",
      "Epoch 2 Lote 26000 Pérdida 0.8673\n",
      "Epoch 2 Lote 26050 Pérdida 0.8664\n",
      "Epoch 2 Lote 26100 Pérdida 0.8654\n",
      "Epoch 2 Lote 26150 Pérdida 0.8642\n",
      "Epoch 2 Lote 26200 Pérdida 0.8630\n",
      "Epoch 2 Lote 26250 Pérdida 0.8620\n",
      "Epoch 2 Lote 26300 Pérdida 0.8611\n",
      "Epoch 2 Lote 26350 Pérdida 0.8606\n",
      "Epoch 2 Lote 26400 Pérdida 0.8594\n",
      "Epoch 2 Lote 26450 Pérdida 0.8583\n",
      "Epoch 2 Lote 26500 Pérdida 0.8572\n",
      "Epoch 2 Lote 26550 Pérdida 0.8564\n",
      "Epoch 2 Lote 26600 Pérdida 0.8559\n",
      "Epoch 2 Lote 26650 Pérdida 0.8548\n",
      "Epoch 2 Lote 26700 Pérdida 0.8537\n",
      "Epoch 2 Lote 26750 Pérdida 0.8531\n",
      "Epoch 2 Lote 26800 Pérdida 0.8519\n",
      "Epoch 2 Lote 26850 Pérdida 0.8515\n",
      "Epoch 2 Lote 26900 Pérdida 0.8510\n",
      "Epoch 2 Lote 26950 Pérdida 0.8509\n",
      "Epoch 2 Lote 27000 Pérdida 0.8506\n",
      "Epoch 2 Lote 27050 Pérdida 0.8497\n",
      "Epoch 2 Lote 27100 Pérdida 0.8493\n",
      "Epoch 2 Lote 27150 Pérdida 0.8488\n",
      "Epoch 2 Lote 27200 Pérdida 0.8480\n",
      "Epoch 2 Lote 27250 Pérdida 0.8476\n",
      "Epoch 2 Lote 27300 Pérdida 0.8469\n",
      "Epoch 2 Lote 27350 Pérdida 0.8466\n",
      "Epoch 2 Lote 27400 Pérdida 0.8458\n",
      "Epoch 2 Lote 27450 Pérdida 0.8453\n",
      "Epoch 2 Lote 27500 Pérdida 0.8449\n",
      "Epoch 2 Lote 27550 Pérdida 0.8441\n",
      "Epoch 2 Lote 27600 Pérdida 0.8434\n",
      "Epoch 2 Lote 27650 Pérdida 0.8432\n",
      "Epoch 2 Lote 27700 Pérdida 0.8429\n",
      "Epoch 2 Lote 27750 Pérdida 0.8421\n",
      "Epoch 2 Lote 27800 Pérdida 0.8415\n",
      "Epoch 2 Lote 27850 Pérdida 0.8410\n",
      "Epoch 2 Lote 27900 Pérdida 0.8406\n",
      "Epoch 2 Lote 27950 Pérdida 0.8396\n",
      "Epoch 2 Lote 28000 Pérdida 0.8390\n",
      "Epoch 2 Lote 28050 Pérdida 0.8384\n",
      "Epoch 2 Lote 28100 Pérdida 0.8373\n",
      "Epoch 2 Lote 28150 Pérdida 0.8367\n",
      "Epoch 2 Lote 28200 Pérdida 0.8364\n",
      "Epoch 2 Lote 28250 Pérdida 0.8362\n",
      "Epoch 2 Lote 28300 Pérdida 0.8358\n",
      "Epoch 2 Lote 28350 Pérdida 0.8354\n",
      "Epoch 2 Lote 28400 Pérdida 0.8346\n",
      "Epoch 2 Lote 28450 Pérdida 0.8336\n",
      "Epoch 2 Lote 28500 Pérdida 0.8329\n",
      "Epoch 2 Lote 28550 Pérdida 0.8319\n",
      "Epoch 2 Lote 28600 Pérdida 0.8309\n",
      "Epoch 2 Lote 28650 Pérdida 0.8296\n",
      "Epoch 2 Lote 28700 Pérdida 0.8286\n",
      "Epoch 2 Lote 28750 Pérdida 0.8278\n",
      "Epoch 2 Lote 28800 Pérdida 0.8266\n",
      "Epoch 2 Lote 28850 Pérdida 0.8261\n",
      "Epoch 2 Lote 28900 Pérdida 0.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Lote 28950 Pérdida 0.8249\n",
      "Epoch 2 Lote 29000 Pérdida 0.8244\n",
      "Epoch 2 Lote 29050 Pérdida 0.8236\n",
      "Epoch 2 Lote 29100 Pérdida 0.8232\n",
      "Epoch 2 Lote 29150 Pérdida 0.8234\n",
      "Epoch 2 Lote 29200 Pérdida 0.8228\n",
      "Epoch 2 Lote 29250 Pérdida 0.8220\n",
      "Epoch 2 Lote 29300 Pérdida 0.8207\n",
      "Epoch 2 Lote 29350 Pérdida 0.8197\n",
      "Epoch 2 Lote 29400 Pérdida 0.8189\n",
      "Epoch 2 Lote 29450 Pérdida 0.8183\n",
      "Epoch 2 Lote 29500 Pérdida 0.8177\n",
      "Epoch 2 Lote 29550 Pérdida 0.8179\n",
      "Epoch 2 Lote 29600 Pérdida 0.8175\n",
      "Epoch 2 Lote 29650 Pérdida 0.8176\n",
      "Epoch 2 Lote 29700 Pérdida 0.8168\n",
      "Epoch 2 Lote 29750 Pérdida 0.8175\n",
      "Epoch 2 Lote 29800 Pérdida 0.8176\n",
      "Epoch 2 Lote 29850 Pérdida 0.8170\n",
      "Epoch 2 Lote 29900 Pérdida 0.8171\n",
      "Epoch 2 Lote 29950 Pérdida 0.8164\n",
      "Epoch 2 Lote 30000 Pérdida 0.8161\n",
      "Epoch 2 Lote 30050 Pérdida 0.8150\n",
      "Epoch 2 Lote 30100 Pérdida 0.8141\n",
      "Epoch 2 Lote 30150 Pérdida 0.8130\n",
      "Epoch 2 Lote 30200 Pérdida 0.8122\n",
      "Epoch 2 Lote 30250 Pérdida 0.8114\n",
      "Epoch 2 Lote 30300 Pérdida 0.8109\n",
      "Epoch 2 Lote 30350 Pérdida 0.8107\n",
      "Epoch 2 Lote 30400 Pérdida 0.8104\n",
      "Epoch 2 Lote 30450 Pérdida 0.8104\n",
      "Epoch 2 Lote 30500 Pérdida 0.8107\n",
      "Epoch 2 Lote 30550 Pérdida 0.8105\n",
      "Epoch 2 Lote 30600 Pérdida 0.8105\n",
      "Epoch 2 Lote 30650 Pérdida 0.8099\n",
      "Epoch 2 Lote 30700 Pérdida 0.8099\n",
      "Epoch 2 Lote 30750 Pérdida 0.8092\n",
      "Epoch 2 Lote 30800 Pérdida 0.8094\n",
      "Epoch 2 Lote 30850 Pérdida 0.8091\n",
      "Epoch 2 Lote 30900 Pérdida 0.8088\n",
      "Epoch 2 Lote 30950 Pérdida 0.8081\n",
      "Epoch 2 Lote 31000 Pérdida 0.8077\n",
      "Epoch 2 Lote 31050 Pérdida 0.8076\n",
      "Epoch 2 Lote 31100 Pérdida 0.8070\n",
      "Epoch 2 Lote 31150 Pérdida 0.8069\n",
      "Epoch 2 Lote 31200 Pérdida 0.8066\n",
      "Epoch 2 Lote 31250 Pérdida 0.8061\n",
      "Epoch 2 Lote 31300 Pérdida 0.8053\n",
      "Epoch 2 Lote 31350 Pérdida 0.8051\n",
      "Epoch 2 Lote 31400 Pérdida 0.8048\n",
      "Epoch 2 Lote 31450 Pérdida 0.8045\n",
      "Epoch 2 Lote 31500 Pérdida 0.8037\n",
      "Epoch 2 Lote 31550 Pérdida 0.8029\n",
      "Epoch 2 Lote 31600 Pérdida 0.8024\n",
      "Epoch 2 Lote 31650 Pérdida 0.8018\n",
      "Epoch 2 Lote 31700 Pérdida 0.8010\n",
      "Epoch 2 Lote 31750 Pérdida 0.8003\n",
      "Epoch 2 Lote 31800 Pérdida 0.7997\n",
      "Epoch 2 Lote 31850 Pérdida 0.7990\n",
      "Epoch 2 Lote 31900 Pérdida 0.7981\n",
      "Epoch 2 Lote 31950 Pérdida 0.7972\n",
      "Epoch 2 Lote 32000 Pérdida 0.7962\n",
      "Epoch 2 Lote 32050 Pérdida 0.7955\n",
      "Epoch 2 Lote 32100 Pérdida 0.7948\n",
      "Epoch 2 Lote 32150 Pérdida 0.7938\n",
      "Epoch 2 Lote 32200 Pérdida 0.7930\n",
      "Epoch 2 Lote 32250 Pérdida 0.7924\n",
      "Epoch 2 Lote 32300 Pérdida 0.7922\n",
      "Epoch 2 Lote 32350 Pérdida 0.7914\n",
      "Epoch 2 Lote 32400 Pérdida 0.7905\n",
      "Epoch 2 Lote 32450 Pérdida 0.7899\n",
      "Epoch 2 Lote 32500 Pérdida 0.7894\n",
      "Epoch 2 Lote 32550 Pérdida 0.7888\n",
      "Epoch 2 Lote 32600 Pérdida 0.7882\n",
      "Epoch 2 Lote 32650 Pérdida 0.7880\n",
      "Epoch 2 Lote 32700 Pérdida 0.7876\n",
      "Epoch 2 Lote 32750 Pérdida 0.7867\n",
      "Epoch 2 Lote 32800 Pérdida 0.7861\n",
      "Epoch 2 Lote 32850 Pérdida 0.7857\n",
      "Epoch 2 Lote 32900 Pérdida 0.7855\n",
      "Epoch 2 Lote 32950 Pérdida 0.7852\n",
      "Epoch 2 Lote 33000 Pérdida 0.7846\n",
      "Epoch 2 Lote 33050 Pérdida 0.7840\n",
      "Epoch 2 Lote 33100 Pérdida 0.7833\n",
      "Epoch 2 Lote 33150 Pérdida 0.7823\n",
      "Epoch 2 Lote 33200 Pérdida 0.7814\n",
      "Epoch 2 Lote 33250 Pérdida 0.7804\n",
      "Epoch 2 Lote 33300 Pérdida 0.7797\n",
      "Epoch 2 Lote 33350 Pérdida 0.7787\n",
      "Epoch 2 Lote 33400 Pérdida 0.7783\n",
      "Epoch 2 Lote 33450 Pérdida 0.7776\n",
      "Epoch 2 Lote 33500 Pérdida 0.7771\n",
      "Epoch 2 Lote 33550 Pérdida 0.7768\n",
      "Epoch 2 Lote 33600 Pérdida 0.7763\n",
      "Epoch 2 Lote 33650 Pérdida 0.7758\n",
      "Epoch 2 Lote 33700 Pérdida 0.7753\n",
      "Epoch 2 Lote 33750 Pérdida 0.7748\n",
      "Epoch 2 Lote 33800 Pérdida 0.7747\n",
      "Epoch 2 Lote 33850 Pérdida 0.7742\n",
      "Epoch 2 Lote 33900 Pérdida 0.7738\n",
      "Epoch 2 Lote 33950 Pérdida 0.7734\n",
      "Epoch 2 Lote 34000 Pérdida 0.7725\n",
      "Epoch 2 Lote 34050 Pérdida 0.7719\n",
      "Epoch 2 Lote 34100 Pérdida 0.7712\n",
      "Epoch 2 Lote 34150 Pérdida 0.7704\n",
      "Epoch 2 Lote 34200 Pérdida 0.7699\n",
      "Epoch 2 Lote 34250 Pérdida 0.7692\n",
      "Epoch 2 Lote 34300 Pérdida 0.7687\n",
      "Epoch 2 Lote 34350 Pérdida 0.7685\n",
      "Epoch 2 Lote 34400 Pérdida 0.7684\n",
      "Epoch 2 Lote 34450 Pérdida 0.7680\n",
      "Epoch 2 Lote 34500 Pérdida 0.7675\n",
      "Epoch 2 Lote 34550 Pérdida 0.7669\n",
      "Epoch 2 Lote 34600 Pérdida 0.7666\n",
      "Epoch 2 Lote 34650 Pérdida 0.7660\n",
      "Epoch 2 Lote 34700 Pérdida 0.7656\n",
      "Epoch 2 Lote 34750 Pérdida 0.7654\n",
      "Epoch 2 Lote 34800 Pérdida 0.7653\n",
      "Epoch 2 Lote 34850 Pérdida 0.7658\n",
      "Epoch 2 Lote 34900 Pérdida 0.7664\n",
      "Epoch 2 Lote 34950 Pérdida 0.7672\n",
      "Epoch 2 Lote 35000 Pérdida 0.7677\n",
      "Epoch 2 Lote 35050 Pérdida 0.7688\n",
      "Epoch 2 Lote 35100 Pérdida 0.7693\n",
      "Epoch 2 Lote 35150 Pérdida 0.7692\n",
      "Epoch 2 Lote 35200 Pérdida 0.7687\n",
      "Epoch 2 Lote 35250 Pérdida 0.7681\n",
      "Epoch 2 Lote 35300 Pérdida 0.7675\n",
      "Epoch 2 Lote 35350 Pérdida 0.7672\n",
      "Epoch 2 Lote 35400 Pérdida 0.7664\n",
      "Epoch 2 Lote 35450 Pérdida 0.7656\n",
      "Epoch 2 Lote 35500 Pérdida 0.7652\n",
      "Epoch 2 Lote 35550 Pérdida 0.7645\n",
      "Epoch 2 Lote 35600 Pérdida 0.7639\n",
      "Epoch 2 Lote 35650 Pérdida 0.7632\n",
      "Epoch 2 Lote 35700 Pérdida 0.7628\n",
      "Epoch 2 Lote 35750 Pérdida 0.7622\n",
      "Epoch 2 Lote 35800 Pérdida 0.7619\n",
      "Epoch 2 Lote 35850 Pérdida 0.7619\n",
      "Epoch 2 Lote 35900 Pérdida 0.7617\n",
      "Epoch 2 Lote 35950 Pérdida 0.7620\n",
      "Epoch 2 Lote 36000 Pérdida 0.7627\n",
      "Epoch 2 Lote 36050 Pérdida 0.7632\n",
      "Epoch 2 Lote 36100 Pérdida 0.7644\n",
      "Epoch 2 Lote 36150 Pérdida 0.7648\n",
      "Epoch 2 Lote 36200 Pérdida 0.7645\n",
      "Epoch 2 Lote 36250 Pérdida 0.7643\n",
      "Epoch 2 Lote 36300 Pérdida 0.7640\n",
      "Epoch 2 Lote 36350 Pérdida 0.7632\n",
      "Epoch 2 Lote 36400 Pérdida 0.7632\n",
      "Epoch 2 Lote 36450 Pérdida 0.7644\n",
      "Epoch 2 Lote 36500 Pérdida 0.7653\n",
      "Epoch 2 Lote 36550 Pérdida 0.7662\n",
      "Epoch 2 Lote 36600 Pérdida 0.7681\n",
      "Epoch 2 Lote 36650 Pérdida 0.7691\n",
      "Epoch 2 Lote 36700 Pérdida 0.7693\n",
      "Epoch 2 Lote 36750 Pérdida 0.7698\n",
      "Epoch 2 Lote 36800 Pérdida 0.7696\n",
      "Epoch 2 Lote 36850 Pérdida 0.7698\n",
      "Epoch 2 Lote 36900 Pérdida 0.7696\n",
      "Epoch 2 Lote 36950 Pérdida 0.7689\n",
      "Epoch 2 Lote 37000 Pérdida 0.7682\n",
      "Epoch 2 Lote 37050 Pérdida 0.7676\n",
      "Epoch 2 Lote 37100 Pérdida 0.7674\n",
      "Epoch 2 Lote 37150 Pérdida 0.7670\n",
      "Epoch 2 Lote 37200 Pérdida 0.7665\n",
      "Epoch 2 Lote 37250 Pérdida 0.7659\n",
      "Epoch 2 Lote 37300 Pérdida 0.7655\n",
      "Epoch 2 Lote 37350 Pérdida 0.7655\n",
      "Epoch 2 Lote 37400 Pérdida 0.7653\n",
      "Epoch 2 Lote 37450 Pérdida 0.7646\n",
      "Epoch 2 Lote 37500 Pérdida 0.7645\n",
      "Epoch 2 Lote 37550 Pérdida 0.7641\n",
      "Epoch 2 Lote 37600 Pérdida 0.7639\n",
      "Epoch 2 Lote 37650 Pérdida 0.7640\n",
      "Epoch 2 Lote 37700 Pérdida 0.7636\n",
      "Epoch 2 Lote 37750 Pérdida 0.7634\n",
      "Epoch 2 Lote 37800 Pérdida 0.7632\n",
      "Epoch 2 Lote 37850 Pérdida 0.7628\n",
      "Epoch 2 Lote 37900 Pérdida 0.7625\n",
      "Epoch 2 Lote 37950 Pérdida 0.7626\n",
      "Epoch 2 Lote 38000 Pérdida 0.7626\n",
      "Epoch 2 Lote 38050 Pérdida 0.7627\n",
      "Epoch 2 Lote 38100 Pérdida 0.7624\n",
      "Epoch 2 Lote 38150 Pérdida 0.7624\n",
      "Epoch 2 Lote 38200 Pérdida 0.7623\n",
      "Epoch 2 Lote 38250 Pérdida 0.7617\n",
      "Epoch 2 Lote 38300 Pérdida 0.7614\n",
      "Epoch 2 Lote 38350 Pérdida 0.7612\n",
      "Epoch 2 Lote 38400 Pérdida 0.7615\n",
      "Epoch 2 Lote 38450 Pérdida 0.7611\n",
      "Epoch 2 Lote 38500 Pérdida 0.7610\n",
      "Epoch 2 Lote 38550 Pérdida 0.7606\n",
      "Epoch 2 Lote 38600 Pérdida 0.7599\n",
      "Epoch 2 Lote 38650 Pérdida 0.7591\n",
      "Epoch 2 Lote 38700 Pérdida 0.7589\n",
      "Epoch 2 Lote 38750 Pérdida 0.7581\n",
      "Epoch 2 Lote 38800 Pérdida 0.7581\n",
      "Epoch 2 Lote 38850 Pérdida 0.7575\n",
      "Epoch 2 Lote 38900 Pérdida 0.7567\n",
      "Epoch 2 Lote 38950 Pérdida 0.7564\n",
      "Epoch 2 Lote 39000 Pérdida 0.7557\n",
      "Epoch 2 Lote 39050 Pérdida 0.7550\n",
      "Epoch 2 Lote 39100 Pérdida 0.7544\n",
      "Epoch 2 Lote 39150 Pérdida 0.7538\n",
      "Epoch 2 Lote 39200 Pérdida 0.7535\n",
      "Epoch 2 Lote 39250 Pérdida 0.7530\n",
      "Epoch 2 Lote 39300 Pérdida 0.7524\n",
      "Epoch 2 Lote 39350 Pérdida 0.7519\n",
      "Epoch 2 Lote 39400 Pérdida 0.7513\n",
      "Epoch 2 Lote 39450 Pérdida 0.7505\n",
      "Epoch 2 Lote 39500 Pérdida 0.7498\n",
      "Epoch 2 Lote 39550 Pérdida 0.7493\n",
      "Epoch 2 Lote 39600 Pérdida 0.7487\n",
      "Epoch 2 Lote 39650 Pérdida 0.7480\n",
      "Epoch 2 Lote 39700 Pérdida 0.7483\n",
      "Epoch 2 Lote 39750 Pérdida 0.7500\n",
      "Epoch 2 Lote 39800 Pérdida 0.7506\n",
      "Epoch 2 Lote 39850 Pérdida 0.7512\n",
      "Epoch 2 Lote 39900 Pérdida 0.7512\n",
      "Epoch 2 Lote 39950 Pérdida 0.7512\n",
      "Epoch 2 Lote 40000 Pérdida 0.7511\n",
      "Epoch 2 Lote 40050 Pérdida 0.7508\n",
      "Epoch 2 Lote 40100 Pérdida 0.7505\n",
      "Epoch 2 Lote 40150 Pérdida 0.7502\n",
      "Epoch 2 Lote 40200 Pérdida 0.7494\n",
      "Epoch 2 Lote 40250 Pérdida 0.7488\n",
      "Epoch 2 Lote 40300 Pérdida 0.7484\n",
      "Epoch 2 Lote 40350 Pérdida 0.7482\n",
      "Epoch 2 Lote 40400 Pérdida 0.7489\n",
      "Epoch 2 Lote 40450 Pérdida 0.7508\n",
      "Epoch 2 Lote 40500 Pérdida 0.7522\n",
      "Epoch 2 Lote 40550 Pérdida 0.7528\n",
      "Epoch 2 Lote 40600 Pérdida 0.7529\n",
      "Epoch 2 Lote 40650 Pérdida 0.7530\n",
      "Epoch 2 Lote 40700 Pérdida 0.7526\n",
      "Epoch 2 Lote 40750 Pérdida 0.7526\n",
      "Epoch 2 Lote 40800 Pérdida 0.7523\n",
      "Epoch 2 Lote 40850 Pérdida 0.7525\n",
      "Epoch 2 Lote 40900 Pérdida 0.7525\n",
      "Epoch 2 Lote 40950 Pérdida 0.7520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Lote 41000 Pérdida 0.7517\n",
      "Epoch 2 Lote 41050 Pérdida 0.7517\n",
      "Epoch 2 Lote 41100 Pérdida 0.7519\n",
      "Epoch 2 Lote 41150 Pérdida 0.7516\n",
      "Epoch 2 Lote 41200 Pérdida 0.7520\n",
      "Epoch 2 Lote 41250 Pérdida 0.7518\n",
      "Epoch 2 Lote 41300 Pérdida 0.7520\n",
      "Epoch 2 Lote 41350 Pérdida 0.7524\n",
      "Epoch 2 Lote 41400 Pérdida 0.7526\n",
      "Epoch 2 Lote 41450 Pérdida 0.7528\n",
      "Epoch 2 Lote 41500 Pérdida 0.7524\n",
      "Epoch 2 Lote 41550 Pérdida 0.7522\n",
      "Epoch 2 Lote 41600 Pérdida 0.7517\n",
      "Epoch 2 Lote 41650 Pérdida 0.7517\n",
      "Epoch 2 Lote 41700 Pérdida 0.7514\n",
      "Epoch 2 Lote 41750 Pérdida 0.7514\n",
      "Epoch 2 Lote 41800 Pérdida 0.7514\n",
      "Epoch 2 Lote 41850 Pérdida 0.7520\n",
      "Epoch 2 Lote 41900 Pérdida 0.7524\n",
      "Epoch 2 Lote 41950 Pérdida 0.7525\n",
      "Epoch 2 Lote 42000 Pérdida 0.7534\n",
      "Epoch 2 Lote 42050 Pérdida 0.7542\n",
      "Epoch 2 Lote 42100 Pérdida 0.7550\n",
      "Epoch 2 Lote 42150 Pérdida 0.7554\n",
      "Epoch 2 Lote 42200 Pérdida 0.7560\n",
      "Epoch 2 Lote 42250 Pérdida 0.7559\n",
      "Epoch 2 Lote 42300 Pérdida 0.7564\n",
      "Epoch 2 Lote 42350 Pérdida 0.7570\n",
      "Epoch 2 Lote 42400 Pérdida 0.7570\n",
      "Epoch 2 Lote 42450 Pérdida 0.7575\n",
      "Epoch 2 Lote 42500 Pérdida 0.7576\n",
      "Epoch 2 Lote 42550 Pérdida 0.7579\n",
      "Epoch 2 Lote 42600 Pérdida 0.7580\n",
      "Epoch 2 Lote 42650 Pérdida 0.7579\n",
      "Epoch 2 Lote 42700 Pérdida 0.7578\n",
      "Epoch 2 Lote 42750 Pérdida 0.7573\n",
      "Epoch 2 Lote 42800 Pérdida 0.7570\n",
      "Epoch 2 Lote 42850 Pérdida 0.7573\n",
      "Epoch 2 Lote 42900 Pérdida 0.7575\n",
      "Epoch 2 Lote 42950 Pérdida 0.7576\n",
      "Epoch 2 Lote 43000 Pérdida 0.7580\n",
      "Epoch 2 Lote 43050 Pérdida 0.7585\n",
      "Epoch 2 Lote 43100 Pérdida 0.7588\n",
      "Epoch 2 Lote 43150 Pérdida 0.7591\n",
      "Epoch 2 Lote 43200 Pérdida 0.7596\n",
      "Epoch 2 Lote 43250 Pérdida 0.7602\n",
      "Epoch 2 Lote 43300 Pérdida 0.7614\n",
      "Epoch 2 Lote 43350 Pérdida 0.7634\n",
      "Epoch 2 Lote 43400 Pérdida 0.7646\n",
      "Epoch 2 Lote 43450 Pérdida 0.7657\n",
      "Epoch 2 Lote 43500 Pérdida 0.7662\n",
      "Epoch 2 Lote 43550 Pérdida 0.7672\n",
      "Epoch 2 Lote 43600 Pérdida 0.7681\n",
      "Epoch 2 Lote 43650 Pérdida 0.7696\n",
      "Epoch 2 Lote 43700 Pérdida 0.7707\n",
      "Epoch 2 Lote 43750 Pérdida 0.7715\n",
      "Epoch 2 Lote 43800 Pérdida 0.7726\n",
      "Epoch 2 Lote 43850 Pérdida 0.7738\n",
      "Epoch 2 Lote 43900 Pérdida 0.7742\n",
      "Epoch 2 Lote 43950 Pérdida 0.7747\n",
      "Tiempo total para entrenar 1 epoch: 4196.6369750499725 segs\n",
      "\n",
      "Inicio del Epoch 3\n",
      "Epoch 3 Lote 0 Pérdida 0.0015\n",
      "Epoch 3 Lote 50 Pérdida 1.4032\n",
      "Epoch 3 Lote 100 Pérdida 1.1401\n",
      "Epoch 3 Lote 150 Pérdida 1.1000\n",
      "Epoch 3 Lote 200 Pérdida 1.0536\n",
      "Epoch 3 Lote 250 Pérdida 1.2218\n",
      "Epoch 3 Lote 300 Pérdida 1.2476\n",
      "Epoch 3 Lote 350 Pérdida 1.2454\n",
      "Epoch 3 Lote 400 Pérdida 1.3441\n",
      "Epoch 3 Lote 450 Pérdida 1.4490\n",
      "Epoch 3 Lote 500 Pérdida 1.4678\n",
      "Epoch 3 Lote 550 Pérdida 1.4850\n",
      "Epoch 3 Lote 600 Pérdida 1.4650\n",
      "Epoch 3 Lote 650 Pérdida 1.4860\n",
      "Epoch 3 Lote 700 Pérdida 1.5434\n",
      "Epoch 3 Lote 750 Pérdida 1.5804\n",
      "Epoch 3 Lote 800 Pérdida 1.5648\n",
      "Epoch 3 Lote 850 Pérdida 1.5812\n",
      "Epoch 3 Lote 900 Pérdida 1.5666\n",
      "Epoch 3 Lote 950 Pérdida 1.5531\n",
      "Epoch 3 Lote 1000 Pérdida 1.5507\n",
      "Epoch 3 Lote 1050 Pérdida 1.5467\n",
      "Epoch 3 Lote 1100 Pérdida 1.5187\n",
      "Epoch 3 Lote 1150 Pérdida 1.5056\n",
      "Epoch 3 Lote 1200 Pérdida 1.4955\n",
      "Epoch 3 Lote 1250 Pérdida 1.4943\n",
      "Epoch 3 Lote 1300 Pérdida 1.5097\n",
      "Epoch 3 Lote 1350 Pérdida 1.5055\n",
      "Epoch 3 Lote 1400 Pérdida 1.5146\n",
      "Epoch 3 Lote 1450 Pérdida 1.5180\n",
      "Epoch 3 Lote 1500 Pérdida 1.5085\n",
      "Epoch 3 Lote 1550 Pérdida 1.5001\n",
      "Epoch 3 Lote 1600 Pérdida 1.4900\n",
      "Epoch 3 Lote 1650 Pérdida 1.4944\n",
      "Epoch 3 Lote 1700 Pérdida 1.4757\n",
      "Epoch 3 Lote 1750 Pérdida 1.4570\n",
      "Epoch 3 Lote 1800 Pérdida 1.4444\n",
      "Epoch 3 Lote 1850 Pérdida 1.4394\n",
      "Epoch 3 Lote 1900 Pérdida 1.4444\n",
      "Epoch 3 Lote 1950 Pérdida 1.4353\n",
      "Epoch 3 Lote 2000 Pérdida 1.4251\n",
      "Epoch 3 Lote 2050 Pérdida 1.4207\n",
      "Epoch 3 Lote 2100 Pérdida 1.4161\n",
      "Epoch 3 Lote 2150 Pérdida 1.3972\n",
      "Epoch 3 Lote 2200 Pérdida 1.3905\n",
      "Epoch 3 Lote 2250 Pérdida 1.3841\n",
      "Epoch 3 Lote 2300 Pérdida 1.3960\n",
      "Epoch 3 Lote 2350 Pérdida 1.3959\n",
      "Epoch 3 Lote 2400 Pérdida 1.3983\n",
      "Epoch 3 Lote 2450 Pérdida 1.4089\n",
      "Epoch 3 Lote 2500 Pérdida 1.4110\n",
      "Epoch 3 Lote 2550 Pérdida 1.4005\n",
      "Epoch 3 Lote 2600 Pérdida 1.4094\n",
      "Epoch 3 Lote 2650 Pérdida 1.4094\n",
      "Epoch 3 Lote 2700 Pérdida 1.4085\n",
      "Epoch 3 Lote 2750 Pérdida 1.4163\n",
      "Epoch 3 Lote 2800 Pérdida 1.4079\n",
      "Epoch 3 Lote 2850 Pérdida 1.4052\n",
      "Epoch 3 Lote 2900 Pérdida 1.4048\n",
      "Epoch 3 Lote 2950 Pérdida 1.4045\n",
      "Epoch 3 Lote 3000 Pérdida 1.3990\n",
      "Epoch 3 Lote 3050 Pérdida 1.3936\n",
      "Epoch 3 Lote 3100 Pérdida 1.3871\n",
      "Epoch 3 Lote 3150 Pérdida 1.3916\n",
      "Epoch 3 Lote 3200 Pérdida 1.3843\n",
      "Epoch 3 Lote 3250 Pérdida 1.3928\n",
      "Epoch 3 Lote 3300 Pérdida 1.3917\n",
      "Epoch 3 Lote 3350 Pérdida 1.3903\n",
      "Epoch 3 Lote 3400 Pérdida 1.3806\n",
      "Epoch 3 Lote 3450 Pérdida 1.3802\n",
      "Epoch 3 Lote 3500 Pérdida 1.3777\n",
      "Epoch 3 Lote 3550 Pérdida 1.3775\n",
      "Epoch 3 Lote 3600 Pérdida 1.3717\n",
      "Epoch 3 Lote 3650 Pérdida 1.3703\n",
      "Epoch 3 Lote 3700 Pérdida 1.3619\n",
      "Epoch 3 Lote 3750 Pérdida 1.3660\n",
      "Epoch 3 Lote 3800 Pérdida 1.3677\n",
      "Epoch 3 Lote 3850 Pérdida 1.3659\n",
      "Epoch 3 Lote 3900 Pérdida 1.3564\n",
      "Epoch 3 Lote 3950 Pérdida 1.3493\n",
      "Epoch 3 Lote 4000 Pérdida 1.3362\n",
      "Epoch 3 Lote 4050 Pérdida 1.3297\n",
      "Epoch 3 Lote 4100 Pérdida 1.3208\n",
      "Epoch 3 Lote 4150 Pérdida 1.3141\n",
      "Epoch 3 Lote 4200 Pérdida 1.3139\n",
      "Epoch 3 Lote 4250 Pérdida 1.3069\n",
      "Epoch 3 Lote 4300 Pérdida 1.3063\n",
      "Epoch 3 Lote 4350 Pérdida 1.3050\n",
      "Epoch 3 Lote 4400 Pérdida 1.2985\n",
      "Epoch 3 Lote 4450 Pérdida 1.2930\n",
      "Epoch 3 Lote 4500 Pérdida 1.2872\n",
      "Epoch 3 Lote 4550 Pérdida 1.2778\n",
      "Epoch 3 Lote 4600 Pérdida 1.2729\n",
      "Epoch 3 Lote 4650 Pérdida 1.2711\n",
      "Epoch 3 Lote 4700 Pérdida 1.2677\n",
      "Epoch 3 Lote 4750 Pérdida 1.2631\n",
      "Epoch 3 Lote 4800 Pérdida 1.2603\n",
      "Epoch 3 Lote 4850 Pérdida 1.2563\n",
      "Epoch 3 Lote 4900 Pérdida 1.2566\n",
      "Epoch 3 Lote 4950 Pérdida 1.2590\n",
      "Epoch 3 Lote 5000 Pérdida 1.2554\n",
      "Epoch 3 Lote 5050 Pérdida 1.2560\n",
      "Epoch 3 Lote 5100 Pérdida 1.2540\n",
      "Epoch 3 Lote 5150 Pérdida 1.2498\n",
      "Epoch 3 Lote 5200 Pérdida 1.2533\n",
      "Epoch 3 Lote 5250 Pérdida 1.2579\n",
      "Epoch 3 Lote 5300 Pérdida 1.2615\n",
      "Epoch 3 Lote 5350 Pérdida 1.2607\n",
      "Epoch 3 Lote 5400 Pérdida 1.2571\n",
      "Epoch 3 Lote 5450 Pérdida 1.2554\n",
      "Epoch 3 Lote 5500 Pérdida 1.2510\n",
      "Epoch 3 Lote 5550 Pérdida 1.2476\n",
      "Epoch 3 Lote 5600 Pérdida 1.2416\n",
      "Epoch 3 Lote 5650 Pérdida 1.2395\n",
      "Epoch 3 Lote 5700 Pérdida 1.2337\n",
      "Epoch 3 Lote 5750 Pérdida 1.2331\n",
      "Epoch 3 Lote 5800 Pérdida 1.2296\n",
      "Epoch 3 Lote 5850 Pérdida 1.2265\n",
      "Epoch 3 Lote 5900 Pérdida 1.2218\n",
      "Epoch 3 Lote 5950 Pérdida 1.2212\n",
      "Epoch 3 Lote 6000 Pérdida 1.2189\n",
      "Epoch 3 Lote 6050 Pérdida 1.2200\n",
      "Epoch 3 Lote 6100 Pérdida 1.2146\n",
      "Epoch 3 Lote 6150 Pérdida 1.2087\n",
      "Epoch 3 Lote 6200 Pérdida 1.2083\n",
      "Epoch 3 Lote 6250 Pérdida 1.2051\n",
      "Epoch 3 Lote 6300 Pérdida 1.2035\n",
      "Epoch 3 Lote 6350 Pérdida 1.2013\n",
      "Epoch 3 Lote 6400 Pérdida 1.2032\n",
      "Epoch 3 Lote 6450 Pérdida 1.2085\n",
      "Epoch 3 Lote 6500 Pérdida 1.2120\n",
      "Epoch 3 Lote 6550 Pérdida 1.2116\n",
      "Epoch 3 Lote 6600 Pérdida 1.2130\n",
      "Epoch 3 Lote 6650 Pérdida 1.2159\n",
      "Epoch 3 Lote 6700 Pérdida 1.2176\n",
      "Epoch 3 Lote 6750 Pérdida 1.2180\n",
      "Epoch 3 Lote 6800 Pérdida 1.2203\n",
      "Epoch 3 Lote 6850 Pérdida 1.2320\n",
      "Epoch 3 Lote 6900 Pérdida 1.2287\n",
      "Epoch 3 Lote 6950 Pérdida 1.2296\n",
      "Epoch 3 Lote 7000 Pérdida 1.2264\n",
      "Epoch 3 Lote 7050 Pérdida 1.2225\n",
      "Epoch 3 Lote 7100 Pérdida 1.2229\n",
      "Epoch 3 Lote 7150 Pérdida 1.2289\n",
      "Epoch 3 Lote 7200 Pérdida 1.2318\n",
      "Epoch 3 Lote 7250 Pérdida 1.2329\n",
      "Epoch 3 Lote 7300 Pérdida 1.2329\n",
      "Epoch 3 Lote 7350 Pérdida 1.2356\n",
      "Epoch 3 Lote 7400 Pérdida 1.2348\n",
      "Epoch 3 Lote 7450 Pérdida 1.2311\n",
      "Epoch 3 Lote 7500 Pérdida 1.2296\n",
      "Epoch 3 Lote 7550 Pérdida 1.2272\n",
      "Epoch 3 Lote 7600 Pérdida 1.2274\n",
      "Epoch 3 Lote 7650 Pérdida 1.2239\n",
      "Epoch 3 Lote 7700 Pérdida 1.2224\n",
      "Epoch 3 Lote 7750 Pérdida 1.2205\n",
      "Epoch 3 Lote 7800 Pérdida 1.2185\n",
      "Epoch 3 Lote 7850 Pérdida 1.2159\n",
      "Epoch 3 Lote 7900 Pérdida 1.2166\n",
      "Epoch 3 Lote 7950 Pérdida 1.2159\n",
      "Epoch 3 Lote 8000 Pérdida 1.2164\n",
      "Epoch 3 Lote 8050 Pérdida 1.2182\n",
      "Epoch 3 Lote 8100 Pérdida 1.2206\n",
      "Epoch 3 Lote 8150 Pérdida 1.2173\n",
      "Epoch 3 Lote 8200 Pérdida 1.2157\n",
      "Epoch 3 Lote 8250 Pérdida 1.2144\n",
      "Epoch 3 Lote 8300 Pérdida 1.2143\n",
      "Epoch 3 Lote 8350 Pérdida 1.2127\n",
      "Epoch 3 Lote 8400 Pérdida 1.2119\n",
      "Epoch 3 Lote 8450 Pérdida 1.2100\n",
      "Epoch 3 Lote 8500 Pérdida 1.2063\n",
      "Epoch 3 Lote 8550 Pérdida 1.2041\n",
      "Epoch 3 Lote 8600 Pérdida 1.2017\n",
      "Epoch 3 Lote 8650 Pérdida 1.2005\n",
      "Epoch 3 Lote 8700 Pérdida 1.2024\n",
      "Epoch 3 Lote 8750 Pérdida 1.2057\n",
      "Epoch 3 Lote 8800 Pérdida 1.2059\n",
      "Epoch 3 Lote 8850 Pérdida 1.2080\n",
      "Epoch 3 Lote 8900 Pérdida 1.2068\n",
      "Epoch 3 Lote 8950 Pérdida 1.2079\n",
      "Epoch 3 Lote 9000 Pérdida 1.2082\n",
      "Epoch 3 Lote 9050 Pérdida 1.2065\n",
      "Epoch 3 Lote 9100 Pérdida 1.2042\n",
      "Epoch 3 Lote 9150 Pérdida 1.2007\n",
      "Epoch 3 Lote 9200 Pérdida 1.1981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Lote 9250 Pérdida 1.1953\n",
      "Epoch 3 Lote 9300 Pérdida 1.1945\n",
      "Epoch 3 Lote 9350 Pérdida 1.1917\n",
      "Epoch 3 Lote 9400 Pérdida 1.1877\n",
      "Epoch 3 Lote 9450 Pérdida 1.1851\n",
      "Epoch 3 Lote 9500 Pérdida 1.1829\n",
      "Epoch 3 Lote 9550 Pérdida 1.1794\n",
      "Epoch 3 Lote 9600 Pérdida 1.1766\n",
      "Epoch 3 Lote 9650 Pérdida 1.1737\n",
      "Epoch 3 Lote 9700 Pérdida 1.1694\n",
      "Epoch 3 Lote 9750 Pérdida 1.1668\n",
      "Epoch 3 Lote 9800 Pérdida 1.1628\n",
      "Epoch 3 Lote 9850 Pérdida 1.1586\n",
      "Epoch 3 Lote 9900 Pérdida 1.1558\n",
      "Epoch 3 Lote 9950 Pérdida 1.1547\n",
      "Epoch 3 Lote 10000 Pérdida 1.1502\n",
      "Epoch 3 Lote 10050 Pérdida 1.1485\n",
      "Epoch 3 Lote 10100 Pérdida 1.1457\n",
      "Epoch 3 Lote 10150 Pérdida 1.1419\n",
      "Epoch 3 Lote 10200 Pérdida 1.1395\n",
      "Epoch 3 Lote 10250 Pérdida 1.1388\n",
      "Epoch 3 Lote 10300 Pérdida 1.1364\n",
      "Epoch 3 Lote 10350 Pérdida 1.1339\n",
      "Epoch 3 Lote 10400 Pérdida 1.1339\n",
      "Epoch 3 Lote 10450 Pérdida 1.1355\n",
      "Epoch 3 Lote 10500 Pérdida 1.1358\n",
      "Epoch 3 Lote 10550 Pérdida 1.1358\n",
      "Epoch 3 Lote 10600 Pérdida 1.1340\n",
      "Epoch 3 Lote 10650 Pérdida 1.1330\n",
      "Epoch 3 Lote 10700 Pérdida 1.1336\n",
      "Epoch 3 Lote 10750 Pérdida 1.1344\n",
      "Epoch 3 Lote 10800 Pérdida 1.1345\n",
      "Epoch 3 Lote 10850 Pérdida 1.1352\n",
      "Epoch 3 Lote 10900 Pérdida 1.1353\n",
      "Epoch 3 Lote 10950 Pérdida 1.1349\n",
      "Epoch 3 Lote 11000 Pérdida 1.1331\n",
      "Epoch 3 Lote 11050 Pérdida 1.1327\n",
      "Epoch 3 Lote 11100 Pérdida 1.1333\n",
      "Epoch 3 Lote 11150 Pérdida 1.1328\n",
      "Epoch 3 Lote 11200 Pérdida 1.1327\n",
      "Epoch 3 Lote 11250 Pérdida 1.1304\n",
      "Epoch 3 Lote 11300 Pérdida 1.1271\n",
      "Epoch 3 Lote 11350 Pérdida 1.1265\n",
      "Epoch 3 Lote 11400 Pérdida 1.1244\n",
      "Epoch 3 Lote 11450 Pérdida 1.1215\n",
      "Epoch 3 Lote 11500 Pérdida 1.1194\n",
      "Epoch 3 Lote 11550 Pérdida 1.1162\n",
      "Epoch 3 Lote 11600 Pérdida 1.1134\n",
      "Epoch 3 Lote 11650 Pérdida 1.1110\n",
      "Epoch 3 Lote 11700 Pérdida 1.1078\n",
      "Epoch 3 Lote 11750 Pérdida 1.1075\n",
      "Epoch 3 Lote 11800 Pérdida 1.1073\n",
      "Epoch 3 Lote 11850 Pérdida 1.1054\n",
      "Epoch 3 Lote 11900 Pérdida 1.1080\n",
      "Epoch 3 Lote 11950 Pérdida 1.1060\n",
      "Epoch 3 Lote 12000 Pérdida 1.1031\n",
      "Epoch 3 Lote 12050 Pérdida 1.1002\n",
      "Epoch 3 Lote 12100 Pérdida 1.0983\n",
      "Epoch 3 Lote 12150 Pérdida 1.0972\n",
      "Epoch 3 Lote 12200 Pérdida 1.0947\n",
      "Epoch 3 Lote 12250 Pérdida 1.0948\n",
      "Epoch 3 Lote 12300 Pérdida 1.0934\n",
      "Epoch 3 Lote 12350 Pérdida 1.0927\n",
      "Epoch 3 Lote 12400 Pérdida 1.0901\n",
      "Epoch 3 Lote 12450 Pérdida 1.0886\n",
      "Epoch 3 Lote 12500 Pérdida 1.0876\n",
      "Epoch 3 Lote 12550 Pérdida 1.0852\n",
      "Epoch 3 Lote 12600 Pérdida 1.0832\n",
      "Epoch 3 Lote 12650 Pérdida 1.0802\n",
      "Epoch 3 Lote 12700 Pérdida 1.0782\n",
      "Epoch 3 Lote 12750 Pérdida 1.0776\n",
      "Epoch 3 Lote 12800 Pérdida 1.0776\n",
      "Epoch 3 Lote 12850 Pérdida 1.0766\n",
      "Epoch 3 Lote 12900 Pérdida 1.0746\n",
      "Epoch 3 Lote 12950 Pérdida 1.0726\n",
      "Epoch 3 Lote 13000 Pérdida 1.0701\n",
      "Epoch 3 Lote 13050 Pérdida 1.0694\n",
      "Epoch 3 Lote 13100 Pérdida 1.0685\n",
      "Epoch 3 Lote 13150 Pérdida 1.0681\n",
      "Epoch 3 Lote 13200 Pérdida 1.0689\n",
      "Epoch 3 Lote 13250 Pérdida 1.0668\n",
      "Epoch 3 Lote 13300 Pérdida 1.0659\n",
      "Epoch 3 Lote 13350 Pérdida 1.0657\n",
      "Epoch 3 Lote 13400 Pérdida 1.0628\n",
      "Epoch 3 Lote 13450 Pérdida 1.0611\n",
      "Epoch 3 Lote 13500 Pérdida 1.0599\n",
      "Epoch 3 Lote 13550 Pérdida 1.0585\n",
      "Epoch 3 Lote 13600 Pérdida 1.0586\n",
      "Epoch 3 Lote 13650 Pérdida 1.0573\n",
      "Epoch 3 Lote 13700 Pérdida 1.0556\n",
      "Epoch 3 Lote 13750 Pérdida 1.0549\n",
      "Epoch 3 Lote 13800 Pérdida 1.0534\n",
      "Epoch 3 Lote 13850 Pérdida 1.0528\n",
      "Epoch 3 Lote 13900 Pérdida 1.0504\n",
      "Epoch 3 Lote 13950 Pérdida 1.0496\n",
      "Epoch 3 Lote 14000 Pérdida 1.0506\n",
      "Epoch 3 Lote 14050 Pérdida 1.0491\n",
      "Epoch 3 Lote 14100 Pérdida 1.0487\n",
      "Epoch 3 Lote 14150 Pérdida 1.0485\n",
      "Epoch 3 Lote 14200 Pérdida 1.0465\n",
      "Epoch 3 Lote 14250 Pérdida 1.0457\n",
      "Epoch 3 Lote 14300 Pérdida 1.0463\n",
      "Epoch 3 Lote 14350 Pérdida 1.0443\n",
      "Epoch 3 Lote 14400 Pérdida 1.0423\n",
      "Epoch 3 Lote 14450 Pérdida 1.0413\n",
      "Epoch 3 Lote 14500 Pérdida 1.0407\n",
      "Epoch 3 Lote 14550 Pérdida 1.0430\n",
      "Epoch 3 Lote 14600 Pérdida 1.0407\n",
      "Epoch 3 Lote 14650 Pérdida 1.0393\n",
      "Epoch 3 Lote 14700 Pérdida 1.0397\n",
      "Epoch 3 Lote 14750 Pérdida 1.0391\n",
      "Epoch 3 Lote 14800 Pérdida 1.0407\n",
      "Epoch 3 Lote 14850 Pérdida 1.0390\n",
      "Epoch 3 Lote 14900 Pérdida 1.0383\n",
      "Epoch 3 Lote 14950 Pérdida 1.0383\n",
      "Epoch 3 Lote 15000 Pérdida 1.0368\n",
      "Epoch 3 Lote 15050 Pérdida 1.0355\n",
      "Epoch 3 Lote 15100 Pérdida 1.0358\n",
      "Epoch 3 Lote 15150 Pérdida 1.0357\n",
      "Epoch 3 Lote 15200 Pérdida 1.0346\n",
      "Epoch 3 Lote 15250 Pérdida 1.0340\n",
      "Epoch 3 Lote 15300 Pérdida 1.0335\n",
      "Epoch 3 Lote 15350 Pérdida 1.0331\n",
      "Epoch 3 Lote 15400 Pérdida 1.0321\n",
      "Epoch 3 Lote 15450 Pérdida 1.0327\n",
      "Epoch 3 Lote 15500 Pérdida 1.0311\n",
      "Epoch 3 Lote 15550 Pérdida 1.0298\n",
      "Epoch 3 Lote 15600 Pérdida 1.0298\n",
      "Epoch 3 Lote 15650 Pérdida 1.0293\n",
      "Epoch 3 Lote 15700 Pérdida 1.0280\n",
      "Epoch 3 Lote 15750 Pérdida 1.0276\n",
      "Epoch 3 Lote 15800 Pérdida 1.0280\n",
      "Epoch 3 Lote 15850 Pérdida 1.0284\n",
      "Epoch 3 Lote 15900 Pérdida 1.0275\n",
      "Epoch 3 Lote 15950 Pérdida 1.0275\n",
      "Epoch 3 Lote 16000 Pérdida 1.0267\n",
      "Epoch 3 Lote 16050 Pérdida 1.0267\n",
      "Epoch 3 Lote 16100 Pérdida 1.0271\n",
      "Epoch 3 Lote 16150 Pérdida 1.0279\n",
      "Epoch 3 Lote 16200 Pérdida 1.0272\n",
      "Epoch 3 Lote 16250 Pérdida 1.0278\n",
      "Epoch 3 Lote 16300 Pérdida 1.0269\n",
      "Epoch 3 Lote 16350 Pérdida 1.0259\n",
      "Epoch 3 Lote 16400 Pérdida 1.0237\n",
      "Epoch 3 Lote 16450 Pérdida 1.0233\n",
      "Epoch 3 Lote 16500 Pérdida 1.0214\n",
      "Epoch 3 Lote 16550 Pérdida 1.0200\n",
      "Epoch 3 Lote 16600 Pérdida 1.0186\n",
      "Epoch 3 Lote 16650 Pérdida 1.0175\n",
      "Epoch 3 Lote 16700 Pérdida 1.0172\n",
      "Epoch 3 Lote 16750 Pérdida 1.0175\n",
      "Epoch 3 Lote 16800 Pérdida 1.0163\n",
      "Epoch 3 Lote 16850 Pérdida 1.0137\n",
      "Epoch 3 Lote 16900 Pérdida 1.0118\n",
      "Epoch 3 Lote 16950 Pérdida 1.0117\n",
      "Epoch 3 Lote 17000 Pérdida 1.0119\n",
      "Epoch 3 Lote 17050 Pérdida 1.0107\n",
      "Epoch 3 Lote 17100 Pérdida 1.0095\n",
      "Epoch 3 Lote 17150 Pérdida 1.0098\n",
      "Epoch 3 Lote 17200 Pérdida 1.0104\n",
      "Epoch 3 Lote 17250 Pérdida 1.0106\n",
      "Epoch 3 Lote 17300 Pérdida 1.0104\n",
      "Epoch 3 Lote 17350 Pérdida 1.0122\n",
      "Epoch 3 Lote 17400 Pérdida 1.0122\n",
      "Epoch 3 Lote 17450 Pérdida 1.0111\n",
      "Epoch 3 Lote 17500 Pérdida 1.0102\n",
      "Epoch 3 Lote 17550 Pérdida 1.0087\n",
      "Epoch 3 Lote 17600 Pérdida 1.0067\n",
      "Epoch 3 Lote 17650 Pérdida 1.0054\n",
      "Epoch 3 Lote 17700 Pérdida 1.0039\n",
      "Epoch 3 Lote 17750 Pérdida 1.0024\n",
      "Epoch 3 Lote 17800 Pérdida 1.0028\n",
      "Epoch 3 Lote 17850 Pérdida 1.0013\n",
      "Epoch 3 Lote 17900 Pérdida 0.9998\n",
      "Epoch 3 Lote 17950 Pérdida 0.9987\n",
      "Epoch 3 Lote 18000 Pérdida 0.9975\n",
      "Epoch 3 Lote 18050 Pérdida 0.9967\n",
      "Epoch 3 Lote 18100 Pérdida 0.9952\n",
      "Epoch 3 Lote 18150 Pérdida 0.9942\n",
      "Epoch 3 Lote 18200 Pérdida 0.9926\n",
      "Epoch 3 Lote 18250 Pérdida 0.9915\n",
      "Epoch 3 Lote 18300 Pérdida 0.9907\n",
      "Epoch 3 Lote 18350 Pérdida 0.9909\n",
      "Epoch 3 Lote 18400 Pérdida 0.9889\n",
      "Epoch 3 Lote 18450 Pérdida 0.9882\n",
      "Epoch 3 Lote 18500 Pérdida 0.9861\n",
      "Epoch 3 Lote 18550 Pérdida 0.9850\n",
      "Epoch 3 Lote 18600 Pérdida 0.9843\n",
      "Epoch 3 Lote 18650 Pérdida 0.9847\n",
      "Epoch 3 Lote 18700 Pérdida 0.9840\n",
      "Epoch 3 Lote 18750 Pérdida 0.9834\n",
      "Epoch 3 Lote 18800 Pérdida 0.9825\n",
      "Epoch 3 Lote 18850 Pérdida 0.9813\n",
      "Epoch 3 Lote 18900 Pérdida 0.9799\n",
      "Epoch 3 Lote 18950 Pérdida 0.9784\n",
      "Epoch 3 Lote 19000 Pérdida 0.9769\n",
      "Epoch 3 Lote 19050 Pérdida 0.9758\n",
      "Epoch 3 Lote 19100 Pérdida 0.9740\n",
      "Epoch 3 Lote 19150 Pérdida 0.9718\n",
      "Epoch 3 Lote 19200 Pérdida 0.9702\n",
      "Epoch 3 Lote 19250 Pérdida 0.9686\n",
      "Epoch 3 Lote 19300 Pérdida 0.9670\n",
      "Epoch 3 Lote 19350 Pérdida 0.9652\n",
      "Epoch 3 Lote 19400 Pérdida 0.9637\n",
      "Epoch 3 Lote 19450 Pérdida 0.9624\n",
      "Epoch 3 Lote 19500 Pérdida 0.9614\n",
      "Epoch 3 Lote 19550 Pérdida 0.9604\n",
      "Epoch 3 Lote 19600 Pérdida 0.9595\n",
      "Epoch 3 Lote 19650 Pérdida 0.9590\n",
      "Epoch 3 Lote 19700 Pérdida 0.9575\n",
      "Epoch 3 Lote 19750 Pérdida 0.9563\n",
      "Epoch 3 Lote 19800 Pérdida 0.9548\n",
      "Epoch 3 Lote 19850 Pérdida 0.9545\n",
      "Epoch 3 Lote 19900 Pérdida 0.9537\n",
      "Epoch 3 Lote 19950 Pérdida 0.9543\n",
      "Epoch 3 Lote 20000 Pérdida 0.9547\n",
      "Epoch 3 Lote 20050 Pérdida 0.9531\n",
      "Epoch 3 Lote 20100 Pérdida 0.9527\n",
      "Epoch 3 Lote 20150 Pérdida 0.9514\n",
      "Epoch 3 Lote 20200 Pérdida 0.9505\n",
      "Epoch 3 Lote 20250 Pérdida 0.9492\n",
      "Epoch 3 Lote 20300 Pérdida 0.9488\n",
      "Epoch 3 Lote 20350 Pérdida 0.9481\n",
      "Epoch 3 Lote 20400 Pérdida 0.9476\n",
      "Epoch 3 Lote 20450 Pérdida 0.9479\n",
      "Epoch 3 Lote 20500 Pérdida 0.9469\n",
      "Epoch 3 Lote 20550 Pérdida 0.9468\n",
      "Epoch 3 Lote 20600 Pérdida 0.9472\n",
      "Epoch 3 Lote 20650 Pérdida 0.9462\n",
      "Epoch 3 Lote 20700 Pérdida 0.9464\n",
      "Epoch 3 Lote 20750 Pérdida 0.9461\n",
      "Epoch 3 Lote 20800 Pérdida 0.9448\n",
      "Epoch 3 Lote 20850 Pérdida 0.9438\n",
      "Epoch 3 Lote 20900 Pérdida 0.9426\n",
      "Epoch 3 Lote 20950 Pérdida 0.9415\n",
      "Epoch 3 Lote 21000 Pérdida 0.9403\n",
      "Epoch 3 Lote 21050 Pérdida 0.9393\n",
      "Epoch 3 Lote 21100 Pérdida 0.9388\n",
      "Epoch 3 Lote 21150 Pérdida 0.9380\n",
      "Epoch 3 Lote 21200 Pérdida 0.9382\n",
      "Epoch 3 Lote 21250 Pérdida 0.9377\n",
      "Epoch 3 Lote 21300 Pérdida 0.9374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Lote 21350 Pérdida 0.9369\n",
      "Epoch 3 Lote 21400 Pérdida 0.9361\n",
      "Epoch 3 Lote 21450 Pérdida 0.9346\n",
      "Epoch 3 Lote 21500 Pérdida 0.9333\n",
      "Epoch 3 Lote 21550 Pérdida 0.9321\n",
      "Epoch 3 Lote 21600 Pérdida 0.9315\n",
      "Epoch 3 Lote 21650 Pérdida 0.9304\n",
      "Epoch 3 Lote 21700 Pérdida 0.9288\n",
      "Epoch 3 Lote 21750 Pérdida 0.9272\n",
      "Epoch 3 Lote 21800 Pérdida 0.9265\n",
      "Epoch 3 Lote 21850 Pérdida 0.9255\n",
      "Epoch 3 Lote 21900 Pérdida 0.9247\n",
      "Epoch 3 Lote 21950 Pérdida 0.9247\n",
      "Epoch 3 Lote 22000 Pérdida 0.9254\n",
      "Epoch 3 Lote 22050 Pérdida 0.9255\n",
      "Epoch 3 Lote 22100 Pérdida 0.9245\n",
      "Epoch 3 Lote 22150 Pérdida 0.9233\n",
      "Epoch 3 Lote 22200 Pérdida 0.9229\n",
      "Epoch 3 Lote 22250 Pérdida 0.9221\n",
      "Epoch 3 Lote 22300 Pérdida 0.9212\n",
      "Epoch 3 Lote 22350 Pérdida 0.9199\n",
      "Epoch 3 Lote 22400 Pérdida 0.9190\n",
      "Epoch 3 Lote 22450 Pérdida 0.9180\n",
      "Epoch 3 Lote 22500 Pérdida 0.9173\n",
      "Epoch 3 Lote 22550 Pérdida 0.9164\n",
      "Epoch 3 Lote 22600 Pérdida 0.9149\n",
      "Epoch 3 Lote 22650 Pérdida 0.9146\n",
      "Epoch 3 Lote 22700 Pérdida 0.9138\n",
      "Epoch 3 Lote 22750 Pérdida 0.9124\n",
      "Epoch 3 Lote 22800 Pérdida 0.9115\n",
      "Epoch 3 Lote 22850 Pérdida 0.9107\n",
      "Epoch 3 Lote 22900 Pérdida 0.9091\n",
      "Epoch 3 Lote 22950 Pérdida 0.9086\n",
      "Epoch 3 Lote 23000 Pérdida 0.9075\n",
      "Epoch 3 Lote 23050 Pérdida 0.9067\n",
      "Epoch 3 Lote 23100 Pérdida 0.9066\n",
      "Epoch 3 Lote 23150 Pérdida 0.9054\n",
      "Epoch 3 Lote 23200 Pérdida 0.9047\n",
      "Epoch 3 Lote 23250 Pérdida 0.9039\n",
      "Epoch 3 Lote 23300 Pérdida 0.9027\n",
      "Epoch 3 Lote 23350 Pérdida 0.9018\n",
      "Epoch 3 Lote 23400 Pérdida 0.9008\n",
      "Epoch 3 Lote 23450 Pérdida 0.8999\n",
      "Epoch 3 Lote 23500 Pérdida 0.8990\n",
      "Epoch 3 Lote 23550 Pérdida 0.8980\n",
      "Epoch 3 Lote 23600 Pérdida 0.8972\n",
      "Epoch 3 Lote 23650 Pérdida 0.8966\n",
      "Epoch 3 Lote 23700 Pérdida 0.8958\n",
      "Epoch 3 Lote 23750 Pérdida 0.8946\n",
      "Epoch 3 Lote 23800 Pérdida 0.8934\n",
      "Epoch 3 Lote 23850 Pérdida 0.8921\n",
      "Epoch 3 Lote 23900 Pérdida 0.8908\n",
      "Epoch 3 Lote 23950 Pérdida 0.8907\n",
      "Epoch 3 Lote 24000 Pérdida 0.8894\n",
      "Epoch 3 Lote 24050 Pérdida 0.8887\n",
      "Epoch 3 Lote 24100 Pérdida 0.8889\n",
      "Epoch 3 Lote 24150 Pérdida 0.8897\n",
      "Epoch 3 Lote 24200 Pérdida 0.8898\n",
      "Epoch 3 Lote 24250 Pérdida 0.8898\n",
      "Epoch 3 Lote 24300 Pérdida 0.8892\n",
      "Epoch 3 Lote 24350 Pérdida 0.8890\n",
      "Epoch 3 Lote 24400 Pérdida 0.8897\n",
      "Epoch 3 Lote 24450 Pérdida 0.8905\n",
      "Epoch 3 Lote 24500 Pérdida 0.8904\n",
      "Epoch 3 Lote 24550 Pérdida 0.8899\n",
      "Epoch 3 Lote 24600 Pérdida 0.8898\n",
      "Epoch 3 Lote 24650 Pérdida 0.8891\n",
      "Epoch 3 Lote 24700 Pérdida 0.8882\n",
      "Epoch 3 Lote 24750 Pérdida 0.8877\n",
      "Epoch 3 Lote 24800 Pérdida 0.8869\n",
      "Epoch 3 Lote 24850 Pérdida 0.8856\n",
      "Epoch 3 Lote 24900 Pérdida 0.8844\n",
      "Epoch 3 Lote 24950 Pérdida 0.8839\n",
      "Epoch 3 Lote 25000 Pérdida 0.8830\n",
      "Epoch 3 Lote 25050 Pérdida 0.8821\n",
      "Epoch 3 Lote 25100 Pérdida 0.8817\n",
      "Epoch 3 Lote 25150 Pérdida 0.8809\n",
      "Epoch 3 Lote 25200 Pérdida 0.8801\n",
      "Epoch 3 Lote 25250 Pérdida 0.8795\n",
      "Epoch 3 Lote 25300 Pérdida 0.8789\n",
      "Epoch 3 Lote 25350 Pérdida 0.8785\n",
      "Epoch 3 Lote 25400 Pérdida 0.8772\n",
      "Epoch 3 Lote 25450 Pérdida 0.8760\n",
      "Epoch 3 Lote 25500 Pérdida 0.8750\n",
      "Epoch 3 Lote 25550 Pérdida 0.8746\n",
      "Epoch 3 Lote 25600 Pérdida 0.8739\n",
      "Epoch 3 Lote 25650 Pérdida 0.8728\n",
      "Epoch 3 Lote 25700 Pérdida 0.8715\n",
      "Epoch 3 Lote 25750 Pérdida 0.8708\n",
      "Epoch 3 Lote 25800 Pérdida 0.8696\n",
      "Epoch 3 Lote 25850 Pérdida 0.8699\n",
      "Epoch 3 Lote 25900 Pérdida 0.8691\n",
      "Epoch 3 Lote 25950 Pérdida 0.8680\n",
      "Epoch 3 Lote 26000 Pérdida 0.8667\n",
      "Epoch 3 Lote 26050 Pérdida 0.8661\n",
      "Epoch 3 Lote 26100 Pérdida 0.8650\n",
      "Epoch 3 Lote 26150 Pérdida 0.8642\n",
      "Epoch 3 Lote 26200 Pérdida 0.8632\n",
      "Epoch 3 Lote 26250 Pérdida 0.8623\n",
      "Epoch 3 Lote 26300 Pérdida 0.8614\n",
      "Epoch 3 Lote 26350 Pérdida 0.8602\n",
      "Epoch 3 Lote 26400 Pérdida 0.8593\n",
      "Epoch 3 Lote 26450 Pérdida 0.8581\n",
      "Epoch 3 Lote 26500 Pérdida 0.8568\n",
      "Epoch 3 Lote 26550 Pérdida 0.8560\n",
      "Epoch 3 Lote 26600 Pérdida 0.8554\n",
      "Epoch 3 Lote 26650 Pérdida 0.8550\n",
      "Epoch 3 Lote 26700 Pérdida 0.8543\n",
      "Epoch 3 Lote 26750 Pérdida 0.8533\n",
      "Epoch 3 Lote 26800 Pérdida 0.8524\n",
      "Epoch 3 Lote 26850 Pérdida 0.8518\n",
      "Epoch 3 Lote 26900 Pérdida 0.8511\n",
      "Epoch 3 Lote 26950 Pérdida 0.8506\n",
      "Epoch 3 Lote 27000 Pérdida 0.8501\n",
      "Epoch 3 Lote 27050 Pérdida 0.8500\n",
      "Epoch 3 Lote 27100 Pérdida 0.8493\n",
      "Epoch 3 Lote 27150 Pérdida 0.8491\n",
      "Epoch 3 Lote 27200 Pérdida 0.8486\n",
      "Epoch 3 Lote 27250 Pérdida 0.8479\n",
      "Epoch 3 Lote 27300 Pérdida 0.8468\n",
      "Epoch 3 Lote 27350 Pérdida 0.8465\n",
      "Epoch 3 Lote 27400 Pérdida 0.8458\n",
      "Epoch 3 Lote 27450 Pérdida 0.8457\n",
      "Epoch 3 Lote 27500 Pérdida 0.8450\n",
      "Epoch 3 Lote 27550 Pérdida 0.8441\n",
      "Epoch 3 Lote 27600 Pérdida 0.8434\n",
      "Epoch 3 Lote 27650 Pérdida 0.8430\n",
      "Epoch 3 Lote 27700 Pérdida 0.8424\n",
      "Epoch 3 Lote 27750 Pérdida 0.8421\n",
      "Epoch 3 Lote 27800 Pérdida 0.8415\n",
      "Epoch 3 Lote 27850 Pérdida 0.8409\n",
      "Epoch 3 Lote 27900 Pérdida 0.8404\n",
      "Epoch 3 Lote 27950 Pérdida 0.8399\n",
      "Epoch 3 Lote 28000 Pérdida 0.8390\n",
      "Epoch 3 Lote 28050 Pérdida 0.8379\n",
      "Epoch 3 Lote 28100 Pérdida 0.8371\n",
      "Epoch 3 Lote 28150 Pérdida 0.8368\n",
      "Epoch 3 Lote 28200 Pérdida 0.8363\n",
      "Epoch 3 Lote 28250 Pérdida 0.8366\n",
      "Epoch 3 Lote 28300 Pérdida 0.8359\n",
      "Epoch 3 Lote 28350 Pérdida 0.8355\n",
      "Epoch 3 Lote 28400 Pérdida 0.8346\n",
      "Epoch 3 Lote 28450 Pérdida 0.8339\n",
      "Epoch 3 Lote 28500 Pérdida 0.8330\n",
      "Epoch 3 Lote 28550 Pérdida 0.8318\n",
      "Epoch 3 Lote 28600 Pérdida 0.8308\n",
      "Epoch 3 Lote 28650 Pérdida 0.8300\n",
      "Epoch 3 Lote 28700 Pérdida 0.8288\n",
      "Epoch 3 Lote 28750 Pérdida 0.8276\n",
      "Epoch 3 Lote 28800 Pérdida 0.8266\n",
      "Epoch 3 Lote 28850 Pérdida 0.8261\n",
      "Epoch 3 Lote 28900 Pérdida 0.8261\n",
      "Epoch 3 Lote 28950 Pérdida 0.8254\n",
      "Epoch 3 Lote 29000 Pérdida 0.8248\n",
      "Epoch 3 Lote 29050 Pérdida 0.8247\n",
      "Epoch 3 Lote 29100 Pérdida 0.8239\n",
      "Epoch 3 Lote 29150 Pérdida 0.8233\n",
      "Epoch 3 Lote 29200 Pérdida 0.8228\n",
      "Epoch 3 Lote 29250 Pérdida 0.8223\n",
      "Epoch 3 Lote 29300 Pérdida 0.8212\n",
      "Epoch 3 Lote 29350 Pérdida 0.8200\n",
      "Epoch 3 Lote 29400 Pérdida 0.8192\n",
      "Epoch 3 Lote 29450 Pérdida 0.8183\n",
      "Epoch 3 Lote 29500 Pérdida 0.8180\n",
      "Epoch 3 Lote 29550 Pérdida 0.8171\n",
      "Epoch 3 Lote 29600 Pérdida 0.8175\n",
      "Epoch 3 Lote 29650 Pérdida 0.8174\n",
      "Epoch 3 Lote 29700 Pérdida 0.8174\n",
      "Epoch 3 Lote 29750 Pérdida 0.8168\n",
      "Epoch 3 Lote 29800 Pérdida 0.8167\n",
      "Epoch 3 Lote 29850 Pérdida 0.8163\n",
      "Epoch 3 Lote 29900 Pérdida 0.8162\n",
      "Epoch 3 Lote 29950 Pérdida 0.8163\n",
      "Epoch 3 Lote 30000 Pérdida 0.8161\n",
      "Epoch 3 Lote 30050 Pérdida 0.8150\n",
      "Epoch 3 Lote 30100 Pérdida 0.8142\n",
      "Epoch 3 Lote 30150 Pérdida 0.8131\n",
      "Epoch 3 Lote 30200 Pérdida 0.8122\n",
      "Epoch 3 Lote 30250 Pérdida 0.8114\n",
      "Epoch 3 Lote 30300 Pérdida 0.8110\n",
      "Epoch 3 Lote 30350 Pérdida 0.8110\n",
      "Epoch 3 Lote 30400 Pérdida 0.8108\n",
      "Epoch 3 Lote 30450 Pérdida 0.8106\n",
      "Epoch 3 Lote 30500 Pérdida 0.8104\n",
      "Epoch 3 Lote 30550 Pérdida 0.8100\n",
      "Epoch 3 Lote 30600 Pérdida 0.8099\n",
      "Epoch 3 Lote 30650 Pérdida 0.8096\n",
      "Epoch 3 Lote 30700 Pérdida 0.8096\n",
      "Epoch 3 Lote 30750 Pérdida 0.8098\n",
      "Epoch 3 Lote 30800 Pérdida 0.8093\n",
      "Epoch 3 Lote 30850 Pérdida 0.8096\n",
      "Epoch 3 Lote 30900 Pérdida 0.8090\n",
      "Epoch 3 Lote 30950 Pérdida 0.8087\n",
      "Epoch 3 Lote 31000 Pérdida 0.8079\n",
      "Epoch 3 Lote 31050 Pérdida 0.8077\n",
      "Epoch 3 Lote 31100 Pérdida 0.8076\n",
      "Epoch 3 Lote 31150 Pérdida 0.8070\n",
      "Epoch 3 Lote 31200 Pérdida 0.8065\n",
      "Epoch 3 Lote 31250 Pérdida 0.8057\n",
      "Epoch 3 Lote 31300 Pérdida 0.8055\n",
      "Epoch 3 Lote 31350 Pérdida 0.8049\n",
      "Epoch 3 Lote 31400 Pérdida 0.8046\n",
      "Epoch 3 Lote 31450 Pérdida 0.8041\n",
      "Epoch 3 Lote 31500 Pérdida 0.8033\n",
      "Epoch 3 Lote 31550 Pérdida 0.8029\n",
      "Epoch 3 Lote 31600 Pérdida 0.8023\n",
      "Epoch 3 Lote 31650 Pérdida 0.8018\n",
      "Epoch 3 Lote 31700 Pérdida 0.8013\n",
      "Epoch 3 Lote 31750 Pérdida 0.8004\n",
      "Epoch 3 Lote 31800 Pérdida 0.7998\n",
      "Epoch 3 Lote 31850 Pérdida 0.7987\n",
      "Epoch 3 Lote 31900 Pérdida 0.7978\n",
      "Epoch 3 Lote 31950 Pérdida 0.7971\n",
      "Epoch 3 Lote 32000 Pérdida 0.7963\n",
      "Epoch 3 Lote 32050 Pérdida 0.7954\n",
      "Epoch 3 Lote 32100 Pérdida 0.7943\n",
      "Epoch 3 Lote 32150 Pérdida 0.7936\n",
      "Epoch 3 Lote 32200 Pérdida 0.7930\n",
      "Epoch 3 Lote 32250 Pérdida 0.7922\n",
      "Epoch 3 Lote 32300 Pérdida 0.7918\n",
      "Epoch 3 Lote 32350 Pérdida 0.7911\n",
      "Epoch 3 Lote 32400 Pérdida 0.7905\n",
      "Epoch 3 Lote 32450 Pérdida 0.7902\n",
      "Epoch 3 Lote 32500 Pérdida 0.7895\n",
      "Epoch 3 Lote 32550 Pérdida 0.7889\n",
      "Epoch 3 Lote 32600 Pérdida 0.7882\n",
      "Epoch 3 Lote 32650 Pérdida 0.7874\n",
      "Epoch 3 Lote 32700 Pérdida 0.7871\n",
      "Epoch 3 Lote 32750 Pérdida 0.7866\n",
      "Epoch 3 Lote 32800 Pérdida 0.7864\n",
      "Epoch 3 Lote 32850 Pérdida 0.7861\n",
      "Epoch 3 Lote 32900 Pérdida 0.7858\n",
      "Epoch 3 Lote 32950 Pérdida 0.7852\n",
      "Epoch 3 Lote 33000 Pérdida 0.7851\n",
      "Epoch 3 Lote 33050 Pérdida 0.7842\n",
      "Epoch 3 Lote 33100 Pérdida 0.7834\n",
      "Epoch 3 Lote 33150 Pérdida 0.7825\n",
      "Epoch 3 Lote 33200 Pérdida 0.7815\n",
      "Epoch 3 Lote 33250 Pérdida 0.7806\n",
      "Epoch 3 Lote 33300 Pérdida 0.7797\n",
      "Epoch 3 Lote 33350 Pérdida 0.7787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Lote 33400 Pérdida 0.7780\n",
      "Epoch 3 Lote 33450 Pérdida 0.7776\n",
      "Epoch 3 Lote 33500 Pérdida 0.7773\n",
      "Epoch 3 Lote 33550 Pérdida 0.7765\n",
      "Epoch 3 Lote 33600 Pérdida 0.7763\n",
      "Epoch 3 Lote 33650 Pérdida 0.7761\n",
      "Epoch 3 Lote 33700 Pérdida 0.7755\n",
      "Epoch 3 Lote 33750 Pérdida 0.7750\n",
      "Epoch 3 Lote 33800 Pérdida 0.7745\n",
      "Epoch 3 Lote 33850 Pérdida 0.7741\n",
      "Epoch 3 Lote 33900 Pérdida 0.7737\n",
      "Epoch 3 Lote 33950 Pérdida 0.7730\n",
      "Epoch 3 Lote 34000 Pérdida 0.7724\n",
      "Epoch 3 Lote 34050 Pérdida 0.7717\n",
      "Epoch 3 Lote 34100 Pérdida 0.7710\n",
      "Epoch 3 Lote 34150 Pérdida 0.7705\n",
      "Epoch 3 Lote 34200 Pérdida 0.7703\n",
      "Epoch 3 Lote 34250 Pérdida 0.7695\n",
      "Epoch 3 Lote 34300 Pérdida 0.7693\n",
      "Epoch 3 Lote 34350 Pérdida 0.7686\n",
      "Epoch 3 Lote 34400 Pérdida 0.7682\n",
      "Epoch 3 Lote 34450 Pérdida 0.7681\n",
      "Epoch 3 Lote 34500 Pérdida 0.7679\n",
      "Epoch 3 Lote 34550 Pérdida 0.7673\n",
      "Epoch 3 Lote 34600 Pérdida 0.7669\n",
      "Epoch 3 Lote 34650 Pérdida 0.7663\n",
      "Epoch 3 Lote 34700 Pérdida 0.7656\n",
      "Epoch 3 Lote 34750 Pérdida 0.7654\n",
      "Epoch 3 Lote 34800 Pérdida 0.7652\n",
      "Epoch 3 Lote 34850 Pérdida 0.7652\n",
      "Epoch 3 Lote 34900 Pérdida 0.7657\n",
      "Epoch 3 Lote 34950 Pérdida 0.7665\n",
      "Epoch 3 Lote 35000 Pérdida 0.7677\n",
      "Epoch 3 Lote 35050 Pérdida 0.7681\n",
      "Epoch 3 Lote 35100 Pérdida 0.7690\n",
      "Epoch 3 Lote 35150 Pérdida 0.7691\n",
      "Epoch 3 Lote 35200 Pérdida 0.7692\n",
      "Epoch 3 Lote 35250 Pérdida 0.7684\n",
      "Epoch 3 Lote 35300 Pérdida 0.7678\n",
      "Epoch 3 Lote 35350 Pérdida 0.7672\n",
      "Epoch 3 Lote 35400 Pérdida 0.7663\n",
      "Epoch 3 Lote 35450 Pérdida 0.7659\n",
      "Epoch 3 Lote 35500 Pérdida 0.7654\n",
      "Epoch 3 Lote 35550 Pérdida 0.7647\n",
      "Epoch 3 Lote 35600 Pérdida 0.7640\n",
      "Epoch 3 Lote 35650 Pérdida 0.7632\n",
      "Epoch 3 Lote 35700 Pérdida 0.7627\n",
      "Epoch 3 Lote 35750 Pérdida 0.7621\n",
      "Epoch 3 Lote 35800 Pérdida 0.7616\n",
      "Epoch 3 Lote 35850 Pérdida 0.7615\n",
      "Epoch 3 Lote 35900 Pérdida 0.7618\n",
      "Epoch 3 Lote 35950 Pérdida 0.7616\n",
      "Epoch 3 Lote 36000 Pérdida 0.7623\n",
      "Epoch 3 Lote 36050 Pérdida 0.7629\n",
      "Epoch 3 Lote 36100 Pérdida 0.7643\n",
      "Epoch 3 Lote 36150 Pérdida 0.7645\n",
      "Epoch 3 Lote 36200 Pérdida 0.7643\n",
      "Epoch 3 Lote 36250 Pérdida 0.7642\n",
      "Epoch 3 Lote 36300 Pérdida 0.7634\n",
      "Epoch 3 Lote 36350 Pérdida 0.7629\n",
      "Epoch 3 Lote 36400 Pérdida 0.7632\n",
      "Epoch 3 Lote 36450 Pérdida 0.7643\n",
      "Epoch 3 Lote 36500 Pérdida 0.7655\n",
      "Epoch 3 Lote 36550 Pérdida 0.7664\n",
      "Epoch 3 Lote 36600 Pérdida 0.7679\n",
      "Epoch 3 Lote 36650 Pérdida 0.7690\n",
      "Epoch 3 Lote 36700 Pérdida 0.7691\n",
      "Epoch 3 Lote 36750 Pérdida 0.7691\n",
      "Epoch 3 Lote 36800 Pérdida 0.7692\n",
      "Epoch 3 Lote 36850 Pérdida 0.7686\n",
      "Epoch 3 Lote 36900 Pérdida 0.7687\n",
      "Epoch 3 Lote 36950 Pérdida 0.7690\n",
      "Epoch 3 Lote 37000 Pérdida 0.7684\n",
      "Epoch 3 Lote 37050 Pérdida 0.7687\n",
      "Epoch 3 Lote 37100 Pérdida 0.7679\n",
      "Epoch 3 Lote 37150 Pérdida 0.7675\n",
      "Epoch 3 Lote 37200 Pérdida 0.7670\n",
      "Epoch 3 Lote 37250 Pérdida 0.7663\n",
      "Epoch 3 Lote 37300 Pérdida 0.7658\n",
      "Epoch 3 Lote 37350 Pérdida 0.7657\n",
      "Epoch 3 Lote 37400 Pérdida 0.7654\n",
      "Epoch 3 Lote 37450 Pérdida 0.7649\n",
      "Epoch 3 Lote 37500 Pérdida 0.7643\n",
      "Epoch 3 Lote 37550 Pérdida 0.7641\n",
      "Epoch 3 Lote 37600 Pérdida 0.7640\n",
      "Epoch 3 Lote 37650 Pérdida 0.7641\n",
      "Epoch 3 Lote 37700 Pérdida 0.7635\n",
      "Epoch 3 Lote 37750 Pérdida 0.7634\n",
      "Epoch 3 Lote 37800 Pérdida 0.7633\n",
      "Epoch 3 Lote 37850 Pérdida 0.7631\n",
      "Epoch 3 Lote 37900 Pérdida 0.7628\n",
      "Epoch 3 Lote 37950 Pérdida 0.7627\n",
      "Epoch 3 Lote 38000 Pérdida 0.7627\n",
      "Epoch 3 Lote 38050 Pérdida 0.7623\n",
      "Epoch 3 Lote 38100 Pérdida 0.7622\n",
      "Epoch 3 Lote 38150 Pérdida 0.7621\n",
      "Epoch 3 Lote 38200 Pérdida 0.7623\n",
      "Epoch 3 Lote 38250 Pérdida 0.7617\n",
      "Epoch 3 Lote 38300 Pérdida 0.7615\n",
      "Epoch 3 Lote 38350 Pérdida 0.7614\n",
      "Epoch 3 Lote 38400 Pérdida 0.7609\n",
      "Epoch 3 Lote 38450 Pérdida 0.7607\n",
      "Epoch 3 Lote 38500 Pérdida 0.7608\n",
      "Epoch 3 Lote 38550 Pérdida 0.7603\n",
      "Epoch 3 Lote 38600 Pérdida 0.7599\n",
      "Epoch 3 Lote 38650 Pérdida 0.7593\n",
      "Epoch 3 Lote 38700 Pérdida 0.7589\n",
      "Epoch 3 Lote 38750 Pérdida 0.7584\n",
      "Epoch 3 Lote 38800 Pérdida 0.7578\n",
      "Epoch 3 Lote 38850 Pérdida 0.7572\n",
      "Epoch 3 Lote 38900 Pérdida 0.7569\n",
      "Epoch 3 Lote 38950 Pérdida 0.7562\n",
      "Epoch 3 Lote 39000 Pérdida 0.7555\n",
      "Epoch 3 Lote 39050 Pérdida 0.7548\n",
      "Epoch 3 Lote 39100 Pérdida 0.7542\n",
      "Epoch 3 Lote 39150 Pérdida 0.7539\n",
      "Epoch 3 Lote 39200 Pérdida 0.7534\n",
      "Epoch 3 Lote 39250 Pérdida 0.7530\n",
      "Epoch 3 Lote 39300 Pérdida 0.7521\n",
      "Epoch 3 Lote 39350 Pérdida 0.7514\n",
      "Epoch 3 Lote 39400 Pérdida 0.7508\n",
      "Epoch 3 Lote 39450 Pérdida 0.7504\n",
      "Epoch 3 Lote 39500 Pérdida 0.7498\n",
      "Epoch 3 Lote 39550 Pérdida 0.7492\n",
      "Epoch 3 Lote 39600 Pérdida 0.7488\n",
      "Epoch 3 Lote 39650 Pérdida 0.7480\n",
      "Epoch 3 Lote 39700 Pérdida 0.7487\n",
      "Epoch 3 Lote 39750 Pérdida 0.7496\n",
      "Epoch 3 Lote 39800 Pérdida 0.7505\n",
      "Epoch 3 Lote 39850 Pérdida 0.7513\n",
      "Epoch 3 Lote 39900 Pérdida 0.7518\n",
      "Epoch 3 Lote 39950 Pérdida 0.7515\n",
      "Epoch 3 Lote 40000 Pérdida 0.7512\n",
      "Epoch 3 Lote 40050 Pérdida 0.7510\n",
      "Epoch 3 Lote 40100 Pérdida 0.7506\n",
      "Epoch 3 Lote 40150 Pérdida 0.7501\n",
      "Epoch 3 Lote 40200 Pérdida 0.7497\n",
      "Epoch 3 Lote 40250 Pérdida 0.7489\n",
      "Epoch 3 Lote 40300 Pérdida 0.7486\n",
      "Epoch 3 Lote 40350 Pérdida 0.7485\n",
      "Epoch 3 Lote 40400 Pérdida 0.7491\n",
      "Epoch 3 Lote 40450 Pérdida 0.7507\n",
      "Epoch 3 Lote 40500 Pérdida 0.7523\n",
      "Epoch 3 Lote 40550 Pérdida 0.7528\n",
      "Epoch 3 Lote 40600 Pérdida 0.7535\n",
      "Epoch 3 Lote 40650 Pérdida 0.7537\n",
      "Epoch 3 Lote 40700 Pérdida 0.7536\n",
      "Epoch 3 Lote 40750 Pérdida 0.7532\n",
      "Epoch 3 Lote 40800 Pérdida 0.7529\n",
      "Epoch 3 Lote 40850 Pérdida 0.7528\n",
      "Epoch 3 Lote 40900 Pérdida 0.7526\n",
      "Epoch 3 Lote 40950 Pérdida 0.7525\n",
      "Epoch 3 Lote 41000 Pérdida 0.7522\n",
      "Epoch 3 Lote 41050 Pérdida 0.7522\n",
      "Epoch 3 Lote 41100 Pérdida 0.7522\n",
      "Epoch 3 Lote 41150 Pérdida 0.7519\n",
      "Epoch 3 Lote 41200 Pérdida 0.7516\n",
      "Epoch 3 Lote 41250 Pérdida 0.7519\n",
      "Epoch 3 Lote 41300 Pérdida 0.7523\n",
      "Epoch 3 Lote 41350 Pérdida 0.7522\n",
      "Epoch 3 Lote 41400 Pérdida 0.7525\n",
      "Epoch 3 Lote 41450 Pérdida 0.7522\n",
      "Epoch 3 Lote 41500 Pérdida 0.7525\n",
      "Epoch 3 Lote 41550 Pérdida 0.7520\n",
      "Epoch 3 Lote 41600 Pérdida 0.7515\n",
      "Epoch 3 Lote 41650 Pérdida 0.7515\n",
      "Epoch 3 Lote 41700 Pérdida 0.7513\n",
      "Epoch 3 Lote 41750 Pérdida 0.7514\n",
      "Epoch 3 Lote 41800 Pérdida 0.7518\n",
      "Epoch 3 Lote 41850 Pérdida 0.7522\n",
      "Epoch 3 Lote 41900 Pérdida 0.7526\n",
      "Epoch 3 Lote 41950 Pérdida 0.7532\n",
      "Epoch 3 Lote 42000 Pérdida 0.7544\n",
      "Epoch 3 Lote 42050 Pérdida 0.7546\n",
      "Epoch 3 Lote 42100 Pérdida 0.7548\n",
      "Epoch 3 Lote 42150 Pérdida 0.7554\n",
      "Epoch 3 Lote 42200 Pérdida 0.7558\n",
      "Epoch 3 Lote 42250 Pérdida 0.7561\n",
      "Epoch 3 Lote 42300 Pérdida 0.7569\n",
      "Epoch 3 Lote 42350 Pérdida 0.7574\n",
      "Epoch 3 Lote 42400 Pérdida 0.7577\n",
      "Epoch 3 Lote 42450 Pérdida 0.7576\n",
      "Epoch 3 Lote 42500 Pérdida 0.7577\n",
      "Epoch 3 Lote 42550 Pérdida 0.7576\n",
      "Epoch 3 Lote 42600 Pérdida 0.7575\n",
      "Epoch 3 Lote 42650 Pérdida 0.7577\n",
      "Epoch 3 Lote 42700 Pérdida 0.7576\n",
      "Epoch 3 Lote 42750 Pérdida 0.7575\n",
      "Epoch 3 Lote 42800 Pérdida 0.7578\n",
      "Epoch 3 Lote 42850 Pérdida 0.7577\n",
      "Epoch 3 Lote 42900 Pérdida 0.7574\n",
      "Epoch 3 Lote 42950 Pérdida 0.7576\n",
      "Epoch 3 Lote 43000 Pérdida 0.7577\n",
      "Epoch 3 Lote 43050 Pérdida 0.7582\n",
      "Epoch 3 Lote 43100 Pérdida 0.7583\n",
      "Epoch 3 Lote 43150 Pérdida 0.7585\n",
      "Epoch 3 Lote 43200 Pérdida 0.7596\n",
      "Epoch 3 Lote 43250 Pérdida 0.7600\n",
      "Epoch 3 Lote 43300 Pérdida 0.7609\n",
      "Epoch 3 Lote 43350 Pérdida 0.7624\n",
      "Epoch 3 Lote 43400 Pérdida 0.7644\n",
      "Epoch 3 Lote 43450 Pérdida 0.7654\n",
      "Epoch 3 Lote 43500 Pérdida 0.7663\n",
      "Epoch 3 Lote 43550 Pérdida 0.7673\n",
      "Epoch 3 Lote 43600 Pérdida 0.7684\n",
      "Epoch 3 Lote 43650 Pérdida 0.7693\n",
      "Epoch 3 Lote 43700 Pérdida 0.7706\n",
      "Epoch 3 Lote 43750 Pérdida 0.7721\n",
      "Epoch 3 Lote 43800 Pérdida 0.7738\n",
      "Epoch 3 Lote 43850 Pérdida 0.7745\n",
      "Epoch 3 Lote 43900 Pérdida 0.7750\n",
      "Epoch 3 Lote 43950 Pérdida 0.7760\n",
      "Tiempo total para entrenar 1 epoch: 4195.23378777504 segs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NB_EPOCHS):\n",
    "    print(\"Inicio del Epoch {}\".format(epoch+1))\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    for (batch, (inputs, targets)) in enumerate(train_dataset_light):\n",
    "        with tf.GradientTape() as tape:\n",
    "            model_outputs = bert_squad(inputs)\n",
    "            loss = squad_loss_fn(targets, model_outputs)\n",
    "        \n",
    "        gradients = tape.gradient(loss, bert_squad.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, bert_squad.trainable_variables))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            print(\"Epoch {} Lote {} Pérdida {:.4f}\".format(\n",
    "                epoch+1, batch, train_loss.result()))\n",
    "        \"\"\"\n",
    "        if batch % 500 == 0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print(\"Guardando checkpoint para el epoch {} en el directorio {}\".format(epoch+1,\n",
    "                                                                ckpt_save_path))\"\"\"\n",
    "    print(\"Tiempo total para entrenar 1 epoch: {} segs\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6WquTCiIR7t"
   },
   "source": [
    "# Fase 5: Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDIlHd5Tos6C"
   },
   "source": [
    "## Preparación de la evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU7_AyTIpTTJ"
   },
   "source": [
    "Get the dev set in the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VGKl84s5WrhD"
   },
   "outputs": [],
   "source": [
    "eval_examples = read_squad_examples(\n",
    "    \"/home/icarlos/BERT/Q&A/dev-v1.1.json\",\n",
    "    is_training=False,\n",
    "    version_2_with_negative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAEUcZDSpYLD"
   },
   "source": [
    "Define the function that will write the tf_record file for the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yCVmIgnEo83o"
   },
   "outputs": [],
   "source": [
    "eval_writer = FeatureWriter(\n",
    "    filename=os.path.join(\"/home/icarlos/BERT/Q&A/\",\n",
    "                          \"eval.tf_record\"),\n",
    "    is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8aSLFdmp71I"
   },
   "source": [
    "Create a tokenizer for future information needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oH5exQ7KwnuH"
   },
   "outputs": [],
   "source": [
    "my_bert_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\",\n",
    "    trainable=False)\n",
    "vocab_file = my_bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = my_bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdHudjJ_qAzo"
   },
   "source": [
    "Define the function that add the features (feature is a protocol in tensorflow) to our eval_features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bmQ5GtoTxRjU"
   },
   "outputs": [],
   "source": [
    "def _append_feature(feature, is_padding):\n",
    "    if not is_padding:\n",
    "        eval_features.append(feature)\n",
    "    eval_writer.process_feature(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLAcwCiaqHi_"
   },
   "source": [
    "Create the eval features and the writes the tf.record file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mz7kGYmUwGQb"
   },
   "outputs": [],
   "source": [
    "eval_features = []\n",
    "dataset_size = convert_examples_to_features(\n",
    "    examples=eval_examples,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=384,\n",
    "    doc_stride=128,\n",
    "    max_query_length=64,\n",
    "    is_training=False,\n",
    "    output_fn=_append_feature,\n",
    "    batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WpZfwPEwMabx"
   },
   "outputs": [],
   "source": [
    "eval_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbKhx3zuq844"
   },
   "source": [
    "Load the ready-to-be-used dataset to our session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eUqYvG5TxctF"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "eval_dataset = create_squad_dataset(\n",
    "    \"/home/icarlos/BERT/Q&A/eval.tf_record\",\n",
    "    384,#input_meta_data['max_seq_length'],\n",
    "    BATCH_SIZE,\n",
    "    is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRbKrFYoo8e8"
   },
   "source": [
    "## Llevar a cabo las prediccioness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyckEWDbrLEX"
   },
   "source": [
    "Definir un cierto tipo de colección (como un diccionario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tyWOUKaDP0H0"
   },
   "outputs": [],
   "source": [
    "RawResult = collections.namedtuple(\"RawResult\",\n",
    "                                   [\"unique_id\", \"start_logits\", \"end_logits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28abKVvqrRa4"
   },
   "source": [
    "Devuelve cada elemento del lote de salida, uno por uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "BScaA0SZQgQW"
   },
   "outputs": [],
   "source": [
    "def get_raw_results(predictions):\n",
    "    for unique_ids, start_logits, end_logits in zip(predictions['unique_ids'],\n",
    "                                                    predictions['start_logits'],\n",
    "                                                    predictions['end_logits']):\n",
    "        yield RawResult(\n",
    "            unique_id=unique_ids.numpy(),\n",
    "            start_logits=start_logits.numpy().tolist(),\n",
    "            end_logits=end_logits.numpy().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiLOOmnLre5C"
   },
   "source": [
    "Hacemos nuestras predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "qqD78Xdjrvpn",
    "outputId": "b128075d-bfc1-4df6-852e-f1020bbc404f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2709\n",
      "100/2709\n",
      "200/2709\n",
      "300/2709\n",
      "400/2709\n",
      "500/2709\n",
      "600/2709\n",
      "700/2709\n",
      "800/2709\n",
      "900/2709\n",
      "1000/2709\n",
      "1100/2709\n",
      "1200/2709\n",
      "1300/2709\n",
      "1400/2709\n",
      "1500/2709\n",
      "1600/2709\n",
      "1700/2709\n",
      "1800/2709\n",
      "1900/2709\n",
      "2000/2709\n",
      "2100/2709\n",
      "2200/2709\n",
      "2300/2709\n",
      "2400/2709\n",
      "2500/2709\n",
      "2600/2709\n",
      "2700/2709\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for count, inputs in enumerate(eval_dataset):\n",
    "    x, _ = inputs  \n",
    "    unique_ids = x.pop(\"unique_ids\")\n",
    "    start_logits, end_logits = bert_squad(x, training=False)\n",
    "    output_dict = dict(\n",
    "        unique_ids=unique_ids,\n",
    "        start_logits=start_logits,\n",
    "        end_logits=end_logits)\n",
    "    for result in get_raw_results(output_dict):\n",
    "        all_results.append(result)\n",
    "    if count % 100 == 0:\n",
    "        print(\"{}/{}\".format(count, 2709))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjQ6kIqGriHr"
   },
   "source": [
    "Escribimos nuestras predicciones en un fichero JSON que funcionará con el script de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "esLdRf7uM3Lz"
   },
   "outputs": [],
   "source": [
    "output_prediction_file = \"/home/icarlos/BERT/Q&A/predictions.json\"\n",
    "output_nbest_file = \"/home/icarlos/BERT/Q&A/nbest_predictions.json\"\n",
    "output_null_log_odds_file = \"/home/icarlos/BERT/Q&A/null_odds.json\"\n",
    "\n",
    "write_predictions(\n",
    "    eval_examples,\n",
    "    eval_features,\n",
    "    all_results,\n",
    "    20,\n",
    "    30,\n",
    "    True,\n",
    "    output_prediction_file,\n",
    "    output_nbest_file,\n",
    "    output_null_log_odds_file,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eaIHyDIYHHx"
   },
   "source": [
    "## Predicción casera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0F4l5h8Zdha"
   },
   "source": [
    "### Creación del diccionario de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrhHzx7ycXXo"
   },
   "source": [
    "Concatenamos la pregunta y el contexto, separados por `[\"SEP\"]`, tras la tokenización, tal cual como lo hicimos con el conjunto de entrenamiento.\n",
    "\n",
    "Lo importante a recordar es que queremos que nuestra respuesta empiece y termine con una palabra real. Por ejemplo, la palabra \"ecologically\" es tokenizada como `[\"ecological\", \"##ly\"]`, y si el token de fin es `[\"ecological\"]` queremos usar la palabra \"ecologically\" como palabra final (del mismo modo si el token de fin es`[\"##ly\"]`). Por eso, empezamos dividiendo nuestro contexto en palabras, y luego pasamos a tokens, recordando qué token se corresponde con qué palabra (ver la función `tokenize_context()` para más detalle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tuNXt98Zm4u"
   },
   "source": [
    "#### Útiles varios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OBjGoQ_wfmml"
   },
   "outputs": [],
   "source": [
    "my_bert_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "    trainable=False)\n",
    "vocab_file = my_bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = my_bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8f_fCe_hLC12"
   },
   "outputs": [],
   "source": [
    "def is_whitespace(c):\n",
    "    '''\n",
    "    Indica si un cadena de caracteres se corresponde con un espacio en blanco / separador o no.\n",
    "    '''\n",
    "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4ZA4TYnxLGVT"
   },
   "outputs": [],
   "source": [
    "def whitespace_split(text):\n",
    "    '''\n",
    "    Toma el texto y devuelve una lista de \"palabras\" separadas segun los \n",
    "    espacios en blanco / separadores anteriores.\n",
    "    '''\n",
    "    doc_tokens = []\n",
    "    prev_is_whitespace = True\n",
    "    for c in text:\n",
    "        if is_whitespace(c):\n",
    "            prev_is_whitespace = True\n",
    "        else:\n",
    "            if prev_is_whitespace:\n",
    "                doc_tokens.append(c)\n",
    "            else:\n",
    "                doc_tokens[-1] += c\n",
    "            prev_is_whitespace = False\n",
    "    return doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Fsfzt3GUNWQK"
   },
   "outputs": [],
   "source": [
    "def tokenize_context(text_words):\n",
    "    '''\n",
    "    Toma una lista de palabras (devueltas por whitespace_split()) y tokeniza cada\n",
    "    palabra una por una. También almacena, para cada nuevo token, la palabra original\n",
    "    del parámetro text_words.\n",
    "    '''\n",
    "    text_tok = []\n",
    "    tok_to_word_id = []\n",
    "    for word_id, word in enumerate(text_words):\n",
    "        word_tok = tokenizer.tokenize(word)\n",
    "        text_tok += word_tok\n",
    "        tok_to_word_id += [word_id]*len(word_tok)\n",
    "    return text_tok, tok_to_word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "c8qreqEURUOP"
   },
   "outputs": [],
   "source": [
    "def get_ids(tokens):\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def get_mask(tokens):\n",
    "    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
    "\n",
    "def get_segments(tokens):\n",
    "    seg_ids = []\n",
    "    current_seg_id = 0\n",
    "    for tok in tokens:\n",
    "        seg_ids.append(current_seg_id)\n",
    "        if tok == \"[SEP]\":\n",
    "            current_seg_id = 1-current_seg_id # Convierte 1 en 0 y viceversa\n",
    "    return seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "P2sPGXxsYUsY"
   },
   "outputs": [],
   "source": [
    "def create_input_dict(question, context):\n",
    "    '''\n",
    "    Take a question and a context as strings and return a dictionary with the 3\n",
    "    elements needed for the model. Also return the context_words, the\n",
    "    context_tok to context_word ids correspondance and the length of\n",
    "    question_tok that we will need later.\n",
    "    '''\n",
    "    question_tok = tokenizer.tokenize(my_question)\n",
    "\n",
    "    context_words = whitespace_split(context)\n",
    "    context_tok, context_tok_to_word_id = tokenize_context(context_words)\n",
    "\n",
    "    input_tok = question_tok + [\"[SEP]\"] + context_tok + [\"[SEP]\"]\n",
    "    input_tok += [\"[PAD]\"]*(384-len(input_tok)) # in our case the model has been\n",
    "                                                # trained to have inputs of length max 384\n",
    "    input_dict = {}\n",
    "    input_dict[\"input_word_ids\"] = tf.expand_dims(tf.cast(get_ids(input_tok), tf.int32), 0)\n",
    "    input_dict[\"input_mask\"] = tf.expand_dims(tf.cast(get_mask(input_tok), tf.int32), 0)\n",
    "    input_dict[\"input_type_ids\"] = tf.expand_dims(tf.cast(get_segments(input_tok), tf.int32), 0)\n",
    "\n",
    "    return input_dict, context_words, context_tok_to_word_id, len(question_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAnaCZWTZpWT"
   },
   "source": [
    "#### Creación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "WQlM-M8rMklA"
   },
   "outputs": [],
   "source": [
    "my_context = '''Neoclassical economics views inequalities in the distribution of income as arising from differences in value added by labor, capital and land. Within labor income distribution is due to differences in value added by different classifications of workers. In this perspective, wages and profits are determined by the marginal value added of each economic actor (worker, capitalist/business owner, landlord). Thus, in a market economy, inequality is a reflection of the productivity gap between highly-paid professions and lower-paid professions.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL_cE-o0U8mx"
   },
   "source": [
    "Neoclassical economics views inequalities in the distribution of income as arising from differences in value added by labor, capital and land. Within labor income distribution is due to differences in value added by different classifications of workers. In this perspective, wages and profits are determined by the marginal value added of each economic actor (worker, capitalist/business owner, landlord). Thus, in a market economy, inequality is a reflection of the productivity gap between highly-paid professions and lower-paid professions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "SeB29SCNNQ1M"
   },
   "outputs": [],
   "source": [
    "#my_question = '''What philosophy of thought addresses wealth inequality?'''\n",
    "my_question = '''What are examples of economic actors?'''\n",
    "#my_question = '''In a market economy, what is inequality a reflection of?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-v5nLMNjZufe"
   },
   "outputs": [],
   "source": [
    "my_input_dict, my_context_words, context_tok_to_word_id, question_tok_len = create_input_dict(my_question, my_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT066rMtZ65X"
   },
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "CcJgDa9gVShl"
   },
   "outputs": [],
   "source": [
    "start_logits, end_logits = bert_squad(my_input_dict, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhdGlIo5Z9IZ"
   },
   "source": [
    "### Interpretación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQJMBkVLd9wp"
   },
   "source": [
    "We remove the ids corresponding to the question and the `[\"SEP\"]` token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "TfwBJfsSTwRn"
   },
   "outputs": [],
   "source": [
    "start_logits_context = start_logits.numpy()[0, question_tok_len+1:]\n",
    "end_logits_context = end_logits.numpy()[0, question_tok_len+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te1u6iZAawYf"
   },
   "source": [
    "First easy interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "lQJ8tp-1WvI4"
   },
   "outputs": [],
   "source": [
    "start_word_id = context_tok_to_word_id[np.argmax(start_logits_context)]\n",
    "end_word_id = context_tok_to_word_id[np.argmax(end_logits_context)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3PHA84rarse"
   },
   "source": [
    "\"Advanced\" - making sure that the start of the answer is before the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "xiFZ2fUiRU_M"
   },
   "outputs": [],
   "source": [
    "pair_scores = np.ones((len(start_logits_context), len(end_logits_context)))*(-1E10)\n",
    "for i in range(len(start_logits_context-1)):\n",
    "    for j in range(i, len(end_logits_context)):\n",
    "        pair_scores[i, j] = start_logits_context[i] + end_logits_context[j]\n",
    "pair_scores_argmax = np.argmax(pair_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "N9KEiFHPXXeM"
   },
   "outputs": [],
   "source": [
    "start_word_id = context_tok_to_word_id[pair_scores_argmax // len(start_logits_context)]\n",
    "end_word_id = context_tok_to_word_id[pair_scores_argmax % len(end_logits_context)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJDBL8KKa6NP"
   },
   "source": [
    "Final answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0Y3WDz0XwAw",
    "outputId": "7ff600bb-528d-4b14-f800-731aa4448e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to:\n",
      "What are examples of economic actors?\n",
      "is:\n",
      "(worker, capitalist/business owner, landlord).\n"
     ]
    }
   ],
   "source": [
    "predicted_answer = ' '.join(my_context_words[start_word_id:end_word_id+1])\n",
    "print(\"The answer to:\\n\" + my_question + \"\\nis:\\n\" + predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "bYGSk_5OSYUk",
    "outputId": "dbd02f58-62e6-45c8-8ddd-b2b6989a2385"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>WHAT ARE EXAMPLES OF ECONOMIC ACTORS?</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<blockquote> Neoclassical economics views inequalities in the distribution of income as arising from differences in value added by labor, capital and land. Within labor income distribution is due to differences in value added by different classifications of workers. In this perspective, wages and profits are determined by the marginal value added of each economic actor <mark>(worker, capitalist/business owner, landlord).</mark> Thus, in a market economy, inequality is a reflection of the productivity gap between highly-paid professions and lower-paid professions. </blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(f'<h2>{my_question.upper()}</h2>'))\n",
    "marked_text = str(my_context.replace(predicted_answer, f\"<mark>{predicted_answer}</mark>\"))\n",
    "display(HTML(f\"\"\"<blockquote> {marked_text} </blockquote>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAXMJwopGRzM"
   },
   "source": [
    "#### Reto Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Brg0AXkA0r74",
    "outputId": "27b814f9-65bf-4ae0-90d7-c246b6363ba6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>WHAT ARE THE COMMON SYMPTOMS OF THE DISEASE?</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<blockquote> \n",
       "Coronavirus disease 2019 is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It was first identified in December 2019 in Wuhan, Hubei, China, and has resulted in an ongoing pandemic.\n",
       "Common symptoms include fever, cough, fatigue, <mark>shortness of breath, and loss of</mark> smell and taste.While most people have mild symptoms, some people develop acute respiratory distress syndrome (ARDS) possibly precipitated by cytokine storm, multi-organ failure, septic shock, and blood clots. The time from exposure to onset of symptoms is typically around five days, but may range from two to fourteen days.\n",
       "The virus is spread primarily via nose and mouth secretions including small droplets produced by coughing,[a] sneezing, and talking. The droplets usually do not travel through air over long distances. However, those standing in close proximity may inhale these droplets and become infected.[b] People may also become infected by touching a contaminated surface and then touching their face. The transmission may also occur through smaller droplets that are able to stay suspended in the air for longer periods of time in enclosed spaces. </blockquote>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_context = '''\n",
    "Coronavirus disease 2019 is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). It was first identified in December 2019 in Wuhan, Hubei, China, and has resulted in an ongoing pandemic.\n",
    "Common symptoms include fever, cough, fatigue, shortness of breath, and loss of smell and taste.While most people have mild symptoms, some people develop acute respiratory distress syndrome (ARDS) possibly precipitated by cytokine storm, multi-organ failure, septic shock, and blood clots. The time from exposure to onset of symptoms is typically around five days, but may range from two to fourteen days.\n",
    "The virus is spread primarily via nose and mouth secretions including small droplets produced by coughing,[a] sneezing, and talking. The droplets usually do not travel through air over long distances. However, those standing in close proximity may inhale these droplets and become infected.[b] People may also become infected by touching a contaminated surface and then touching their face. The transmission may also occur through smaller droplets that are able to stay suspended in the air for longer periods of time in enclosed spaces.'''\n",
    "\n",
    "my_question = '''What are the common symptoms of the disease?'''\n",
    "\n",
    "my_input_dict, my_context_words, context_tok_to_word_id, question_tok_len = create_input_dict(my_question, my_context)\n",
    "\n",
    "start_logits, end_logits = bert_squad(my_input_dict, training=False)\n",
    "\n",
    "pair_scores = np.ones((len(start_logits_context), len(end_logits_context)))*(-1E10)\n",
    "for i in range(len(start_logits_context-1)):\n",
    "    for j in range(i, len(end_logits_context)):\n",
    "        pair_scores[i, j] = start_logits_context[i] + end_logits_context[j]\n",
    "pair_scores_argmax = np.argmax(pair_scores)\n",
    "\n",
    "start_word_id = context_tok_to_word_id[pair_scores_argmax // len(start_logits_context)]\n",
    "end_word_id = context_tok_to_word_id[pair_scores_argmax % len(end_logits_context)]\n",
    "\n",
    "predicted_answer = ' '.join(my_context_words[start_word_id:end_word_id+1])\n",
    "\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(f'<h2>{my_question.upper()}</h2>'))\n",
    "marked_text = str(my_context.replace(predicted_answer, f\"<mark>{predicted_answer}</mark>\"))\n",
    "display(HTML(f\"\"\"<blockquote> {marked_text} </blockquote>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fTt1zl8Fbom"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "qDIlHd5Tos6C"
   ],
   "machine_shape": "hm",
   "name": "BERT_squad",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
